!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="",n(n.s=208)}([function(e,t,n){e.exports={EPSILON:n(17),create:n(18),clone:n(80),angle:n(81),fromValues:n(19),copy:n(82),set:n(83),equals:n(84),exactEquals:n(85),add:n(86),subtract:n(20),sub:n(87),multiply:n(21),mul:n(88),divide:n(22),div:n(89),min:n(90),max:n(91),floor:n(92),ceil:n(93),round:n(94),scale:n(95),scaleAndAdd:n(96),distance:n(23),dist:n(97),squaredDistance:n(24),sqrDist:n(98),length:n(10),len:n(99),squaredLength:n(25),sqrLen:n(100),negate:n(101),inverse:n(102),normalize:n(8),dot:n(9),cross:n(26),lerp:n(103),random:n(104),transformMat4:n(105),transformMat3:n(106),transformQuat:n(107),rotateX:n(108),rotateY:n(109),rotateZ:n(110),forEach:n(111)}},function(e,t,n){e.exports={create:n(52),clone:n(53),copy:n(54),identity:n(16),transpose:n(55),invert:n(56),adjoint:n(57),determinant:n(58),multiply:n(59),translate:n(60),scale:n(61),rotate:n(62),rotateX:n(63),rotateY:n(64),rotateZ:n(65),fromRotation:n(66),fromRotationTranslation:n(67),fromScaling:n(68),fromTranslation:n(69),fromXRotation:n(70),fromYRotation:n(71),fromZRotation:n(72),fromQuat:n(73),frustum:n(74),perspective:n(75),perspectiveFromFieldOfView:n(76),ortho:n(77),lookAt:n(78),str:n(79)}},function(e,t,n){e.exports={EPSILON:n(27),create:n(28),clone:n(112),fromValues:n(113),copy:n(114),set:n(115),equals:n(116),exactEquals:n(117),add:n(118),subtract:n(29),sub:n(119),multiply:n(30),mul:n(120),divide:n(31),div:n(121),inverse:n(122),min:n(123),max:n(124),rotate:n(125),floor:n(126),ceil:n(127),round:n(128),scale:n(129),scaleAndAdd:n(130),distance:n(32),dist:n(131),squaredDistance:n(33),sqrDist:n(132),length:n(34),len:n(133),squaredLength:n(35),sqrLen:n(134),negate:n(135),normalize:n(136),dot:n(137),cross:n(138),lerp:n(139),random:n(140),transformMat2:n(141),transformMat2d:n(142),transformMat3:n(143),transformMat4:n(144),forEach:n(145),limit:n(146)}},function(e,t,n){"use strict";var r=n(7),o="object"==typeof self&&self&&self.Object===Object&&self,a=r.a||o||Function("return this")();t.a=a},function(e,t,n){e.exports={create:n(147),clone:n(36),fromValues:n(37),copy:n(38),set:n(39),add:n(40),subtract:n(148),multiply:n(149),divide:n(150),min:n(151),max:n(152),scale:n(11),scaleAndAdd:n(153),distance:n(154),squaredDistance:n(155),length:n(41),squaredLength:n(42),negate:n(156),inverse:n(157),normalize:n(12),dot:n(43),lerp:n(44),random:n(158),transformMat4:n(159),transformQuat:n(160)}},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\nvec2 getFullscreenPositionFromVertexId () {\n  vec2 pos;\n  pos.x = -1.0 + float((gl_VertexID & 1) << 2);\n  pos.y = -1.0 + float((gl_VertexID & 2) << 1);\n  return pos;\n}\n\r\n\r\nout vec2 v_position;\r\n\r\nvoid main() {\r\n  vec2 pos = getFullscreenPositionFromVertexId();\r\n  gl_Position = vec4(pos, 0.0f, 1.0f);\r\n  v_position = pos;\r\n}\r\n"},function(e,t,n){"use strict";(function(e){var r=n(3),o=n(50),a="object"==typeof exports&&exports&&!exports.nodeType&&exports,i=a&&"object"==typeof e&&e&&!e.nodeType&&e,s=i&&i.exports===a?r.a.Buffer:void 0,l=(s?s.isBuffer:void 0)||o.a;t.a=l}).call(this,n(45)(e))},function(e,t,n){"use strict";(function(e){var n="object"==typeof e&&e&&e.Object===Object&&e;t.a=n}).call(this,n(161))},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=n*n+r*r+o*o;a>0&&(a=1/Math.sqrt(a),e[0]=t[0]*a,e[1]=t[1]*a,e[2]=t[2]*a);return e}},function(e,t){e.exports=function(e,t){return e[0]*t[0]+e[1]*t[1]+e[2]*t[2]}},function(e,t){e.exports=function(e){var t=e[0],n=e[1],r=e[2];return Math.sqrt(t*t+n*n+r*r)}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n,e[1]=t[1]*n,e[2]=t[2]*n,e[3]=t[3]*n,e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=t[3],i=n*n+r*r+o*o+a*a;i>0&&(i=1/Math.sqrt(i),e[0]=n*i,e[1]=r*i,e[2]=o*i,e[3]=a*i);return e}},function(e,t,n){e.exports=n(12)},function(e,t,n){"use strict";(function(e){var r=n(7),o="object"==typeof exports&&exports&&!exports.nodeType&&exports,a=o&&"object"==typeof e&&e&&!e.nodeType&&e,i=a&&a.exports===o&&r.a.process,s=function(){try{var e=a&&a.require&&a.require("util").types;return e||i&&i.binding&&i.binding("util")}catch(e){}}();t.a=s}).call(this,n(45)(e))},function(e,t,n){e.exports={add:n(162),calculateW:n(163),clone:n(164),conjugate:n(165),copy:n(166),create:n(167),dot:n(168),fromMat3:n(46),fromValues:n(169),identity:n(170),invert:n(171),length:n(172),lerp:n(173),multiply:n(174),normalize:n(13),rotateX:n(175),rotateY:n(176),rotateZ:n(177),rotationTo:n(178),scale:n(179),set:n(180),setAxes:n(181),setAxisAngle:n(47),slerp:n(48),sqlerp:n(183),squaredLength:n(184)}},function(e,t){e.exports=function(e){return e[0]=1,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=1,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=1,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=1e-6},function(e,t){e.exports=function(){var e=new Float32Array(3);return e[0]=0,e[1]=0,e[2]=0,e}},function(e,t){e.exports=function(e,t,n){var r=new Float32Array(3);return r[0]=e,r[1]=t,r[2]=n,r}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]-n[0],e[1]=t[1]-n[1],e[2]=t[2]-n[2],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n[0],e[1]=t[1]*n[1],e[2]=t[2]*n[2],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]/n[0],e[1]=t[1]/n[1],e[2]=t[2]/n[2],e}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1],o=t[2]-e[2];return Math.sqrt(n*n+r*r+o*o)}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1],o=t[2]-e[2];return n*n+r*r+o*o}},function(e,t){e.exports=function(e){var t=e[0],n=e[1],r=e[2];return t*t+n*n+r*r}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=n[0],s=n[1],l=n[2];return e[0]=o*l-a*s,e[1]=a*i-r*l,e[2]=r*s-o*i,e}},function(e,t){e.exports=1e-6},function(e,t){e.exports=function(){var e=new Float32Array(2);return e[0]=0,e[1]=0,e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]-n[0],e[1]=t[1]-n[1],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n[0],e[1]=t[1]*n[1],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]/n[0],e[1]=t[1]/n[1],e}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1];return Math.sqrt(n*n+r*r)}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1];return n*n+r*r}},function(e,t){e.exports=function(e){var t=e[0],n=e[1];return Math.sqrt(t*t+n*n)}},function(e,t){e.exports=function(e){var t=e[0],n=e[1];return t*t+n*n}},function(e,t){e.exports=function(e){var t=new Float32Array(4);return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t}},function(e,t){e.exports=function(e,t,n,r){var o=new Float32Array(4);return o[0]=e,o[1]=t,o[2]=n,o[3]=r,o}},function(e,t){e.exports=function(e,t){return e[0]=t[0],e[1]=t[1],e[2]=t[2],e[3]=t[3],e}},function(e,t){e.exports=function(e,t,n,r,o){return e[0]=t,e[1]=n,e[2]=r,e[3]=o,e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]+n[0],e[1]=t[1]+n[1],e[2]=t[2]+n[2],e[3]=t[3]+n[3],e}},function(e,t){e.exports=function(e){var t=e[0],n=e[1],r=e[2],o=e[3];return Math.sqrt(t*t+n*n+r*r+o*o)}},function(e,t){e.exports=function(e){var t=e[0],n=e[1],r=e[2],o=e[3];return t*t+n*n+r*r+o*o}},function(e,t){e.exports=function(e,t){return e[0]*t[0]+e[1]*t[1]+e[2]*t[2]+e[3]*t[3]}},function(e,t){e.exports=function(e,t,n,r){var o=t[0],a=t[1],i=t[2],s=t[3];return e[0]=o+r*(n[0]-o),e[1]=a+r*(n[1]-a),e[2]=i+r*(n[2]-i),e[3]=s+r*(n[3]-s),e}},function(e,t){e.exports=function(e){if(!e.webpackPolyfill){var t=Object.create(e);t.children||(t.children=[]),Object.defineProperty(t,"loaded",{enumerable:!0,get:function(){return t.l}}),Object.defineProperty(t,"id",{enumerable:!0,get:function(){return t.i}}),Object.defineProperty(t,"exports",{enumerable:!0}),t.webpackPolyfill=1}return t}},function(e,t){e.exports=function(e,t){var n,r=t[0]+t[4]+t[8];if(r>0)n=Math.sqrt(r+1),e[3]=.5*n,n=.5/n,e[0]=(t[5]-t[7])*n,e[1]=(t[6]-t[2])*n,e[2]=(t[1]-t[3])*n;else{var o=0;t[4]>t[0]&&(o=1),t[8]>t[3*o+o]&&(o=2);var a=(o+1)%3,i=(o+2)%3;n=Math.sqrt(t[3*o+o]-t[3*a+a]-t[3*i+i]+1),e[o]=.5*n,n=.5/n,e[3]=(t[3*a+i]-t[3*i+a])*n,e[a]=(t[3*a+o]+t[3*o+a])*n,e[i]=(t[3*i+o]+t[3*o+i])*n}return e}},function(e,t){e.exports=function(e,t,n){n*=.5;var r=Math.sin(n);return e[0]=r*t[0],e[1]=r*t[1],e[2]=r*t[2],e[3]=Math.cos(n),e}},function(e,t){e.exports=function(e,t,n,r){var o,a,i,s,l,c=t[0],u=t[1],d=t[2],f=t[3],h=n[0],m=n[1],p=n[2],_=n[3];(a=c*h+u*m+d*p+f*_)<0&&(a=-a,h=-h,m=-m,p=-p,_=-_);1-a>1e-6?(o=Math.acos(a),i=Math.sin(o),s=Math.sin((1-r)*o)/i,l=Math.sin(r*o)/i):(s=1-r,l=r);return e[0]=s*c+l*h,e[1]=s*u+l*m,e[2]=s*d+l*p,e[3]=s*f+l*_,e}},function(e,t){e.exports="#version 300 es\r\n\r\nvoid main() {\r\n}\r\n"},function(e,t,n){"use strict";t.a=function(){return!1}},function(module,exports,__webpack_require__){var t;window,t=function(){return function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}return n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,"a",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p="/",n(n.s=0)}({"./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/*! exports provided: Attribute, DuplicateAttributeException, Layout, Material, MaterialLibrary, Mesh, TYPES, downloadModels, downloadMeshes, initMeshBuffers, deleteMeshBuffers, version */function(module,__webpack_exports__,__webpack_require__){"use strict";eval('__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "version", function() { return version; });\n/* harmony import */ var _mesh__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./mesh */ "./src/mesh.ts");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Mesh", function() { return _mesh__WEBPACK_IMPORTED_MODULE_0__["default"]; });\n\n/* harmony import */ var _material__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./material */ "./src/material.ts");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Material", function() { return _material__WEBPACK_IMPORTED_MODULE_1__["Material"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "MaterialLibrary", function() { return _material__WEBPACK_IMPORTED_MODULE_1__["MaterialLibrary"]; });\n\n/* harmony import */ var _layout__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./layout */ "./src/layout.ts");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Attribute", function() { return _layout__WEBPACK_IMPORTED_MODULE_2__["Attribute"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "DuplicateAttributeException", function() { return _layout__WEBPACK_IMPORTED_MODULE_2__["DuplicateAttributeException"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "Layout", function() { return _layout__WEBPACK_IMPORTED_MODULE_2__["Layout"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "TYPES", function() { return _layout__WEBPACK_IMPORTED_MODULE_2__["TYPES"]; });\n\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./utils */ "./src/utils.ts");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "downloadModels", function() { return _utils__WEBPACK_IMPORTED_MODULE_3__["downloadModels"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "downloadMeshes", function() { return _utils__WEBPACK_IMPORTED_MODULE_3__["downloadMeshes"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "initMeshBuffers", function() { return _utils__WEBPACK_IMPORTED_MODULE_3__["initMeshBuffers"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "deleteMeshBuffers", function() { return _utils__WEBPACK_IMPORTED_MODULE_3__["deleteMeshBuffers"]; });\n\n\n\n\n\nconst version = "1.1.3";\n/**\n * @namespace\n */\n\n\n\n//# sourceURL=webpack://OBJ/./src/index.ts?')},"./src/layout.ts":
/*!***********************!*\
  !*** ./src/layout.ts ***!
  \***********************/
/*! exports provided: TYPES, DuplicateAttributeException, Attribute, Layout */function(module,__webpack_exports__,__webpack_require__){"use strict";eval('__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "TYPES", function() { return TYPES; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DuplicateAttributeException", function() { return DuplicateAttributeException; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Attribute", function() { return Attribute; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Layout", function() { return Layout; });\nvar TYPES;\n(function (TYPES) {\n    TYPES[TYPES["BYTE"] = 1] = "BYTE";\n    TYPES[TYPES["UNSIGNED_BYTE"] = 1] = "UNSIGNED_BYTE";\n    TYPES[TYPES["SHORT"] = 2] = "SHORT";\n    TYPES[TYPES["UNSIGNED_SHORT"] = 2] = "UNSIGNED_SHORT";\n    TYPES[TYPES["FLOAT"] = 4] = "FLOAT";\n})(TYPES || (TYPES = {}));\n/**\n * An exception for when two or more of the same attributes are found in the\n * same layout.\n * @private\n */\nclass DuplicateAttributeException extends Error {\n    /**\n     * Create a DuplicateAttributeException\n     * @param {Attribute} attribute - The attribute that was found more than\n     *        once in the {@link Layout}\n     */\n    constructor(attribute) {\n        super(`found duplicate attribute: ${attribute.key}`);\n    }\n}\n/**\n * Represents how a vertex attribute should be packed into an buffer.\n * @private\n */\nclass Attribute {\n    /**\n     * Create an attribute. Do not call this directly, use the predefined\n     * constants.\n     * @param {string} key - The name of this attribute as if it were a key in\n     *        an Object. Use the camel case version of the upper snake case\n     *        const name.\n     * @param {number} size - The number of components per vertex attribute.\n     *        Must be 1, 2, 3, or 4.\n     * @param {string} type - The data type of each component for this\n     *        attribute. Possible values:<br/>\n     *        "BYTE": signed 8-bit integer, with values in [-128, 127]<br/>\n     *        "SHORT": signed 16-bit integer, with values in\n     *            [-32768, 32767]<br/>\n     *        "UNSIGNED_BYTE": unsigned 8-bit integer, with values in\n     *            [0, 255]<br/>\n     *        "UNSIGNED_SHORT": unsigned 16-bit integer, with values in\n     *            [0, 65535]<br/>\n     *        "FLOAT": 32-bit floating point number\n     * @param {boolean} normalized - Whether integer data values should be\n     *        normalized when being casted to a float.<br/>\n     *        If true, signed integers are normalized to [-1, 1].<br/>\n     *        If true, unsigned integers are normalized to [0, 1].<br/>\n     *        For type "FLOAT", this parameter has no effect.\n     */\n    constructor(key, size, type, normalized = false) {\n        this.key = key;\n        this.size = size;\n        this.type = type;\n        this.normalized = normalized;\n        this.sizeOfType = this.type;\n        this.sizeInBytes = this.sizeOfType * size;\n    }\n}\n/**\n * A class to represent the memory layout for a vertex attribute array. Used by\n * {@link Mesh}\'s TBD(...) method to generate a packed array from mesh data.\n * <p>\n * Layout can sort of be thought of as a C-style struct declaration.\n * {@link Mesh}\'s TBD(...) method will use the {@link Layout} instance to\n * pack an array in the given attribute order.\n * <p>\n * Layout also is very helpful when calling a WebGL context\'s\n * <code>vertexAttribPointer</code> method. If you\'ve created a buffer using\n * a Layout instance, then the same Layout instance can be used to determine\n * the size, type, normalized, stride, and offset parameters for\n * <code>vertexAttribPointer</code>.\n * <p>\n * For example:\n * <pre><code>\n *\n * const index = glctx.getAttribLocation(shaderProgram, "pos");\n * glctx.vertexAttribPointer(\n *   layout.position.size,\n *   glctx[layout.position.type],\n *   layout.position.normalized,\n *   layout.position.stride,\n *   layout.position.offset);\n * </code></pre>\n * @see {@link Mesh}\n */\nclass Layout {\n    /**\n     * Create a Layout object. This constructor will throw if any duplicate\n     * attributes are given.\n     * @param {Array} ...attributes - An ordered list of attributes that\n     *        describe the desired memory layout for each vertex attribute.\n     *        <p>\n     *\n     * @see {@link Mesh}\n     */\n    constructor(...attributes) {\n        this.attributes = attributes;\n        this.attributeMap = {};\n        let offset = 0;\n        let maxStrideMultiple = 0;\n        for (const attribute of attributes) {\n            if (this.attributeMap[attribute.key]) {\n                throw new DuplicateAttributeException(attribute);\n            }\n            // Add padding to satisfy WebGL\'s requirement that all\n            // vertexAttribPointer calls have an offset that is a multiple of\n            // the type size.\n            if (offset % attribute.sizeOfType !== 0) {\n                offset += attribute.sizeOfType - (offset % attribute.sizeOfType);\n                console.warn("Layout requires padding before " + attribute.key + " attribute");\n            }\n            this.attributeMap[attribute.key] = {\n                attribute: attribute,\n                size: attribute.size,\n                type: attribute.type,\n                normalized: attribute.normalized,\n                offset: offset,\n            };\n            offset += attribute.sizeInBytes;\n            maxStrideMultiple = Math.max(maxStrideMultiple, attribute.sizeOfType);\n        }\n        // Add padding to the end to satisfy WebGL\'s requirement that all\n        // vertexAttribPointer calls have a stride that is a multiple of the\n        // type size. Because we\'re putting differently sized attributes into\n        // the same buffer, it must be padded to a multiple of the largest\n        // type size.\n        if (offset % maxStrideMultiple !== 0) {\n            offset += maxStrideMultiple - (offset % maxStrideMultiple);\n            console.warn("Layout requires padding at the back");\n        }\n        this.stride = offset;\n        for (const attribute of attributes) {\n            this.attributeMap[attribute.key].stride = this.stride;\n        }\n    }\n}\n// Geometry attributes\n/**\n * Attribute layout to pack a vertex\'s x, y, & z as floats\n *\n * @see {@link Layout}\n */\nLayout.POSITION = new Attribute("position", 3, TYPES.FLOAT);\n/**\n * Attribute layout to pack a vertex\'s normal\'s x, y, & z as floats\n *\n * @see {@link Layout}\n */\nLayout.NORMAL = new Attribute("normal", 3, TYPES.FLOAT);\n/**\n * Attribute layout to pack a vertex\'s normal\'s x, y, & z as floats.\n * <p>\n * This value will be computed on-the-fly based on the texture coordinates.\n * If no texture coordinates are available, the generated value will default to\n * 0, 0, 0.\n *\n * @see {@link Layout}\n */\nLayout.TANGENT = new Attribute("tangent", 3, TYPES.FLOAT);\n/**\n * Attribute layout to pack a vertex\'s normal\'s bitangent x, y, & z as floats.\n * <p>\n * This value will be computed on-the-fly based on the texture coordinates.\n * If no texture coordinates are available, the generated value will default to\n * 0, 0, 0.\n * @see {@link Layout}\n */\nLayout.BITANGENT = new Attribute("bitangent", 3, TYPES.FLOAT);\n/**\n * Attribute layout to pack a vertex\'s texture coordinates\' u & v as floats\n *\n * @see {@link Layout}\n */\nLayout.UV = new Attribute("uv", 2, TYPES.FLOAT);\n// Material attributes\n/**\n * Attribute layout to pack an unsigned short to be interpreted as a the index\n * into a {@link Mesh}\'s materials list.\n * <p>\n * The intention of this value is to send all of the {@link Mesh}\'s materials\n * into multiple shader uniforms and then reference the current one by this\n * vertex attribute.\n * <p>\n * example glsl code:\n *\n * <pre><code>\n *  // this is bound using MATERIAL_INDEX\n *  attribute int materialIndex;\n *\n *  struct Material {\n *    vec3 diffuse;\n *    vec3 specular;\n *    vec3 specularExponent;\n *  };\n *\n *  uniform Material materials[MAX_MATERIALS];\n *\n *  // ...\n *\n *  vec3 diffuse = materials[materialIndex];\n *\n * </code></pre>\n * TODO: More description & test to make sure subscripting by attributes even\n * works for webgl\n *\n * @see {@link Layout}\n */\nLayout.MATERIAL_INDEX = new Attribute("materialIndex", 1, TYPES.SHORT);\nLayout.MATERIAL_ENABLED = new Attribute("materialEnabled", 1, TYPES.UNSIGNED_SHORT);\nLayout.AMBIENT = new Attribute("ambient", 3, TYPES.FLOAT);\nLayout.DIFFUSE = new Attribute("diffuse", 3, TYPES.FLOAT);\nLayout.SPECULAR = new Attribute("specular", 3, TYPES.FLOAT);\nLayout.SPECULAR_EXPONENT = new Attribute("specularExponent", 3, TYPES.FLOAT);\nLayout.EMISSIVE = new Attribute("emissive", 3, TYPES.FLOAT);\nLayout.TRANSMISSION_FILTER = new Attribute("transmissionFilter", 3, TYPES.FLOAT);\nLayout.DISSOLVE = new Attribute("dissolve", 1, TYPES.FLOAT);\nLayout.ILLUMINATION = new Attribute("illumination", 1, TYPES.UNSIGNED_SHORT);\nLayout.REFRACTION_INDEX = new Attribute("refractionIndex", 1, TYPES.FLOAT);\nLayout.SHARPNESS = new Attribute("sharpness", 1, TYPES.FLOAT);\nLayout.MAP_DIFFUSE = new Attribute("mapDiffuse", 1, TYPES.SHORT);\nLayout.MAP_AMBIENT = new Attribute("mapAmbient", 1, TYPES.SHORT);\nLayout.MAP_SPECULAR = new Attribute("mapSpecular", 1, TYPES.SHORT);\nLayout.MAP_SPECULAR_EXPONENT = new Attribute("mapSpecularExponent", 1, TYPES.SHORT);\nLayout.MAP_DISSOLVE = new Attribute("mapDissolve", 1, TYPES.SHORT);\nLayout.ANTI_ALIASING = new Attribute("antiAliasing", 1, TYPES.UNSIGNED_SHORT);\nLayout.MAP_BUMP = new Attribute("mapBump", 1, TYPES.SHORT);\nLayout.MAP_DISPLACEMENT = new Attribute("mapDisplacement", 1, TYPES.SHORT);\nLayout.MAP_DECAL = new Attribute("mapDecal", 1, TYPES.SHORT);\nLayout.MAP_EMISSIVE = new Attribute("mapEmissive", 1, TYPES.SHORT);\n\n\n//# sourceURL=webpack://OBJ/./src/layout.ts?')},"./src/material.ts":
/*!*************************!*\
  !*** ./src/material.ts ***!
  \*************************/
/*! exports provided: Material, MaterialLibrary */function(module,__webpack_exports__,__webpack_require__){"use strict";eval('__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "Material", function() { return Material; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MaterialLibrary", function() { return MaterialLibrary; });\n/**\n * The Material class.\n */\nclass Material {\n    constructor(name) {\n        this.name = name;\n        /**\n         * Constructor\n         * @param {String} name the unique name of the material\n         */\n        // The values for the following attibutes\n        // are an array of R, G, B normalized values.\n        // Ka - Ambient Reflectivity\n        this.ambient = [0, 0, 0];\n        // Kd - Defuse Reflectivity\n        this.diffuse = [0, 0, 0];\n        // Ks\n        this.specular = [0, 0, 0];\n        // Ke\n        this.emissive = [0, 0, 0];\n        // Tf\n        this.transmissionFilter = [0, 0, 0];\n        // d\n        this.dissolve = 0;\n        // valid range is between 0 and 1000\n        this.specularExponent = 0;\n        // either d or Tr; valid values are normalized\n        this.transparency = 0;\n        // illum - the enum of the illumination model to use\n        this.illumination = 0;\n        // Ni - Set to "normal" (air).\n        this.refractionIndex = 1;\n        // sharpness\n        this.sharpness = 0;\n        // map_Kd\n        this.mapDiffuse = emptyTextureOptions();\n        // map_Ka\n        this.mapAmbient = emptyTextureOptions();\n        // map_Ks\n        this.mapSpecular = emptyTextureOptions();\n        // map_Ns\n        this.mapSpecularExponent = emptyTextureOptions();\n        // map_d\n        this.mapDissolve = emptyTextureOptions();\n        // map_aat\n        this.antiAliasing = false;\n        // map_bump or bump\n        this.mapBump = emptyTextureOptions();\n        // disp\n        this.mapDisplacement = emptyTextureOptions();\n        // decal\n        this.mapDecal = emptyTextureOptions();\n        // map_Ke\n        this.mapEmissive = emptyTextureOptions();\n        // refl - when the reflection type is a cube, there will be multiple refl\n        //        statements for each side of the cube. If it\'s a spherical\n        //        reflection, there should only ever be one.\n        this.mapReflections = [];\n    }\n}\nconst SENTINEL_MATERIAL = new Material("sentinel");\n/**\n * https://en.wikipedia.org/wiki/Wavefront_.obj_file\n * http://paulbourke.net/dataformats/mtl/\n */\nclass MaterialLibrary {\n    constructor(data) {\n        this.data = data;\n        /**\n         * Constructs the Material Parser\n         * @param mtlData the MTL file contents\n         */\n        this.currentMaterial = SENTINEL_MATERIAL;\n        this.materials = {};\n        this.parse();\n    }\n    /* eslint-disable camelcase */\n    /* the function names here disobey camelCase conventions\n     to make parsing/routing easier. see the parse function\n     documentation for more information. */\n    /**\n     * Creates a new Material object and adds to the registry.\n     * @param tokens the tokens associated with the directive\n     */\n    parse_newmtl(tokens) {\n        const name = tokens[0];\n        // console.info(\'Parsing new Material:\', name);\n        this.currentMaterial = new Material(name);\n        this.materials[name] = this.currentMaterial;\n    }\n    /**\n     * See the documenation for parse_Ka below for a better understanding.\n     *\n     * Given a list of possible color tokens, returns an array of R, G, and B\n     * color values.\n     *\n     * @param tokens the tokens associated with the directive\n     * @return {*} a 3 element array containing the R, G, and B values\n     * of the color.\n     */\n    parseColor(tokens) {\n        if (tokens[0] == "spectral") {\n            throw new Error("The MTL parser does not support spectral curve files. You will " +\n                "need to convert the MTL colors to either RGB or CIEXYZ.");\n        }\n        if (tokens[0] == "xyz") {\n            throw new Error("The MTL parser does not currently support XYZ colors. Either convert the " +\n                "XYZ values to RGB or create an issue to add support for XYZ");\n        }\n        // from my understanding of the spec, RGB values at this point\n        // will either be 3 floats or exactly 1 float, so that\'s the check\n        // that i\'m going to perform here\n        if (tokens.length == 3) {\n            const [x, y, z] = tokens;\n            return [parseFloat(x), parseFloat(y), parseFloat(z)];\n        }\n        // Since tokens at this point has a length of 3, we\'re going to assume\n        // it\'s exactly 1, skipping the check for 2.\n        const value = parseFloat(tokens[0]);\n        // in this case, all values are equivalent\n        return [value, value, value];\n    }\n    /**\n     * Parse the ambient reflectivity\n     *\n     * A Ka directive can take one of three forms:\n     *   - Ka r g b\n     *   - Ka spectral file.rfl\n     *   - Ka xyz x y z\n     * These three forms are mutually exclusive in that only one\n     * declaration can exist per material. It is considered a syntax\n     * error otherwise.\n     *\n     * The "Ka" form specifies the ambient reflectivity using RGB values.\n     * The "g" and "b" values are optional. If only the "r" value is\n     * specified, then the "g" and "b" values are assigned the value of\n     * "r". Values are normally in the range 0.0 to 1.0. Values outside\n     * of this range increase or decrease the reflectivity accordingly.\n     *\n     * The "Ka spectral" form specifies the ambient reflectivity using a\n     * spectral curve. "file.rfl" is the name of the ".rfl" file containing\n     * the curve data. "factor" is an optional argument which is a multiplier\n     * for the values in the .rfl file and defaults to 1.0 if not specified.\n     *\n     * The "Ka xyz" form specifies the ambient reflectivity using CIEXYZ values.\n     * "x y z" are the values of the CIEXYZ color space. The "y" and "z" arguments\n     * are optional and take on the value of the "x" component if only "x" is\n     * specified. The "x y z" values are normally in the range of 0.0 to 1.0 and\n     * increase or decrease ambient reflectivity accordingly outside of that\n     * range.\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Ka(tokens) {\n        this.currentMaterial.ambient = this.parseColor(tokens);\n    }\n    /**\n     * Diffuse Reflectivity\n     *\n     * Similar to the Ka directive. Simply replace "Ka" with "Kd" and the rules\n     * are the same\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Kd(tokens) {\n        this.currentMaterial.diffuse = this.parseColor(tokens);\n    }\n    /**\n     * Spectral Reflectivity\n     *\n     * Similar to the Ka directive. Simply replace "Ks" with "Kd" and the rules\n     * are the same\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Ks(tokens) {\n        this.currentMaterial.specular = this.parseColor(tokens);\n    }\n    /**\n     * Emissive\n     *\n     * The amount and color of light emitted by the object.\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Ke(tokens) {\n        this.currentMaterial.emissive = this.parseColor(tokens);\n    }\n    /**\n     * Transmission Filter\n     *\n     * Any light passing through the object is filtered by the transmission\n     * filter, which only allows specific colors to pass through. For example, Tf\n     * 0 1 0 allows all of the green to pass through and filters out all of the\n     * red and blue.\n     *\n     * Similar to the Ka directive. Simply replace "Ks" with "Tf" and the rules\n     * are the same\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Tf(tokens) {\n        this.currentMaterial.transmissionFilter = this.parseColor(tokens);\n    }\n    /**\n     * Specifies the dissolve for the current material.\n     *\n     * Statement: d [-halo] `factor`\n     *\n     * Example: "d 0.5"\n     *\n     * The factor is the amount this material dissolves into the background. A\n     * factor of 1.0 is fully opaque. This is the default when a new material is\n     * created. A factor of 0.0 is fully dissolved (completely transparent).\n     *\n     * Unlike a real transparent material, the dissolve does not depend upon\n     * material thickness nor does it have any spectral character. Dissolve works\n     * on all illumination models.\n     *\n     * The dissolve statement allows for an optional "-halo" flag which indicates\n     * that a dissolve is dependent on the surface orientation relative to the\n     * viewer. For example, a sphere with the following dissolve, "d -halo 0.0",\n     * will be fully dissolved at its center and will appear gradually more opaque\n     * toward its edge.\n     *\n     * "factor" is the minimum amount of dissolve applied to the material. The\n     * amount of dissolve will vary between 1.0 (fully opaque) and the specified\n     * "factor". The formula is:\n     *\n     *    dissolve = 1.0 - (N*v)(1.0-factor)\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_d(tokens) {\n        // this ignores the -halo option as I can\'t find any documentation on what\n        // it\'s supposed to be.\n        this.currentMaterial.dissolve = parseFloat(tokens.pop() || "0");\n    }\n    /**\n     * The "illum" statement specifies the illumination model to use in the\n     * material. Illumination models are mathematical equations that represent\n     * various material lighting and shading effects.\n     *\n     * The illumination number can be a number from 0 to 10. The following are\n     * the list of illumination enumerations and their summaries:\n     * 0. Color on and Ambient off\n     * 1. Color on and Ambient on\n     * 2. Highlight on\n     * 3. Reflection on and Ray trace on\n     * 4. Transparency: Glass on, Reflection: Ray trace on\n     * 5. Reflection: Fresnel on and Ray trace on\n     * 6. Transparency: Refraction on, Reflection: Fresnel off and Ray trace on\n     * 7. Transparency: Refraction on, Reflection: Fresnel on and Ray trace on\n     * 8. Reflection on and Ray trace off\n     * 9. Transparency: Glass on, Reflection: Ray trace off\n     * 10. Casts shadows onto invisible surfaces\n     *\n     * Example: "illum 2" to specify the "Highlight on" model\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_illum(tokens) {\n        this.currentMaterial.illumination = parseInt(tokens[0]);\n    }\n    /**\n     * Optical Density (AKA Index of Refraction)\n     *\n     * Statement: Ni `index`\n     *\n     * Example: Ni 1.0\n     *\n     * Specifies the optical density for the surface. `index` is the value\n     * for the optical density. The values can range from 0.001 to 10.  A value of\n     * 1.0 means that light does not bend as it passes through an object.\n     * Increasing the optical_density increases the amount of bending. Glass has\n     * an index of refraction of about 1.5. Values of less than 1.0 produce\n     * bizarre results and are not recommended\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Ni(tokens) {\n        this.currentMaterial.refractionIndex = parseFloat(tokens[0]);\n    }\n    /**\n     * Specifies the specular exponent for the current material. This defines the\n     * focus of the specular highlight.\n     *\n     * Statement: Ns `exponent`\n     *\n     * Example: "Ns 250"\n     *\n     * `exponent` is the value for the specular exponent. A high exponent results\n     * in a tight, concentrated highlight. Ns Values normally range from 0 to\n     * 1000.\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_Ns(tokens) {\n        this.currentMaterial.specularExponent = parseInt(tokens[0]);\n    }\n    /**\n     * Specifies the sharpness of the reflections from the local reflection map.\n     *\n     * Statement: sharpness `value`\n     *\n     * Example: "sharpness 100"\n     *\n     * If a material does not have a local reflection map defined in its material\n     * defintions, sharpness will apply to the global reflection map defined in\n     * PreView.\n     *\n     * `value` can be a number from 0 to 1000. The default is 60. A high value\n     * results in a clear reflection of objects in the reflection map.\n     *\n     * Tip: sharpness values greater than 100 introduce aliasing effects in\n     * flat surfaces that are viewed at a sharp angle.\n     *\n     * @param tokens the tokens associated with the directive\n     */\n    parse_sharpness(tokens) {\n        this.currentMaterial.sharpness = parseInt(tokens[0]);\n    }\n    /**\n     * Parses the -cc flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -cc flag\n     * @param options the Object of all image options\n     */\n    parse_cc(values, options) {\n        options.colorCorrection = values[0] == "on";\n    }\n    /**\n     * Parses the -blendu flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -blendu flag\n     * @param options the Object of all image options\n     */\n    parse_blendu(values, options) {\n        options.horizontalBlending = values[0] == "on";\n    }\n    /**\n     * Parses the -blendv flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -blendv flag\n     * @param options the Object of all image options\n     */\n    parse_blendv(values, options) {\n        options.verticalBlending = values[0] == "on";\n    }\n    /**\n     * Parses the -boost flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -boost flag\n     * @param options the Object of all image options\n     */\n    parse_boost(values, options) {\n        options.boostMipMapSharpness = parseFloat(values[0]);\n    }\n    /**\n     * Parses the -mm flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -mm flag\n     * @param options the Object of all image options\n     */\n    parse_mm(values, options) {\n        options.modifyTextureMap.brightness = parseFloat(values[0]);\n        options.modifyTextureMap.contrast = parseFloat(values[1]);\n    }\n    /**\n     * Parses and sets the -o, -s, and -t  u, v, and w values\n     *\n     * @param values the values passed to the -o, -s, -t flag\n     * @param {Object} option the Object of either the -o, -s, -t option\n     * @param {Integer} defaultValue the Object of all image options\n     */\n    parse_ost(values, option, defaultValue) {\n        while (values.length < 3) {\n            values.push(defaultValue.toString());\n        }\n        option.u = parseFloat(values[0]);\n        option.v = parseFloat(values[1]);\n        option.w = parseFloat(values[2]);\n    }\n    /**\n     * Parses the -o flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -o flag\n     * @param options the Object of all image options\n     */\n    parse_o(values, options) {\n        this.parse_ost(values, options.offset, 0);\n    }\n    /**\n     * Parses the -s flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -s flag\n     * @param options the Object of all image options\n     */\n    parse_s(values, options) {\n        this.parse_ost(values, options.scale, 1);\n    }\n    /**\n     * Parses the -t flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -t flag\n     * @param options the Object of all image options\n     */\n    parse_t(values, options) {\n        this.parse_ost(values, options.turbulence, 0);\n    }\n    /**\n     * Parses the -texres flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -texres flag\n     * @param options the Object of all image options\n     */\n    parse_texres(values, options) {\n        options.textureResolution = parseFloat(values[0]);\n    }\n    /**\n     * Parses the -clamp flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -clamp flag\n     * @param options the Object of all image options\n     */\n    parse_clamp(values, options) {\n        options.clamp = values[0] == "on";\n    }\n    /**\n     * Parses the -bm flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -bm flag\n     * @param options the Object of all image options\n     */\n    parse_bm(values, options) {\n        options.bumpMultiplier = parseFloat(values[0]);\n    }\n    /**\n     * Parses the -imfchan flag and updates the options object with the values.\n     *\n     * @param values the values passed to the -imfchan flag\n     * @param options the Object of all image options\n     */\n    parse_imfchan(values, options) {\n        options.imfChan = values[0];\n    }\n    /**\n     * This only exists for relection maps and denotes the type of reflection.\n     *\n     * @param values the values passed to the -type flag\n     * @param options the Object of all image options\n     */\n    parse_type(values, options) {\n        options.reflectionType = values[0];\n    }\n    /**\n     * Parses the texture\'s options and returns an options object with the info\n     *\n     * @param tokens all of the option tokens to pass to the texture\n     * @return {Object} a complete object of objects to apply to the texture\n     */\n    parseOptions(tokens) {\n        const options = emptyTextureOptions();\n        let option;\n        let values;\n        const optionsToValues = {};\n        tokens.reverse();\n        while (tokens.length) {\n            // token is guaranteed to exists here, hence the explicit "as"\n            const token = tokens.pop();\n            if (token.startsWith("-")) {\n                option = token.substr(1);\n                optionsToValues[option] = [];\n            }\n            else if (option) {\n                optionsToValues[option].push(token);\n            }\n        }\n        for (option in optionsToValues) {\n            if (!optionsToValues.hasOwnProperty(option)) {\n                continue;\n            }\n            values = optionsToValues[option];\n            const optionMethod = this[`parse_${option}`];\n            if (optionMethod) {\n                optionMethod.bind(this)(values, options);\n            }\n        }\n        return options;\n    }\n    /**\n     * Parses the given texture map line.\n     *\n     * @param tokens all of the tokens representing the texture\n     * @return a complete object of objects to apply to the texture\n     */\n    parseMap(tokens) {\n        // according to wikipedia:\n        // (https://en.wikipedia.org/wiki/Wavefront_.obj_file#Vendor_specific_alterations)\n        // there is at least one vendor that places the filename before the options\n        // rather than after (which is to spec). All options start with a \'-\'\n        // so if the first token doesn\'t start with a \'-\', we\'re going to assume\n        // it\'s the name of the map file.\n        let optionsString;\n        let filename = "";\n        if (!tokens[0].startsWith("-")) {\n            [filename, ...optionsString] = tokens;\n        }\n        else {\n            filename = tokens.pop();\n            optionsString = tokens;\n        }\n        const options = this.parseOptions(optionsString);\n        options.filename = filename;\n        return options;\n    }\n    /**\n     * Parses the ambient map.\n     *\n     * @param tokens list of tokens for the map_Ka direcive\n     */\n    parse_map_Ka(tokens) {\n        this.currentMaterial.mapAmbient = this.parseMap(tokens);\n    }\n    /**\n     * Parses the diffuse map.\n     *\n     * @param tokens list of tokens for the map_Kd direcive\n     */\n    parse_map_Kd(tokens) {\n        this.currentMaterial.mapDiffuse = this.parseMap(tokens);\n    }\n    /**\n     * Parses the specular map.\n     *\n     * @param tokens list of tokens for the map_Ks direcive\n     */\n    parse_map_Ks(tokens) {\n        this.currentMaterial.mapSpecular = this.parseMap(tokens);\n    }\n    /**\n     * Parses the emissive map.\n     *\n     * @param tokens list of tokens for the map_Ke direcive\n     */\n    parse_map_Ke(tokens) {\n        this.currentMaterial.mapEmissive = this.parseMap(tokens);\n    }\n    /**\n     * Parses the specular exponent map.\n     *\n     * @param tokens list of tokens for the map_Ns direcive\n     */\n    parse_map_Ns(tokens) {\n        this.currentMaterial.mapSpecularExponent = this.parseMap(tokens);\n    }\n    /**\n     * Parses the dissolve map.\n     *\n     * @param tokens list of tokens for the map_d direcive\n     */\n    parse_map_d(tokens) {\n        this.currentMaterial.mapDissolve = this.parseMap(tokens);\n    }\n    /**\n     * Parses the anti-aliasing option.\n     *\n     * @param tokens list of tokens for the map_aat direcive\n     */\n    parse_map_aat(tokens) {\n        this.currentMaterial.antiAliasing = tokens[0] == "on";\n    }\n    /**\n     * Parses the bump map.\n     *\n     * @param tokens list of tokens for the map_bump direcive\n     */\n    parse_map_bump(tokens) {\n        this.currentMaterial.mapBump = this.parseMap(tokens);\n    }\n    /**\n     * Parses the bump map.\n     *\n     * @param tokens list of tokens for the bump direcive\n     */\n    parse_bump(tokens) {\n        this.parse_map_bump(tokens);\n    }\n    /**\n     * Parses the disp map.\n     *\n     * @param tokens list of tokens for the disp direcive\n     */\n    parse_disp(tokens) {\n        this.currentMaterial.mapDisplacement = this.parseMap(tokens);\n    }\n    /**\n     * Parses the decal map.\n     *\n     * @param tokens list of tokens for the map_decal direcive\n     */\n    parse_decal(tokens) {\n        this.currentMaterial.mapDecal = this.parseMap(tokens);\n    }\n    /**\n     * Parses the refl map.\n     *\n     * @param tokens list of tokens for the refl direcive\n     */\n    parse_refl(tokens) {\n        this.currentMaterial.mapReflections.push(this.parseMap(tokens));\n    }\n    /**\n     * Parses the MTL file.\n     *\n     * Iterates line by line parsing each MTL directive.\n     *\n     * This function expects the first token in the line\n     * to be a valid MTL directive. That token is then used\n     * to try and run a method on this class. parse_[directive]\n     * E.g., the `newmtl` directive would try to call the method\n     * parse_newmtl. Each parsing function takes in the remaining\n     * list of tokens and updates the currentMaterial class with\n     * the attributes provided.\n     */\n    parse() {\n        const lines = this.data.split(/\\r?\\n/);\n        for (let line of lines) {\n            line = line.trim();\n            if (!line || line.startsWith("#")) {\n                continue;\n            }\n            const [directive, ...tokens] = line.split(/\\s/);\n            const parseMethod = this[`parse_${directive}`];\n            if (!parseMethod) {\n                console.warn(`Don\'t know how to parse the directive: "${directive}"`);\n                continue;\n            }\n            // console.log(`Parsing "${directive}" with tokens: ${tokens}`);\n            parseMethod.bind(this)(tokens);\n        }\n        // some cleanup. These don\'t need to be exposed as public data.\n        delete this.data;\n        this.currentMaterial = SENTINEL_MATERIAL;\n    }\n}\nfunction emptyTextureOptions() {\n    return {\n        colorCorrection: false,\n        horizontalBlending: true,\n        verticalBlending: true,\n        boostMipMapSharpness: 0,\n        modifyTextureMap: {\n            brightness: 0,\n            contrast: 1,\n        },\n        offset: { u: 0, v: 0, w: 0 },\n        scale: { u: 1, v: 1, w: 1 },\n        turbulence: { u: 0, v: 0, w: 0 },\n        clamp: false,\n        textureResolution: null,\n        bumpMultiplier: 1,\n        imfChan: null,\n        filename: "",\n    };\n}\n\n\n//# sourceURL=webpack://OBJ/./src/material.ts?')},"./src/mesh.ts":
/*!*********************!*\
  !*** ./src/mesh.ts ***!
  \*********************/
/*! exports provided: default */function(module,__webpack_exports__,__webpack_require__){"use strict";eval('__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "default", function() { return Mesh; });\n/* harmony import */ var _layout__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./layout */ "./src/layout.ts");\n\n/**\n * The main Mesh class. The constructor will parse through the OBJ file data\n * and collect the vertex, vertex normal, texture, and face information. This\n * information can then be used later on when creating your VBOs. See\n * OBJ.initMeshBuffers for an example of how to use the newly created Mesh\n */\nclass Mesh {\n    /**\n     * Create a Mesh\n     * @param {String} objectData - a string representation of an OBJ file with\n     *     newlines preserved.\n     * @param {Object} options - a JS object containing valid options. See class\n     *     documentation for options.\n     * @param {bool} options.enableWTextureCoord - Texture coordinates can have\n     *     an optional "w" coordinate after the u and v coordinates. This extra\n     *     value can be used in order to perform fancy transformations on the\n     *     textures themselves. Default is to truncate to only the u an v\n     *     coordinates. Passing true will provide a default value of 0 in the\n     *     event that any or all texture coordinates don\'t provide a w value.\n     *     Always use the textureStride attribute in order to determine the\n     *     stride length of the texture coordinates when rendering the element\n     *     array.\n     * @param {bool} options.calcTangentsAndBitangents - Calculate the tangents\n     *     and bitangents when loading of the OBJ is completed. This adds two new\n     *     attributes to the Mesh instance: `tangents` and `bitangents`.\n     */\n    constructor(objectData, options) {\n        this.name = "";\n        this.indicesPerMaterial = [];\n        this.materialsByIndex = {};\n        this.tangents = [];\n        this.bitangents = [];\n        options = options || {};\n        options.materials = options.materials || {};\n        options.enableWTextureCoord = !!options.enableWTextureCoord;\n        // the list of unique vertex, normal, texture, attributes\n        this.vertexNormals = [];\n        this.textures = [];\n        // the indicies to draw the faces\n        this.indices = [];\n        this.textureStride = options.enableWTextureCoord ? 3 : 2;\n        /*\n        The OBJ file format does a sort of compression when saving a model in a\n        program like Blender. There are at least 3 sections (4 including textures)\n        within the file. Each line in a section begins with the same string:\n          * \'v\': indicates vertex section\n          * \'vn\': indicates vertex normal section\n          * \'f\': indicates the faces section\n          * \'vt\': indicates vertex texture section (if textures were used on the model)\n        Each of the above sections (except for the faces section) is a list/set of\n        unique vertices.\n\n        Each line of the faces section contains a list of\n        (vertex, [texture], normal) groups.\n\n        **Note:** The following documentation will use a capital "V" Vertex to\n        denote the above (vertex, [texture], normal) groups whereas a lowercase\n        "v" vertex is used to denote an X, Y, Z coordinate.\n\n        Some examples:\n            // the texture index is optional, both formats are possible for models\n            // without a texture applied\n            f 1/25 18/46 12/31\n            f 1//25 18//46 12//31\n\n            // A 3 vertex face with texture indices\n            f 16/92/11 14/101/22 1/69/1\n\n            // A 4 vertex face\n            f 16/92/11 40/109/40 38/114/38 14/101/22\n\n        The first two lines are examples of a 3 vertex face without a texture applied.\n        The second is an example of a 3 vertex face with a texture applied.\n        The third is an example of a 4 vertex face. Note: a face can contain N\n        number of vertices.\n\n        Each number that appears in one of the groups is a 1-based index\n        corresponding to an item from the other sections (meaning that indexing\n        starts at one and *not* zero).\n\n        For example:\n            `f 16/92/11` is saying to\n              - take the 16th element from the [v] vertex array\n              - take the 92nd element from the [vt] texture array\n              - take the 11th element from the [vn] normal array\n            and together they make a unique vertex.\n        Using all 3+ unique Vertices from the face line will produce a polygon.\n\n        Now, you could just go through the OBJ file and create a new vertex for\n        each face line and WebGL will draw what appears to be the same model.\n        However, vertices will be overlapped and duplicated all over the place.\n\n        Consider a cube in 3D space centered about the origin and each side is\n        2 units long. The front face (with the positive Z-axis pointing towards\n        you) would have a Top Right vertex (looking orthogonal to its normal)\n        mapped at (1,1,1) The right face would have a Top Left vertex (looking\n        orthogonal to its normal) at (1,1,1) and the top face would have a Bottom\n        Right vertex (looking orthogonal to its normal) at (1,1,1). Each face\n        has a vertex at the same coordinates, however, three distinct vertices\n        will be drawn at the same spot.\n\n        To solve the issue of duplicate Vertices (the `(vertex, [texture], normal)`\n        groups), while iterating through the face lines, when a group is encountered\n        the whole group string (\'16/92/11\') is checked to see if it exists in the\n        packed.hashindices object, and if it doesn\'t, the indices it specifies\n        are used to look up each attribute in the corresponding attribute arrays\n        already created. The values are then copied to the corresponding unpacked\n        array (flattened to play nice with WebGL\'s ELEMENT_ARRAY_BUFFER indexing),\n        the group string is added to the hashindices set and the current unpacked\n        index is used as this hashindices value so that the group of elements can\n        be reused. The unpacked index is incremented. If the group string already\n        exists in the hashindices object, its corresponding value is the index of\n        that group and is appended to the unpacked indices array.\n       */\n        const verts = [];\n        const vertNormals = [];\n        const textures = [];\n        const materialNamesByIndex = [];\n        const materialIndicesByName = {};\n        // keep track of what material we\'ve seen last\n        let currentMaterialIndex = -1;\n        let currentObjectByMaterialIndex = 0;\n        // unpacking stuff\n        const unpacked = {\n            verts: [],\n            norms: [],\n            textures: [],\n            hashindices: {},\n            indices: [[]],\n            materialIndices: [],\n            index: 0,\n        };\n        const VERTEX_RE = /^v\\s/;\n        const NORMAL_RE = /^vn\\s/;\n        const TEXTURE_RE = /^vt\\s/;\n        const FACE_RE = /^f\\s/;\n        const WHITESPACE_RE = /\\s+/;\n        const USE_MATERIAL_RE = /^usemtl/;\n        // array of lines separated by the newline\n        const lines = objectData.split("\\n");\n        for (let line of lines) {\n            line = line.trim();\n            if (!line || line.startsWith("#")) {\n                continue;\n            }\n            const elements = line.split(WHITESPACE_RE);\n            elements.shift();\n            if (VERTEX_RE.test(line)) {\n                // if this is a vertex\n                verts.push(...elements);\n            }\n            else if (NORMAL_RE.test(line)) {\n                // if this is a vertex normal\n                vertNormals.push(...elements);\n            }\n            else if (TEXTURE_RE.test(line)) {\n                let coords = elements;\n                // by default, the loader will only look at the U and V\n                // coordinates of the vt declaration. So, this truncates the\n                // elements to only those 2 values. If W texture coordinate\n                // support is enabled, then the texture coordinate is\n                // expected to have three values in it.\n                if (elements.length > 2 && !options.enableWTextureCoord) {\n                    coords = elements.slice(0, 2);\n                }\n                else if (elements.length === 2 && options.enableWTextureCoord) {\n                    // If for some reason W texture coordinate support is enabled\n                    // and only the U and V coordinates are given, then we supply\n                    // the default value of 0 so that the stride length is correct\n                    // when the textures are unpacked below.\n                    coords.push("0");\n                }\n                textures.push(...coords);\n            }\n            else if (USE_MATERIAL_RE.test(line)) {\n                const materialName = elements[0];\n                // check to see if we\'ve ever seen it before\n                if (!(materialName in materialIndicesByName)) {\n                    // new material we\'ve never seen\n                    materialNamesByIndex.push(materialName);\n                    materialIndicesByName[materialName] = materialNamesByIndex.length - 1;\n                    // push new array into indices\n                    // already contains an array at index zero, don\'t add\n                    if (materialIndicesByName[materialName] > 0) {\n                        unpacked.indices.push([]);\n                    }\n                }\n                // keep track of the current material index\n                currentMaterialIndex = materialIndicesByName[materialName];\n                // update current index array\n                currentObjectByMaterialIndex = currentMaterialIndex;\n            }\n            else if (FACE_RE.test(line)) {\n                // if this is a face\n                /*\n                split this face into an array of Vertex groups\n                for example:\n                   f 16/92/11 14/101/22 1/69/1\n                becomes:\n                  [\'16/92/11\', \'14/101/22\', \'1/69/1\'];\n                */\n                let quad = false;\n                for (let j = 0, eleLen = elements.length; j < eleLen; j++) {\n                    // Triangulating quads\n                    // quad: \'f v0/t0/vn0 v1/t1/vn1 v2/t2/vn2 v3/t3/vn3/\'\n                    // corresponding triangles:\n                    //      \'f v0/t0/vn0 v1/t1/vn1 v2/t2/vn2\'\n                    //      \'f v2/t2/vn2 v3/t3/vn3 v0/t0/vn0\'\n                    if (j === 3 && !quad) {\n                        // add v2/t2/vn2 in again before continuing to 3\n                        j = 2;\n                        quad = true;\n                    }\n                    const hash0 = elements[0] + "," + currentMaterialIndex;\n                    const hash = elements[j] + "," + currentMaterialIndex;\n                    if (hash in unpacked.hashindices) {\n                        unpacked.indices[currentObjectByMaterialIndex].push(unpacked.hashindices[hash]);\n                    }\n                    else {\n                        /*\n                        Each element of the face line array is a Vertex which has its\n                        attributes delimited by a forward slash. This will separate\n                        each attribute into another array:\n                            \'19/92/11\'\n                        becomes:\n                            Vertex = [\'19\', \'92\', \'11\'];\n                        where\n                            Vertex[0] is the vertex index\n                            Vertex[1] is the texture index\n                            Vertex[2] is the normal index\n                         Think of faces having Vertices which are comprised of the\n                         attributes location (v), texture (vt), and normal (vn).\n                         */\n                        const vertex = elements[j].split("/");\n                        // it\'s possible for faces to only specify the vertex\n                        // and the normal. In this case, vertex will only have\n                        // a length of 2 and not 3 and the normal will be the\n                        // second item in the list with an index of 1.\n                        const normalIndex = vertex.length - 1;\n                        /*\n                         The verts, textures, and vertNormals arrays each contain a\n                         flattend array of coordinates.\n\n                         Because it gets confusing by referring to Vertex and then\n                         vertex (both are different in my descriptions) I will explain\n                         what\'s going on using the vertexNormals array:\n\n                         vertex[2] will contain the one-based index of the vertexNormals\n                         section (vn). One is subtracted from this index number to play\n                         nice with javascript\'s zero-based array indexing.\n\n                         Because vertexNormal is a flattened array of x, y, z values,\n                         simple pointer arithmetic is used to skip to the start of the\n                         vertexNormal, then the offset is added to get the correct\n                         component: +0 is x, +1 is y, +2 is z.\n\n                         This same process is repeated for verts and textures.\n                         */\n                        // Vertex position\n                        unpacked.verts.push(+verts[(+vertex[0] - 1) * 3 + 0]);\n                        unpacked.verts.push(+verts[(+vertex[0] - 1) * 3 + 1]);\n                        unpacked.verts.push(+verts[(+vertex[0] - 1) * 3 + 2]);\n                        // Vertex textures\n                        if (textures.length) {\n                            const stride = options.enableWTextureCoord ? 3 : 2;\n                            unpacked.textures.push(+textures[(+vertex[1] - 1) * stride + 0]);\n                            unpacked.textures.push(+textures[(+vertex[1] - 1) * stride + 1]);\n                            if (options.enableWTextureCoord) {\n                                unpacked.textures.push(+textures[(+vertex[1] - 1) * stride + 2]);\n                            }\n                        }\n                        // Vertex normals\n                        unpacked.norms.push(+vertNormals[(+vertex[normalIndex] - 1) * 3 + 0]);\n                        unpacked.norms.push(+vertNormals[(+vertex[normalIndex] - 1) * 3 + 1]);\n                        unpacked.norms.push(+vertNormals[(+vertex[normalIndex] - 1) * 3 + 2]);\n                        // Vertex material indices\n                        unpacked.materialIndices.push(currentMaterialIndex);\n                        // add the newly created Vertex to the list of indices\n                        unpacked.hashindices[hash] = unpacked.index;\n                        unpacked.indices[currentObjectByMaterialIndex].push(unpacked.hashindices[hash]);\n                        // increment the counter\n                        unpacked.index += 1;\n                    }\n                    if (j === 3 && quad) {\n                        // add v0/t0/vn0 onto the second triangle\n                        unpacked.indices[currentObjectByMaterialIndex].push(unpacked.hashindices[hash0]);\n                    }\n                }\n            }\n        }\n        this.vertices = unpacked.verts;\n        this.vertexNormals = unpacked.norms;\n        this.textures = unpacked.textures;\n        this.vertexMaterialIndices = unpacked.materialIndices;\n        this.indices = unpacked.indices[currentObjectByMaterialIndex];\n        this.indicesPerMaterial = unpacked.indices;\n        this.materialNames = materialNamesByIndex;\n        this.materialIndices = materialIndicesByName;\n        this.materialsByIndex = {};\n        if (options.calcTangentsAndBitangents) {\n            this.calculateTangentsAndBitangents();\n        }\n    }\n    /**\n     * Calculates the tangents and bitangents of the mesh that forms an orthogonal basis together with the\n     * normal in the direction of the texture coordinates. These are useful for setting up the TBN matrix\n     * when distorting the normals through normal maps.\n     * Method derived from: http://www.opengl-tutorial.org/intermediate-tutorials/tutorial-13-normal-mapping/\n     *\n     * This method requires the normals and texture coordinates to be parsed and set up correctly.\n     * Adds the tangents and bitangents as members of the class instance.\n     */\n    calculateTangentsAndBitangents() {\n        console.assert(!!(this.vertices &&\n            this.vertices.length &&\n            this.vertexNormals &&\n            this.vertexNormals.length &&\n            this.textures &&\n            this.textures.length), "Missing attributes for calculating tangents and bitangents");\n        const unpacked = {\n            tangents: [...new Array(this.vertices.length)].map(_ => 0),\n            bitangents: [...new Array(this.vertices.length)].map(_ => 0),\n        };\n        // Loop through all faces in the whole mesh\n        const indices = this.indices;\n        const vertices = this.vertices;\n        const normals = this.vertexNormals;\n        const uvs = this.textures;\n        for (let i = 0; i < indices.length; i += 3) {\n            const i0 = indices[i + 0];\n            const i1 = indices[i + 1];\n            const i2 = indices[i + 2];\n            const x_v0 = vertices[i0 * 3 + 0];\n            const y_v0 = vertices[i0 * 3 + 1];\n            const z_v0 = vertices[i0 * 3 + 2];\n            const x_uv0 = uvs[i0 * 2 + 0];\n            const y_uv0 = uvs[i0 * 2 + 1];\n            const x_v1 = vertices[i1 * 3 + 0];\n            const y_v1 = vertices[i1 * 3 + 1];\n            const z_v1 = vertices[i1 * 3 + 2];\n            const x_uv1 = uvs[i1 * 2 + 0];\n            const y_uv1 = uvs[i1 * 2 + 1];\n            const x_v2 = vertices[i2 * 3 + 0];\n            const y_v2 = vertices[i2 * 3 + 1];\n            const z_v2 = vertices[i2 * 3 + 2];\n            const x_uv2 = uvs[i2 * 2 + 0];\n            const y_uv2 = uvs[i2 * 2 + 1];\n            const x_deltaPos1 = x_v1 - x_v0;\n            const y_deltaPos1 = y_v1 - y_v0;\n            const z_deltaPos1 = z_v1 - z_v0;\n            const x_deltaPos2 = x_v2 - x_v0;\n            const y_deltaPos2 = y_v2 - y_v0;\n            const z_deltaPos2 = z_v2 - z_v0;\n            const x_uvDeltaPos1 = x_uv1 - x_uv0;\n            const y_uvDeltaPos1 = y_uv1 - y_uv0;\n            const x_uvDeltaPos2 = x_uv2 - x_uv0;\n            const y_uvDeltaPos2 = y_uv2 - y_uv0;\n            const rInv = x_uvDeltaPos1 * y_uvDeltaPos2 - y_uvDeltaPos1 * x_uvDeltaPos2;\n            const r = 1.0 / Math.abs(rInv < 0.0001 ? 1.0 : rInv);\n            // Tangent\n            const x_tangent = (x_deltaPos1 * y_uvDeltaPos2 - x_deltaPos2 * y_uvDeltaPos1) * r;\n            const y_tangent = (y_deltaPos1 * y_uvDeltaPos2 - y_deltaPos2 * y_uvDeltaPos1) * r;\n            const z_tangent = (z_deltaPos1 * y_uvDeltaPos2 - z_deltaPos2 * y_uvDeltaPos1) * r;\n            // Bitangent\n            const x_bitangent = (x_deltaPos2 * x_uvDeltaPos1 - x_deltaPos1 * x_uvDeltaPos2) * r;\n            const y_bitangent = (y_deltaPos2 * x_uvDeltaPos1 - y_deltaPos1 * x_uvDeltaPos2) * r;\n            const z_bitangent = (z_deltaPos2 * x_uvDeltaPos1 - z_deltaPos1 * x_uvDeltaPos2) * r;\n            // Gram-Schmidt orthogonalize\n            //t = glm::normalize(t - n * glm:: dot(n, t));\n            const x_n0 = normals[i0 * 3 + 0];\n            const y_n0 = normals[i0 * 3 + 1];\n            const z_n0 = normals[i0 * 3 + 2];\n            const x_n1 = normals[i1 * 3 + 0];\n            const y_n1 = normals[i1 * 3 + 1];\n            const z_n1 = normals[i1 * 3 + 2];\n            const x_n2 = normals[i2 * 3 + 0];\n            const y_n2 = normals[i2 * 3 + 1];\n            const z_n2 = normals[i2 * 3 + 2];\n            // Tangent\n            const n0_dot_t = x_tangent * x_n0 + y_tangent * y_n0 + z_tangent * z_n0;\n            const n1_dot_t = x_tangent * x_n1 + y_tangent * y_n1 + z_tangent * z_n1;\n            const n2_dot_t = x_tangent * x_n2 + y_tangent * y_n2 + z_tangent * z_n2;\n            const x_resTangent0 = x_tangent - x_n0 * n0_dot_t;\n            const y_resTangent0 = y_tangent - y_n0 * n0_dot_t;\n            const z_resTangent0 = z_tangent - z_n0 * n0_dot_t;\n            const x_resTangent1 = x_tangent - x_n1 * n1_dot_t;\n            const y_resTangent1 = y_tangent - y_n1 * n1_dot_t;\n            const z_resTangent1 = z_tangent - z_n1 * n1_dot_t;\n            const x_resTangent2 = x_tangent - x_n2 * n2_dot_t;\n            const y_resTangent2 = y_tangent - y_n2 * n2_dot_t;\n            const z_resTangent2 = z_tangent - z_n2 * n2_dot_t;\n            const magTangent0 = Math.sqrt(x_resTangent0 * x_resTangent0 + y_resTangent0 * y_resTangent0 + z_resTangent0 * z_resTangent0);\n            const magTangent1 = Math.sqrt(x_resTangent1 * x_resTangent1 + y_resTangent1 * y_resTangent1 + z_resTangent1 * z_resTangent1);\n            const magTangent2 = Math.sqrt(x_resTangent2 * x_resTangent2 + y_resTangent2 * y_resTangent2 + z_resTangent2 * z_resTangent2);\n            // Bitangent\n            const n0_dot_bt = x_bitangent * x_n0 + y_bitangent * y_n0 + z_bitangent * z_n0;\n            const n1_dot_bt = x_bitangent * x_n1 + y_bitangent * y_n1 + z_bitangent * z_n1;\n            const n2_dot_bt = x_bitangent * x_n2 + y_bitangent * y_n2 + z_bitangent * z_n2;\n            const x_resBitangent0 = x_bitangent - x_n0 * n0_dot_bt;\n            const y_resBitangent0 = y_bitangent - y_n0 * n0_dot_bt;\n            const z_resBitangent0 = z_bitangent - z_n0 * n0_dot_bt;\n            const x_resBitangent1 = x_bitangent - x_n1 * n1_dot_bt;\n            const y_resBitangent1 = y_bitangent - y_n1 * n1_dot_bt;\n            const z_resBitangent1 = z_bitangent - z_n1 * n1_dot_bt;\n            const x_resBitangent2 = x_bitangent - x_n2 * n2_dot_bt;\n            const y_resBitangent2 = y_bitangent - y_n2 * n2_dot_bt;\n            const z_resBitangent2 = z_bitangent - z_n2 * n2_dot_bt;\n            const magBitangent0 = Math.sqrt(x_resBitangent0 * x_resBitangent0 +\n                y_resBitangent0 * y_resBitangent0 +\n                z_resBitangent0 * z_resBitangent0);\n            const magBitangent1 = Math.sqrt(x_resBitangent1 * x_resBitangent1 +\n                y_resBitangent1 * y_resBitangent1 +\n                z_resBitangent1 * z_resBitangent1);\n            const magBitangent2 = Math.sqrt(x_resBitangent2 * x_resBitangent2 +\n                y_resBitangent2 * y_resBitangent2 +\n                z_resBitangent2 * z_resBitangent2);\n            unpacked.tangents[i0 * 3 + 0] += x_resTangent0 / magTangent0;\n            unpacked.tangents[i0 * 3 + 1] += y_resTangent0 / magTangent0;\n            unpacked.tangents[i0 * 3 + 2] += z_resTangent0 / magTangent0;\n            unpacked.tangents[i1 * 3 + 0] += x_resTangent1 / magTangent1;\n            unpacked.tangents[i1 * 3 + 1] += y_resTangent1 / magTangent1;\n            unpacked.tangents[i1 * 3 + 2] += z_resTangent1 / magTangent1;\n            unpacked.tangents[i2 * 3 + 0] += x_resTangent2 / magTangent2;\n            unpacked.tangents[i2 * 3 + 1] += y_resTangent2 / magTangent2;\n            unpacked.tangents[i2 * 3 + 2] += z_resTangent2 / magTangent2;\n            unpacked.bitangents[i0 * 3 + 0] += x_resBitangent0 / magBitangent0;\n            unpacked.bitangents[i0 * 3 + 1] += y_resBitangent0 / magBitangent0;\n            unpacked.bitangents[i0 * 3 + 2] += z_resBitangent0 / magBitangent0;\n            unpacked.bitangents[i1 * 3 + 0] += x_resBitangent1 / magBitangent1;\n            unpacked.bitangents[i1 * 3 + 1] += y_resBitangent1 / magBitangent1;\n            unpacked.bitangents[i1 * 3 + 2] += z_resBitangent1 / magBitangent1;\n            unpacked.bitangents[i2 * 3 + 0] += x_resBitangent2 / magBitangent2;\n            unpacked.bitangents[i2 * 3 + 1] += y_resBitangent2 / magBitangent2;\n            unpacked.bitangents[i2 * 3 + 2] += z_resBitangent2 / magBitangent2;\n            // TODO: check handedness\n        }\n        this.tangents = unpacked.tangents;\n        this.bitangents = unpacked.bitangents;\n    }\n    /**\n     * @param layout - A {@link Layout} object that describes the\n     * desired memory layout of the generated buffer\n     * @return The packed array in the ... TODO\n     */\n    makeBufferData(layout) {\n        const numItems = this.vertices.length / 3;\n        const buffer = new ArrayBuffer(layout.stride * numItems);\n        buffer.numItems = numItems;\n        const dataView = new DataView(buffer);\n        for (let i = 0, vertexOffset = 0; i < numItems; i++) {\n            vertexOffset = i * layout.stride;\n            // copy in the vertex data in the order and format given by the\n            // layout param\n            for (const attribute of layout.attributes) {\n                const offset = vertexOffset + layout.attributeMap[attribute.key].offset;\n                switch (attribute.key) {\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].POSITION.key:\n                        dataView.setFloat32(offset, this.vertices[i * 3], true);\n                        dataView.setFloat32(offset + 4, this.vertices[i * 3 + 1], true);\n                        dataView.setFloat32(offset + 8, this.vertices[i * 3 + 2], true);\n                        break;\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].UV.key:\n                        dataView.setFloat32(offset, this.textures[i * 2], true);\n                        dataView.setFloat32(offset + 4, this.textures[i * 2 + 1], true);\n                        break;\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].NORMAL.key:\n                        dataView.setFloat32(offset, this.vertexNormals[i * 3], true);\n                        dataView.setFloat32(offset + 4, this.vertexNormals[i * 3 + 1], true);\n                        dataView.setFloat32(offset + 8, this.vertexNormals[i * 3 + 2], true);\n                        break;\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].MATERIAL_INDEX.key:\n                        dataView.setInt16(offset, this.vertexMaterialIndices[i], true);\n                        break;\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].AMBIENT.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.ambient[0], true);\n                        dataView.setFloat32(offset + 4, material.ambient[1], true);\n                        dataView.setFloat32(offset + 8, material.ambient[2], true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].DIFFUSE.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.diffuse[0], true);\n                        dataView.setFloat32(offset + 4, material.diffuse[1], true);\n                        dataView.setFloat32(offset + 8, material.diffuse[2], true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].SPECULAR.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.specular[0], true);\n                        dataView.setFloat32(offset + 4, material.specular[1], true);\n                        dataView.setFloat32(offset + 8, material.specular[2], true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].SPECULAR_EXPONENT.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.specularExponent, true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].EMISSIVE.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.emissive[0], true);\n                        dataView.setFloat32(offset + 4, material.emissive[1], true);\n                        dataView.setFloat32(offset + 8, material.emissive[2], true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].TRANSMISSION_FILTER.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.transmissionFilter[0], true);\n                        dataView.setFloat32(offset + 4, material.transmissionFilter[1], true);\n                        dataView.setFloat32(offset + 8, material.transmissionFilter[2], true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].DISSOLVE.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.dissolve, true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].ILLUMINATION.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setInt16(offset, material.illumination, true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].REFRACTION_INDEX.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.refractionIndex, true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].SHARPNESS.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setFloat32(offset, material.sharpness, true);\n                        break;\n                    }\n                    case _layout__WEBPACK_IMPORTED_MODULE_0__["Layout"].ANTI_ALIASING.key: {\n                        const materialIndex = this.vertexMaterialIndices[i];\n                        const material = this.materialsByIndex[materialIndex];\n                        if (!material) {\n                            console.warn(\'Material "\' +\n                                this.materialNames[materialIndex] +\n                                \'" not found in mesh. Did you forget to call addMaterialLibrary(...)?"\');\n                            break;\n                        }\n                        dataView.setInt16(offset, material.antiAliasing ? 1 : 0, true);\n                        break;\n                    }\n                }\n            }\n        }\n        return buffer;\n    }\n    makeIndexBufferData() {\n        const buffer = new Uint16Array(this.indices);\n        buffer.numItems = this.indices.length;\n        return buffer;\n    }\n    addMaterialLibrary(mtl) {\n        for (const name in mtl.materials) {\n            if (!(name in this.materialIndices)) {\n                // This material is not referenced by the mesh\n                continue;\n            }\n            const material = mtl.materials[name];\n            // Find the material index for this material\n            const materialIndex = this.materialIndices[material.name];\n            // Put the material into the materialsByIndex object at the right\n            // spot as determined when the obj file was parsed\n            this.materialsByIndex[materialIndex] = material;\n        }\n    }\n}\n\n\n//# sourceURL=webpack://OBJ/./src/mesh.ts?')},"./src/utils.ts":
/*!**********************!*\
  !*** ./src/utils.ts ***!
  \**********************/
/*! exports provided: downloadModels, downloadMeshes, initMeshBuffers, deleteMeshBuffers */function(module,__webpack_exports__,__webpack_require__){"use strict";eval('__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "downloadModels", function() { return downloadModels; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "downloadMeshes", function() { return downloadMeshes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "initMeshBuffers", function() { return initMeshBuffers; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "deleteMeshBuffers", function() { return deleteMeshBuffers; });\n/* harmony import */ var _mesh__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./mesh */ "./src/mesh.ts");\n/* harmony import */ var _material__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./material */ "./src/material.ts");\n\n\nfunction downloadMtlTextures(mtl, root) {\n    const mapAttributes = [\n        "mapDiffuse",\n        "mapAmbient",\n        "mapSpecular",\n        "mapDissolve",\n        "mapBump",\n        "mapDisplacement",\n        "mapDecal",\n        "mapEmissive",\n    ];\n    if (!root.endsWith("/")) {\n        root += "/";\n    }\n    const textures = [];\n    for (const materialName in mtl.materials) {\n        if (!mtl.materials.hasOwnProperty(materialName)) {\n            continue;\n        }\n        const material = mtl.materials[materialName];\n        for (const attr of mapAttributes) {\n            const mapData = material[attr];\n            if (!mapData) {\n                continue;\n            }\n            const url = root + mapData.filename;\n            textures.push(fetch(url)\n                .then(response => {\n                if (!response.ok) {\n                    throw new Error();\n                }\n                return response.blob();\n            })\n                .then(function (data) {\n                const image = new Image();\n                image.src = URL.createObjectURL(data);\n                mapData.texture = image;\n                return new Promise(resolve => (image.onload = resolve));\n            })\n                .catch(() => {\n                console.error(`Unable to download texture: ${url}`);\n            }));\n        }\n    }\n    return Promise.all(textures);\n}\nfunction getMtl(modelOptions) {\n    if (!(typeof modelOptions.mtl === "string")) {\n        return modelOptions.obj.replace(/\\.obj$/, ".mtl");\n    }\n    return modelOptions.mtl;\n}\n/**\n * Accepts a list of model request objects and returns a Promise that\n * resolves when all models have been downloaded and parsed.\n *\n * The list of model objects follow this interface:\n * {\n *  obj: \'path/to/model.obj\',\n *  mtl: true | \'path/to/model.mtl\',\n *  downloadMtlTextures: true | false\n *  mtlTextureRoot: \'/models/suzanne/maps\'\n *  name: \'suzanne\'\n * }\n *\n * The `obj` attribute is required and should be the path to the\n * model\'s .obj file relative to the current repo (absolute URLs are\n * suggested).\n *\n * The `mtl` attribute is optional and can either be a boolean or\n * a path to the model\'s .mtl file relative to the current URL. If\n * the value is `true`, then the path and basename given for the `obj`\n * attribute is used replacing the .obj suffix for .mtl\n * E.g.: {obj: \'models/foo.obj\', mtl: true} would search for \'models/foo.mtl\'\n *\n * The `name` attribute is optional and is a human friendly name to be\n * included with the parsed OBJ and MTL files. If not given, the base .obj\n * filename will be used.\n *\n * The `downloadMtlTextures` attribute is a flag for automatically downloading\n * any images found in the MTL file and attaching them to each Material\n * created from that file. For example, if material.mapDiffuse is set (there\n * was data in the MTL file), then material.mapDiffuse.texture will contain\n * the downloaded image. This option defaults to `true`. By default, the MTL\'s\n * URL will be used to determine the location of the images.\n *\n * The `mtlTextureRoot` attribute is optional and should point to the location\n * on the server that this MTL\'s texture files are located. The default is to\n * use the MTL file\'s location.\n *\n * @returns {Promise} the result of downloading the given list of models. The\n * promise will resolve with an object whose keys are the names of the models\n * and the value is its Mesh object. Each Mesh object will automatically\n * have its addMaterialLibrary() method called to set the given MTL data (if given).\n */\nfunction downloadModels(models) {\n    const finished = [];\n    for (const model of models) {\n        if (!model.obj) {\n            throw new Error(\'"obj" attribute of model object not set. The .obj file is required to be set \' +\n                "in order to use downloadModels()");\n        }\n        const options = {\n            indicesPerMaterial: !!model.indicesPerMaterial,\n            calcTangentsAndBitangents: !!model.calcTangentsAndBitangents,\n        };\n        // if the name is not provided, dervive it from the given OBJ\n        let name = model.name;\n        if (!name) {\n            const parts = model.obj.split("/");\n            name = parts[parts.length - 1].replace(".obj", "");\n        }\n        const namePromise = Promise.resolve(name);\n        const meshPromise = fetch(model.obj)\n            .then(response => response.text())\n            .then(data => {\n            return new _mesh__WEBPACK_IMPORTED_MODULE_0__["default"](data, options);\n        });\n        let mtlPromise;\n        // Download MaterialLibrary file?\n        if (model.mtl) {\n            const mtl = getMtl(model);\n            mtlPromise = fetch(mtl)\n                .then(response => response.text())\n                .then((data) => {\n                const material = new _material__WEBPACK_IMPORTED_MODULE_1__["MaterialLibrary"](data);\n                if (model.downloadMtlTextures !== false) {\n                    let root = model.mtlTextureRoot;\n                    if (!root) {\n                        // get the directory of the MTL file as default\n                        root = mtl.substr(0, mtl.lastIndexOf("/"));\n                    }\n                    // downloadMtlTextures returns a Promise that\n                    // is resolved once all of the images it\n                    // contains are downloaded. These are then\n                    // attached to the map data objects\n                    return Promise.all([Promise.resolve(material), downloadMtlTextures(material, root)]);\n                }\n                return Promise.all([Promise.resolve(material), undefined]);\n            })\n                .then((value) => {\n                return value[0];\n            });\n        }\n        const parsed = [namePromise, meshPromise, mtlPromise];\n        finished.push(Promise.all(parsed));\n    }\n    return Promise.all(finished).then(ms => {\n        // the "finished" promise is a list of name, Mesh instance,\n        // and MaterialLibary instance. This unpacks and returns an\n        // object mapping name to Mesh (Mesh points to MTL).\n        const models = {};\n        for (const model of ms) {\n            const [name, mesh, mtl] = model;\n            mesh.name = name;\n            if (mtl) {\n                mesh.addMaterialLibrary(mtl);\n            }\n            models[name] = mesh;\n        }\n        return models;\n    });\n}\n/**\n * Takes in an object of `mesh_name`, `\'/url/to/OBJ/file\'` pairs and a callback\n * function. Each OBJ file will be ajaxed in and automatically converted to\n * an OBJ.Mesh. When all files have successfully downloaded the callback\n * function provided will be called and passed in an object containing\n * the newly created meshes.\n *\n * **Note:** In order to use this function as a way to download meshes, a\n * webserver of some sort must be used.\n *\n * @param {Object} nameAndAttrs an object where the key is the name of the mesh and the value is the url to that mesh\'s OBJ file\n *\n * @param {Function} completionCallback should contain a function that will take one parameter: an object array where the keys will be the unique object name and the value will be a Mesh object\n *\n * @param {Object} meshes In case other meshes are loaded separately or if a previously declared variable is desired to be used, pass in a (possibly empty) json object of the pattern: { \'<mesh_name>\': OBJ.Mesh }\n *\n */\nfunction downloadMeshes(nameAndURLs, completionCallback, meshes) {\n    if (meshes === undefined) {\n        meshes = {};\n    }\n    const completed = [];\n    for (const mesh_name in nameAndURLs) {\n        if (!nameAndURLs.hasOwnProperty(mesh_name)) {\n            continue;\n        }\n        const url = nameAndURLs[mesh_name];\n        completed.push(fetch(url)\n            .then(response => response.text())\n            .then(data => {\n            return [mesh_name, new _mesh__WEBPACK_IMPORTED_MODULE_0__["default"](data)];\n        }));\n    }\n    Promise.all(completed).then(ms => {\n        for (const [name, mesh] of ms) {\n            meshes[name] = mesh;\n        }\n        return completionCallback(meshes);\n    });\n}\nfunction _buildBuffer(gl, type, data, itemSize) {\n    const buffer = gl.createBuffer();\n    const arrayView = type === gl.ARRAY_BUFFER ? Float32Array : Uint16Array;\n    gl.bindBuffer(type, buffer);\n    gl.bufferData(type, new arrayView(data), gl.STATIC_DRAW);\n    buffer.itemSize = itemSize;\n    buffer.numItems = data.length / itemSize;\n    return buffer;\n}\n/**\n * Takes in the WebGL context and a Mesh, then creates and appends the buffers\n * to the mesh object as attributes.\n *\n * @param {WebGLRenderingContext} gl the `canvas.getContext(\'webgl\')` context instance\n * @param {Mesh} mesh a single `OBJ.Mesh` instance\n *\n * The newly created mesh attributes are:\n *\n * Attrbute | Description\n * :--- | ---\n * **normalBuffer**       |contains the model&#39;s Vertex Normals\n * normalBuffer.itemSize  |set to 3 items\n * normalBuffer.numItems  |the total number of vertex normals\n * |\n * **textureBuffer**      |contains the model&#39;s Texture Coordinates\n * textureBuffer.itemSize |set to 2 items\n * textureBuffer.numItems |the number of texture coordinates\n * |\n * **vertexBuffer**       |contains the model&#39;s Vertex Position Coordinates (does not include w)\n * vertexBuffer.itemSize  |set to 3 items\n * vertexBuffer.numItems  |the total number of vertices\n * |\n * **indexBuffer**        |contains the indices of the faces\n * indexBuffer.itemSize   |is set to 1\n * indexBuffer.numItems   |the total number of indices\n *\n * A simple example (a lot of steps are missing, so don\'t copy and paste):\n *\n *     const gl   = canvas.getContext(\'webgl\'),\n *         mesh = OBJ.Mesh(obj_file_data);\n *     // compile the shaders and create a shader program\n *     const shaderProgram = gl.createProgram();\n *     // compilation stuff here\n *     ...\n *     // make sure you have vertex, vertex normal, and texture coordinate\n *     // attributes located in your shaders and attach them to the shader program\n *     shaderProgram.vertexPositionAttribute = gl.getAttribLocation(shaderProgram, "aVertexPosition");\n *     gl.enableVertexAttribArray(shaderProgram.vertexPositionAttribute);\n *\n *     shaderProgram.vertexNormalAttribute = gl.getAttribLocation(shaderProgram, "aVertexNormal");\n *     gl.enableVertexAttribArray(shaderProgram.vertexNormalAttribute);\n *\n *     shaderProgram.textureCoordAttribute = gl.getAttribLocation(shaderProgram, "aTextureCoord");\n *     gl.enableVertexAttribArray(shaderProgram.textureCoordAttribute);\n *\n *     // create and initialize the vertex, vertex normal, and texture coordinate buffers\n *     // and save on to the mesh object\n *     OBJ.initMeshBuffers(gl, mesh);\n *\n *     // now to render the mesh\n *     gl.bindBuffer(gl.ARRAY_BUFFER, mesh.vertexBuffer);\n *     gl.vertexAttribPointer(shaderProgram.vertexPositionAttribute, mesh.vertexBuffer.itemSize, gl.FLOAT, false, 0, 0);\n *     // it\'s possible that the mesh doesn\'t contain\n *     // any texture coordinates (e.g. suzanne.obj in the development branch).\n *     // in this case, the texture vertexAttribArray will need to be disabled\n *     // before the call to drawElements\n *     if(!mesh.textures.length){\n *       gl.disableVertexAttribArray(shaderProgram.textureCoordAttribute);\n *     }\n *     else{\n *       // if the texture vertexAttribArray has been previously\n *       // disabled, then it needs to be re-enabled\n *       gl.enableVertexAttribArray(shaderProgram.textureCoordAttribute);\n *       gl.bindBuffer(gl.ARRAY_BUFFER, mesh.textureBuffer);\n *       gl.vertexAttribPointer(shaderProgram.textureCoordAttribute, mesh.textureBuffer.itemSize, gl.FLOAT, false, 0, 0);\n *     }\n *\n *     gl.bindBuffer(gl.ARRAY_BUFFER, mesh.normalBuffer);\n *     gl.vertexAttribPointer(shaderProgram.vertexNormalAttribute, mesh.normalBuffer.itemSize, gl.FLOAT, false, 0, 0);\n *\n *     gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, model.mesh.indexBuffer);\n *     gl.drawElements(gl.TRIANGLES, model.mesh.indexBuffer.numItems, gl.UNSIGNED_SHORT, 0);\n */\nfunction initMeshBuffers(gl, mesh) {\n    mesh.normalBuffer = _buildBuffer(gl, gl.ARRAY_BUFFER, mesh.vertexNormals, 3);\n    mesh.textureBuffer = _buildBuffer(gl, gl.ARRAY_BUFFER, mesh.textures, mesh.textureStride);\n    mesh.vertexBuffer = _buildBuffer(gl, gl.ARRAY_BUFFER, mesh.vertices, 3);\n    mesh.indexBuffer = _buildBuffer(gl, gl.ELEMENT_ARRAY_BUFFER, mesh.indices, 1);\n    return mesh;\n}\nfunction deleteMeshBuffers(gl, mesh) {\n    gl.deleteBuffer(mesh.normalBuffer);\n    gl.deleteBuffer(mesh.textureBuffer);\n    gl.deleteBuffer(mesh.vertexBuffer);\n    gl.deleteBuffer(mesh.indexBuffer);\n}\n\n\n//# sourceURL=webpack://OBJ/./src/utils.ts?')},0:
/*!****************************!*\
  !*** multi ./src/index.ts ***!
  \****************************/
/*! no static exports found */function(module,exports,__webpack_require__){eval('module.exports = __webpack_require__(/*! /home/aaron/google_drive/projects/webgl-obj-loader/src/index.ts */"./src/index.ts");\n\n\n//# sourceURL=webpack://OBJ/multi_./src/index.ts?')}})},module.exports=t()},function(e,t){e.exports=function(){var e=new Float32Array(16);return e[0]=1,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=1,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=1,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e){var t=new Float32Array(16);return t[0]=e[0],t[1]=e[1],t[2]=e[2],t[3]=e[3],t[4]=e[4],t[5]=e[5],t[6]=e[6],t[7]=e[7],t[8]=e[8],t[9]=e[9],t[10]=e[10],t[11]=e[11],t[12]=e[12],t[13]=e[13],t[14]=e[14],t[15]=e[15],t}},function(e,t){e.exports=function(e,t){return e[0]=t[0],e[1]=t[1],e[2]=t[2],e[3]=t[3],e[4]=t[4],e[5]=t[5],e[6]=t[6],e[7]=t[7],e[8]=t[8],e[9]=t[9],e[10]=t[10],e[11]=t[11],e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15],e}},function(e,t){e.exports=function(e,t){if(e===t){var n=t[1],r=t[2],o=t[3],a=t[6],i=t[7],s=t[11];e[1]=t[4],e[2]=t[8],e[3]=t[12],e[4]=n,e[6]=t[9],e[7]=t[13],e[8]=r,e[9]=a,e[11]=t[14],e[12]=o,e[13]=i,e[14]=s}else e[0]=t[0],e[1]=t[4],e[2]=t[8],e[3]=t[12],e[4]=t[1],e[5]=t[5],e[6]=t[9],e[7]=t[13],e[8]=t[2],e[9]=t[6],e[10]=t[10],e[11]=t[14],e[12]=t[3],e[13]=t[7],e[14]=t[11],e[15]=t[15];return e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=t[3],i=t[4],s=t[5],l=t[6],c=t[7],u=t[8],d=t[9],f=t[10],h=t[11],m=t[12],p=t[13],_=t[14],v=t[15],g=n*s-r*i,S=n*l-o*i,x=n*c-a*i,b=r*l-o*s,y=r*c-a*s,w=o*c-a*l,T=u*p-d*m,E=u*_-f*m,A=u*v-h*m,P=d*_-f*p,M=d*v-h*p,C=f*v-h*_,O=g*C-S*M+x*P+b*A-y*E+w*T;if(!O)return null;return O=1/O,e[0]=(s*C-l*M+c*P)*O,e[1]=(o*M-r*C-a*P)*O,e[2]=(p*w-_*y+v*b)*O,e[3]=(f*y-d*w-h*b)*O,e[4]=(l*A-i*C-c*E)*O,e[5]=(n*C-o*A+a*E)*O,e[6]=(_*x-m*w-v*S)*O,e[7]=(u*w-f*x+h*S)*O,e[8]=(i*M-s*A+c*T)*O,e[9]=(r*A-n*M-a*T)*O,e[10]=(m*y-p*x+v*g)*O,e[11]=(d*x-u*y-h*g)*O,e[12]=(s*E-i*P-l*T)*O,e[13]=(n*P-r*E+o*T)*O,e[14]=(p*S-m*b-_*g)*O,e[15]=(u*b-d*S+f*g)*O,e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=t[3],i=t[4],s=t[5],l=t[6],c=t[7],u=t[8],d=t[9],f=t[10],h=t[11],m=t[12],p=t[13],_=t[14],v=t[15];return e[0]=s*(f*v-h*_)-d*(l*v-c*_)+p*(l*h-c*f),e[1]=-(r*(f*v-h*_)-d*(o*v-a*_)+p*(o*h-a*f)),e[2]=r*(l*v-c*_)-s*(o*v-a*_)+p*(o*c-a*l),e[3]=-(r*(l*h-c*f)-s*(o*h-a*f)+d*(o*c-a*l)),e[4]=-(i*(f*v-h*_)-u*(l*v-c*_)+m*(l*h-c*f)),e[5]=n*(f*v-h*_)-u*(o*v-a*_)+m*(o*h-a*f),e[6]=-(n*(l*v-c*_)-i*(o*v-a*_)+m*(o*c-a*l)),e[7]=n*(l*h-c*f)-i*(o*h-a*f)+u*(o*c-a*l),e[8]=i*(d*v-h*p)-u*(s*v-c*p)+m*(s*h-c*d),e[9]=-(n*(d*v-h*p)-u*(r*v-a*p)+m*(r*h-a*d)),e[10]=n*(s*v-c*p)-i*(r*v-a*p)+m*(r*c-a*s),e[11]=-(n*(s*h-c*d)-i*(r*h-a*d)+u*(r*c-a*s)),e[12]=-(i*(d*_-f*p)-u*(s*_-l*p)+m*(s*f-l*d)),e[13]=n*(d*_-f*p)-u*(r*_-o*p)+m*(r*f-o*d),e[14]=-(n*(s*_-l*p)-i*(r*_-o*p)+m*(r*l-o*s)),e[15]=n*(s*f-l*d)-i*(r*f-o*d)+u*(r*l-o*s),e}},function(e,t){e.exports=function(e){var t=e[0],n=e[1],r=e[2],o=e[3],a=e[4],i=e[5],s=e[6],l=e[7],c=e[8],u=e[9],d=e[10],f=e[11],h=e[12],m=e[13],p=e[14],_=e[15];return(t*i-n*a)*(d*_-f*p)-(t*s-r*a)*(u*_-f*m)+(t*l-o*a)*(u*p-d*m)+(n*s-r*i)*(c*_-f*h)-(n*l-o*i)*(c*p-d*h)+(r*l-o*s)*(c*m-u*h)}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=t[3],s=t[4],l=t[5],c=t[6],u=t[7],d=t[8],f=t[9],h=t[10],m=t[11],p=t[12],_=t[13],v=t[14],g=t[15],S=n[0],x=n[1],b=n[2],y=n[3];return e[0]=S*r+x*s+b*d+y*p,e[1]=S*o+x*l+b*f+y*_,e[2]=S*a+x*c+b*h+y*v,e[3]=S*i+x*u+b*m+y*g,S=n[4],x=n[5],b=n[6],y=n[7],e[4]=S*r+x*s+b*d+y*p,e[5]=S*o+x*l+b*f+y*_,e[6]=S*a+x*c+b*h+y*v,e[7]=S*i+x*u+b*m+y*g,S=n[8],x=n[9],b=n[10],y=n[11],e[8]=S*r+x*s+b*d+y*p,e[9]=S*o+x*l+b*f+y*_,e[10]=S*a+x*c+b*h+y*v,e[11]=S*i+x*u+b*m+y*g,S=n[12],x=n[13],b=n[14],y=n[15],e[12]=S*r+x*s+b*d+y*p,e[13]=S*o+x*l+b*f+y*_,e[14]=S*a+x*c+b*h+y*v,e[15]=S*i+x*u+b*m+y*g,e}},function(e,t){e.exports=function(e,t,n){var r,o,a,i,s,l,c,u,d,f,h,m,p=n[0],_=n[1],v=n[2];t===e?(e[12]=t[0]*p+t[4]*_+t[8]*v+t[12],e[13]=t[1]*p+t[5]*_+t[9]*v+t[13],e[14]=t[2]*p+t[6]*_+t[10]*v+t[14],e[15]=t[3]*p+t[7]*_+t[11]*v+t[15]):(r=t[0],o=t[1],a=t[2],i=t[3],s=t[4],l=t[5],c=t[6],u=t[7],d=t[8],f=t[9],h=t[10],m=t[11],e[0]=r,e[1]=o,e[2]=a,e[3]=i,e[4]=s,e[5]=l,e[6]=c,e[7]=u,e[8]=d,e[9]=f,e[10]=h,e[11]=m,e[12]=r*p+s*_+d*v+t[12],e[13]=o*p+l*_+f*v+t[13],e[14]=a*p+c*_+h*v+t[14],e[15]=i*p+u*_+m*v+t[15]);return e}},function(e,t){e.exports=function(e,t,n){var r=n[0],o=n[1],a=n[2];return e[0]=t[0]*r,e[1]=t[1]*r,e[2]=t[2]*r,e[3]=t[3]*r,e[4]=t[4]*o,e[5]=t[5]*o,e[6]=t[6]*o,e[7]=t[7]*o,e[8]=t[8]*a,e[9]=t[9]*a,e[10]=t[10]*a,e[11]=t[11]*a,e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15],e}},function(e,t){e.exports=function(e,t,n,r){var o,a,i,s,l,c,u,d,f,h,m,p,_,v,g,S,x,b,y,w,T,E,A,P,M=r[0],C=r[1],O=r[2],R=Math.sqrt(M*M+C*C+O*O);if(Math.abs(R)<1e-6)return null;M*=R=1/R,C*=R,O*=R,o=Math.sin(n),a=Math.cos(n),i=1-a,s=t[0],l=t[1],c=t[2],u=t[3],d=t[4],f=t[5],h=t[6],m=t[7],p=t[8],_=t[9],v=t[10],g=t[11],S=M*M*i+a,x=C*M*i+O*o,b=O*M*i-C*o,y=M*C*i-O*o,w=C*C*i+a,T=O*C*i+M*o,E=M*O*i+C*o,A=C*O*i-M*o,P=O*O*i+a,e[0]=s*S+d*x+p*b,e[1]=l*S+f*x+_*b,e[2]=c*S+h*x+v*b,e[3]=u*S+m*x+g*b,e[4]=s*y+d*w+p*T,e[5]=l*y+f*w+_*T,e[6]=c*y+h*w+v*T,e[7]=u*y+m*w+g*T,e[8]=s*E+d*A+p*P,e[9]=l*E+f*A+_*P,e[10]=c*E+h*A+v*P,e[11]=u*E+m*A+g*P,t!==e&&(e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15]);return e}},function(e,t){e.exports=function(e,t,n){var r=Math.sin(n),o=Math.cos(n),a=t[4],i=t[5],s=t[6],l=t[7],c=t[8],u=t[9],d=t[10],f=t[11];t!==e&&(e[0]=t[0],e[1]=t[1],e[2]=t[2],e[3]=t[3],e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15]);return e[4]=a*o+c*r,e[5]=i*o+u*r,e[6]=s*o+d*r,e[7]=l*o+f*r,e[8]=c*o-a*r,e[9]=u*o-i*r,e[10]=d*o-s*r,e[11]=f*o-l*r,e}},function(e,t){e.exports=function(e,t,n){var r=Math.sin(n),o=Math.cos(n),a=t[0],i=t[1],s=t[2],l=t[3],c=t[8],u=t[9],d=t[10],f=t[11];t!==e&&(e[4]=t[4],e[5]=t[5],e[6]=t[6],e[7]=t[7],e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15]);return e[0]=a*o-c*r,e[1]=i*o-u*r,e[2]=s*o-d*r,e[3]=l*o-f*r,e[8]=a*r+c*o,e[9]=i*r+u*o,e[10]=s*r+d*o,e[11]=l*r+f*o,e}},function(e,t){e.exports=function(e,t,n){var r=Math.sin(n),o=Math.cos(n),a=t[0],i=t[1],s=t[2],l=t[3],c=t[4],u=t[5],d=t[6],f=t[7];t!==e&&(e[8]=t[8],e[9]=t[9],e[10]=t[10],e[11]=t[11],e[12]=t[12],e[13]=t[13],e[14]=t[14],e[15]=t[15]);return e[0]=a*o+c*r,e[1]=i*o+u*r,e[2]=s*o+d*r,e[3]=l*o+f*r,e[4]=c*o-a*r,e[5]=u*o-i*r,e[6]=d*o-s*r,e[7]=f*o-l*r,e}},function(e,t){e.exports=function(e,t,n){var r,o,a,i=n[0],s=n[1],l=n[2],c=Math.sqrt(i*i+s*s+l*l);if(Math.abs(c)<1e-6)return null;return i*=c=1/c,s*=c,l*=c,r=Math.sin(t),o=Math.cos(t),a=1-o,e[0]=i*i*a+o,e[1]=s*i*a+l*r,e[2]=l*i*a-s*r,e[3]=0,e[4]=i*s*a-l*r,e[5]=s*s*a+o,e[6]=l*s*a+i*r,e[7]=0,e[8]=i*l*a+s*r,e[9]=s*l*a-i*r,e[10]=l*l*a+o,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=t[3],s=r+r,l=o+o,c=a+a,u=r*s,d=r*l,f=r*c,h=o*l,m=o*c,p=a*c,_=i*s,v=i*l,g=i*c;return e[0]=1-(h+p),e[1]=d+g,e[2]=f-v,e[3]=0,e[4]=d-g,e[5]=1-(u+p),e[6]=m+_,e[7]=0,e[8]=f+v,e[9]=m-_,e[10]=1-(u+h),e[11]=0,e[12]=n[0],e[13]=n[1],e[14]=n[2],e[15]=1,e}},function(e,t){e.exports=function(e,t){return e[0]=t[0],e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=t[1],e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=t[2],e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t){return e[0]=1,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=1,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=1,e[11]=0,e[12]=t[0],e[13]=t[1],e[14]=t[2],e[15]=1,e}},function(e,t){e.exports=function(e,t){var n=Math.sin(t),r=Math.cos(t);return e[0]=1,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=r,e[6]=n,e[7]=0,e[8]=0,e[9]=-n,e[10]=r,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t){var n=Math.sin(t),r=Math.cos(t);return e[0]=r,e[1]=0,e[2]=-n,e[3]=0,e[4]=0,e[5]=1,e[6]=0,e[7]=0,e[8]=n,e[9]=0,e[10]=r,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t){var n=Math.sin(t),r=Math.cos(t);return e[0]=r,e[1]=n,e[2]=0,e[3]=0,e[4]=-n,e[5]=r,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=1,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=t[3],i=n+n,s=r+r,l=o+o,c=n*i,u=r*i,d=r*s,f=o*i,h=o*s,m=o*l,p=a*i,_=a*s,v=a*l;return e[0]=1-d-m,e[1]=u+v,e[2]=f-_,e[3]=0,e[4]=u-v,e[5]=1-c-m,e[6]=h+p,e[7]=0,e[8]=f+_,e[9]=h-p,e[10]=1-c-d,e[11]=0,e[12]=0,e[13]=0,e[14]=0,e[15]=1,e}},function(e,t){e.exports=function(e,t,n,r,o,a,i){var s=1/(n-t),l=1/(o-r),c=1/(a-i);return e[0]=2*a*s,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=2*a*l,e[6]=0,e[7]=0,e[8]=(n+t)*s,e[9]=(o+r)*l,e[10]=(i+a)*c,e[11]=-1,e[12]=0,e[13]=0,e[14]=i*a*2*c,e[15]=0,e}},function(e,t){e.exports=function(e,t,n,r,o){var a=1/Math.tan(t/2),i=1/(r-o);return e[0]=a/n,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=a,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=(o+r)*i,e[11]=-1,e[12]=0,e[13]=0,e[14]=2*o*r*i,e[15]=0,e}},function(e,t){e.exports=function(e,t,n,r){var o=Math.tan(t.upDegrees*Math.PI/180),a=Math.tan(t.downDegrees*Math.PI/180),i=Math.tan(t.leftDegrees*Math.PI/180),s=Math.tan(t.rightDegrees*Math.PI/180),l=2/(i+s),c=2/(o+a);return e[0]=l,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=c,e[6]=0,e[7]=0,e[8]=-(i-s)*l*.5,e[9]=(o-a)*c*.5,e[10]=r/(n-r),e[11]=-1,e[12]=0,e[13]=0,e[14]=r*n/(n-r),e[15]=0,e}},function(e,t){e.exports=function(e,t,n,r,o,a,i){var s=1/(t-n),l=1/(r-o),c=1/(a-i);return e[0]=-2*s,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=-2*l,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[10]=2*c,e[11]=0,e[12]=(t+n)*s,e[13]=(o+r)*l,e[14]=(i+a)*c,e[15]=1,e}},function(e,t,n){var r=n(16);e.exports=function(e,t,n,o){var a,i,s,l,c,u,d,f,h,m,p=t[0],_=t[1],v=t[2],g=o[0],S=o[1],x=o[2],b=n[0],y=n[1],w=n[2];if(Math.abs(p-b)<1e-6&&Math.abs(_-y)<1e-6&&Math.abs(v-w)<1e-6)return r(e);d=p-b,f=_-y,h=v-w,m=1/Math.sqrt(d*d+f*f+h*h),a=S*(h*=m)-x*(f*=m),i=x*(d*=m)-g*h,s=g*f-S*d,(m=Math.sqrt(a*a+i*i+s*s))?(a*=m=1/m,i*=m,s*=m):(a=0,i=0,s=0);l=f*s-h*i,c=h*a-d*s,u=d*i-f*a,(m=Math.sqrt(l*l+c*c+u*u))?(l*=m=1/m,c*=m,u*=m):(l=0,c=0,u=0);return e[0]=a,e[1]=l,e[2]=d,e[3]=0,e[4]=i,e[5]=c,e[6]=f,e[7]=0,e[8]=s,e[9]=u,e[10]=h,e[11]=0,e[12]=-(a*p+i*_+s*v),e[13]=-(l*p+c*_+u*v),e[14]=-(d*p+f*_+h*v),e[15]=1,e}},function(e,t){e.exports=function(e){return"mat4("+e[0]+", "+e[1]+", "+e[2]+", "+e[3]+", "+e[4]+", "+e[5]+", "+e[6]+", "+e[7]+", "+e[8]+", "+e[9]+", "+e[10]+", "+e[11]+", "+e[12]+", "+e[13]+", "+e[14]+", "+e[15]+")"}},function(e,t){e.exports=function(e){var t=new Float32Array(3);return t[0]=e[0],t[1]=e[1],t[2]=e[2],t}},function(e,t,n){e.exports=function(e,t){var n=r(e[0],e[1],e[2]),i=r(t[0],t[1],t[2]);o(n,n),o(i,i);var s=a(n,i);return s>1?0:Math.acos(s)};var r=n(19),o=n(8),a=n(9)},function(e,t){e.exports=function(e,t){return e[0]=t[0],e[1]=t[1],e[2]=t[2],e}},function(e,t){e.exports=function(e,t,n,r){return e[0]=t,e[1]=n,e[2]=r,e}},function(e,t,n){e.exports=function(e,t){var n=e[0],o=e[1],a=e[2],i=t[0],s=t[1],l=t[2];return Math.abs(n-i)<=r*Math.max(1,Math.abs(n),Math.abs(i))&&Math.abs(o-s)<=r*Math.max(1,Math.abs(o),Math.abs(s))&&Math.abs(a-l)<=r*Math.max(1,Math.abs(a),Math.abs(l))};var r=n(17)},function(e,t){e.exports=function(e,t){return e[0]===t[0]&&e[1]===t[1]&&e[2]===t[2]}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]+n[0],e[1]=t[1]+n[1],e[2]=t[2]+n[2],e}},function(e,t,n){e.exports=n(20)},function(e,t,n){e.exports=n(21)},function(e,t,n){e.exports=n(22)},function(e,t){e.exports=function(e,t,n){return e[0]=Math.min(t[0],n[0]),e[1]=Math.min(t[1],n[1]),e[2]=Math.min(t[2],n[2]),e}},function(e,t){e.exports=function(e,t,n){return e[0]=Math.max(t[0],n[0]),e[1]=Math.max(t[1],n[1]),e[2]=Math.max(t[2],n[2]),e}},function(e,t){e.exports=function(e,t){return e[0]=Math.floor(t[0]),e[1]=Math.floor(t[1]),e[2]=Math.floor(t[2]),e}},function(e,t){e.exports=function(e,t){return e[0]=Math.ceil(t[0]),e[1]=Math.ceil(t[1]),e[2]=Math.ceil(t[2]),e}},function(e,t){e.exports=function(e,t){return e[0]=Math.round(t[0]),e[1]=Math.round(t[1]),e[2]=Math.round(t[2]),e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n,e[1]=t[1]*n,e[2]=t[2]*n,e}},function(e,t){e.exports=function(e,t,n,r){return e[0]=t[0]+n[0]*r,e[1]=t[1]+n[1]*r,e[2]=t[2]+n[2]*r,e}},function(e,t,n){e.exports=n(23)},function(e,t,n){e.exports=n(24)},function(e,t,n){e.exports=n(10)},function(e,t,n){e.exports=n(25)},function(e,t){e.exports=function(e,t){return e[0]=-t[0],e[1]=-t[1],e[2]=-t[2],e}},function(e,t){e.exports=function(e,t){return e[0]=1/t[0],e[1]=1/t[1],e[2]=1/t[2],e}},function(e,t){e.exports=function(e,t,n,r){var o=t[0],a=t[1],i=t[2];return e[0]=o+r*(n[0]-o),e[1]=a+r*(n[1]-a),e[2]=i+r*(n[2]-i),e}},function(e,t){e.exports=function(e,t){t=t||1;var n=2*Math.random()*Math.PI,r=2*Math.random()-1,o=Math.sqrt(1-r*r)*t;return e[0]=Math.cos(n)*o,e[1]=Math.sin(n)*o,e[2]=r*t,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=n[3]*r+n[7]*o+n[11]*a+n[15];return i=i||1,e[0]=(n[0]*r+n[4]*o+n[8]*a+n[12])/i,e[1]=(n[1]*r+n[5]*o+n[9]*a+n[13])/i,e[2]=(n[2]*r+n[6]*o+n[10]*a+n[14])/i,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2];return e[0]=r*n[0]+o*n[3]+a*n[6],e[1]=r*n[1]+o*n[4]+a*n[7],e[2]=r*n[2]+o*n[5]+a*n[8],e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=n[0],s=n[1],l=n[2],c=n[3],u=c*r+s*a-l*o,d=c*o+l*r-i*a,f=c*a+i*o-s*r,h=-i*r-s*o-l*a;return e[0]=u*c+h*-i+d*-l-f*-s,e[1]=d*c+h*-s+f*-i-u*-l,e[2]=f*c+h*-l+u*-s-d*-i,e}},function(e,t){e.exports=function(e,t,n,r){var o=n[1],a=n[2],i=t[1]-o,s=t[2]-a,l=Math.sin(r),c=Math.cos(r);return e[0]=t[0],e[1]=o+i*c-s*l,e[2]=a+i*l+s*c,e}},function(e,t){e.exports=function(e,t,n,r){var o=n[0],a=n[2],i=t[0]-o,s=t[2]-a,l=Math.sin(r),c=Math.cos(r);return e[0]=o+s*l+i*c,e[1]=t[1],e[2]=a+s*c-i*l,e}},function(e,t){e.exports=function(e,t,n,r){var o=n[0],a=n[1],i=t[0]-o,s=t[1]-a,l=Math.sin(r),c=Math.cos(r);return e[0]=o+i*c-s*l,e[1]=a+i*l+s*c,e[2]=t[2],e}},function(e,t,n){e.exports=function(e,t,n,o,a,i){var s,l;t||(t=3);n||(n=0);l=o?Math.min(o*t+n,e.length):e.length;for(s=n;s<l;s+=t)r[0]=e[s],r[1]=e[s+1],r[2]=e[s+2],a(r,r,i),e[s]=r[0],e[s+1]=r[1],e[s+2]=r[2];return e};var r=n(18)()},function(e,t){e.exports=function(e){var t=new Float32Array(2);return t[0]=e[0],t[1]=e[1],t}},function(e,t){e.exports=function(e,t){var n=new Float32Array(2);return n[0]=e,n[1]=t,n}},function(e,t){e.exports=function(e,t){return e[0]=t[0],e[1]=t[1],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t,e[1]=n,e}},function(e,t,n){e.exports=function(e,t){var n=e[0],o=e[1],a=t[0],i=t[1];return Math.abs(n-a)<=r*Math.max(1,Math.abs(n),Math.abs(a))&&Math.abs(o-i)<=r*Math.max(1,Math.abs(o),Math.abs(i))};var r=n(27)},function(e,t){e.exports=function(e,t){return e[0]===t[0]&&e[1]===t[1]}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]+n[0],e[1]=t[1]+n[1],e}},function(e,t,n){e.exports=n(29)},function(e,t,n){e.exports=n(30)},function(e,t,n){e.exports=n(31)},function(e,t){e.exports=function(e,t){return e[0]=1/t[0],e[1]=1/t[1],e}},function(e,t){e.exports=function(e,t,n){return e[0]=Math.min(t[0],n[0]),e[1]=Math.min(t[1],n[1]),e}},function(e,t){e.exports=function(e,t,n){return e[0]=Math.max(t[0],n[0]),e[1]=Math.max(t[1],n[1]),e}},function(e,t){e.exports=function(e,t,n){var r=Math.cos(n),o=Math.sin(n),a=t[0],i=t[1];return e[0]=a*r-i*o,e[1]=a*o+i*r,e}},function(e,t){e.exports=function(e,t){return e[0]=Math.floor(t[0]),e[1]=Math.floor(t[1]),e}},function(e,t){e.exports=function(e,t){return e[0]=Math.ceil(t[0]),e[1]=Math.ceil(t[1]),e}},function(e,t){e.exports=function(e,t){return e[0]=Math.round(t[0]),e[1]=Math.round(t[1]),e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n,e[1]=t[1]*n,e}},function(e,t){e.exports=function(e,t,n,r){return e[0]=t[0]+n[0]*r,e[1]=t[1]+n[1]*r,e}},function(e,t,n){e.exports=n(32)},function(e,t,n){e.exports=n(33)},function(e,t,n){e.exports=n(34)},function(e,t,n){e.exports=n(35)},function(e,t){e.exports=function(e,t){return e[0]=-t[0],e[1]=-t[1],e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=n*n+r*r;o>0&&(o=1/Math.sqrt(o),e[0]=t[0]*o,e[1]=t[1]*o);return e}},function(e,t){e.exports=function(e,t){return e[0]*t[0]+e[1]*t[1]}},function(e,t){e.exports=function(e,t,n){var r=t[0]*n[1]-t[1]*n[0];return e[0]=e[1]=0,e[2]=r,e}},function(e,t){e.exports=function(e,t,n,r){var o=t[0],a=t[1];return e[0]=o+r*(n[0]-o),e[1]=a+r*(n[1]-a),e}},function(e,t){e.exports=function(e,t){t=t||1;var n=2*Math.random()*Math.PI;return e[0]=Math.cos(n)*t,e[1]=Math.sin(n)*t,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1];return e[0]=n[0]*r+n[2]*o,e[1]=n[1]*r+n[3]*o,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1];return e[0]=n[0]*r+n[2]*o+n[4],e[1]=n[1]*r+n[3]*o+n[5],e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1];return e[0]=n[0]*r+n[3]*o+n[6],e[1]=n[1]*r+n[4]*o+n[7],e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1];return e[0]=n[0]*r+n[4]*o+n[12],e[1]=n[1]*r+n[5]*o+n[13],e}},function(e,t,n){e.exports=function(e,t,n,o,a,i){var s,l;t||(t=2);n||(n=0);l=o?Math.min(o*t+n,e.length):e.length;for(s=n;s<l;s+=t)r[0]=e[s],r[1]=e[s+1],a(r,r,i),e[s]=r[0],e[s+1]=r[1];return e};var r=n(28)()},function(e,t){e.exports=function(e,t,n){var r=t[0]*t[0]+t[1]*t[1];if(r>n*n){var o=Math.sqrt(r);e[0]=t[0]/o*n,e[1]=t[1]/o*n}else e[0]=t[0],e[1]=t[1];return e}},function(e,t){e.exports=function(){var e=new Float32Array(4);return e[0]=0,e[1]=0,e[2]=0,e[3]=0,e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]-n[0],e[1]=t[1]-n[1],e[2]=t[2]-n[2],e[3]=t[3]-n[3],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]*n[0],e[1]=t[1]*n[1],e[2]=t[2]*n[2],e[3]=t[3]*n[3],e}},function(e,t){e.exports=function(e,t,n){return e[0]=t[0]/n[0],e[1]=t[1]/n[1],e[2]=t[2]/n[2],e[3]=t[3]/n[3],e}},function(e,t){e.exports=function(e,t,n){return e[0]=Math.min(t[0],n[0]),e[1]=Math.min(t[1],n[1]),e[2]=Math.min(t[2],n[2]),e[3]=Math.min(t[3],n[3]),e}},function(e,t){e.exports=function(e,t,n){return e[0]=Math.max(t[0],n[0]),e[1]=Math.max(t[1],n[1]),e[2]=Math.max(t[2],n[2]),e[3]=Math.max(t[3],n[3]),e}},function(e,t){e.exports=function(e,t,n,r){return e[0]=t[0]+n[0]*r,e[1]=t[1]+n[1]*r,e[2]=t[2]+n[2]*r,e[3]=t[3]+n[3]*r,e}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1],o=t[2]-e[2],a=t[3]-e[3];return Math.sqrt(n*n+r*r+o*o+a*a)}},function(e,t){e.exports=function(e,t){var n=t[0]-e[0],r=t[1]-e[1],o=t[2]-e[2],a=t[3]-e[3];return n*n+r*r+o*o+a*a}},function(e,t){e.exports=function(e,t){return e[0]=-t[0],e[1]=-t[1],e[2]=-t[2],e[3]=-t[3],e}},function(e,t){e.exports=function(e,t){return e[0]=1/t[0],e[1]=1/t[1],e[2]=1/t[2],e[3]=1/t[3],e}},function(e,t,n){var r=n(12),o=n(11);e.exports=function(e,t){return t=t||1,e[0]=Math.random(),e[1]=Math.random(),e[2]=Math.random(),e[3]=Math.random(),r(e,e),o(e,e,t),e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=t[3];return e[0]=n[0]*r+n[4]*o+n[8]*a+n[12]*i,e[1]=n[1]*r+n[5]*o+n[9]*a+n[13]*i,e[2]=n[2]*r+n[6]*o+n[10]*a+n[14]*i,e[3]=n[3]*r+n[7]*o+n[11]*a+n[15]*i,e}},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=n[0],s=n[1],l=n[2],c=n[3],u=c*r+s*a-l*o,d=c*o+l*r-i*a,f=c*a+i*o-s*r,h=-i*r-s*o-l*a;return e[0]=u*c+h*-i+d*-l-f*-s,e[1]=d*c+h*-s+f*-i-u*-l,e[2]=f*c+h*-l+u*-s-d*-i,e[3]=t[3],e}},function(e,t){var n;n=function(){return this}();try{n=n||new Function("return this")()}catch(e){"object"==typeof window&&(n=window)}e.exports=n},function(e,t,n){e.exports=n(40)},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2];return e[0]=n,e[1]=r,e[2]=o,e[3]=Math.sqrt(Math.abs(1-n*n-r*r-o*o)),e}},function(e,t,n){e.exports=n(36)},function(e,t){e.exports=function(e,t){return e[0]=-t[0],e[1]=-t[1],e[2]=-t[2],e[3]=t[3],e}},function(e,t,n){e.exports=n(38)},function(e,t){e.exports=function(){var e=new Float32Array(4);return e[0]=0,e[1]=0,e[2]=0,e[3]=1,e}},function(e,t,n){e.exports=n(43)},function(e,t,n){e.exports=n(37)},function(e,t){e.exports=function(e){return e[0]=0,e[1]=0,e[2]=0,e[3]=1,e}},function(e,t){e.exports=function(e,t){var n=t[0],r=t[1],o=t[2],a=t[3],i=n*n+r*r+o*o+a*a,s=i?1/i:0;return e[0]=-n*s,e[1]=-r*s,e[2]=-o*s,e[3]=a*s,e}},function(e,t,n){e.exports=n(41)},function(e,t,n){e.exports=n(44)},function(e,t){e.exports=function(e,t,n){var r=t[0],o=t[1],a=t[2],i=t[3],s=n[0],l=n[1],c=n[2],u=n[3];return e[0]=r*u+i*s+o*c-a*l,e[1]=o*u+i*l+a*s-r*c,e[2]=a*u+i*c+r*l-o*s,e[3]=i*u-r*s-o*l-a*c,e}},function(e,t){e.exports=function(e,t,n){n*=.5;var r=t[0],o=t[1],a=t[2],i=t[3],s=Math.sin(n),l=Math.cos(n);return e[0]=r*l+i*s,e[1]=o*l+a*s,e[2]=a*l-o*s,e[3]=i*l-r*s,e}},function(e,t){e.exports=function(e,t,n){n*=.5;var r=t[0],o=t[1],a=t[2],i=t[3],s=Math.sin(n),l=Math.cos(n);return e[0]=r*l-a*s,e[1]=o*l+i*s,e[2]=a*l+r*s,e[3]=i*l-o*s,e}},function(e,t){e.exports=function(e,t,n){n*=.5;var r=t[0],o=t[1],a=t[2],i=t[3],s=Math.sin(n),l=Math.cos(n);return e[0]=r*l+o*s,e[1]=o*l-r*s,e[2]=a*l+i*s,e[3]=i*l-a*s,e}},function(e,t,n){var r=n(9),o=n(26),a=n(10),i=n(8),s=n(13),l=n(47);e.exports=function(e,t,n){var f=r(t,n);return f<-.999999?(o(c,u,t),a(c)<1e-6&&o(c,d,t),i(c,c),l(e,c,Math.PI),e):f>.999999?(e[0]=0,e[1]=0,e[2]=0,e[3]=1,e):(o(c,t,n),e[0]=c[0],e[1]=c[1],e[2]=c[2],e[3]=1+f,s(e,e))};var c=[0,0,0],u=[1,0,0],d=[0,1,0]},function(e,t,n){e.exports=n(11)},function(e,t,n){e.exports=n(39)},function(e,t,n){var r=n(182),o=n(46),a=n(13);e.exports=function(e,t,n,r){return i[0]=n[0],i[3]=n[1],i[6]=n[2],i[1]=r[0],i[4]=r[1],i[7]=r[2],i[2]=-t[0],i[5]=-t[1],i[8]=-t[2],a(e,o(e,i))};var i=r()},function(e,t){e.exports=function(){var e=new Float32Array(9);return e[0]=1,e[1]=0,e[2]=0,e[3]=0,e[4]=1,e[5]=0,e[6]=0,e[7]=0,e[8]=1,e}},function(e,t,n){var r=n(48);e.exports=function(e,t,n,i,s,l){return r(o,t,s,l),r(a,n,i,l),r(e,o,a,2*l*(1-l)),e};var o=[0,0,0,1],a=[0,0,0,1]},function(e,t,n){e.exports=n(42)},function(e,t,n){var r;e.exports=((r=function(){function e(e){return o.appendChild(e.dom),e}function t(e){for(var t=0;t<o.children.length;t++)o.children[t].style.display=t===e?"block":"none";n=e}var n=0,o=document.createElement("div");o.style.cssText="position:fixed;top:0;left:0;cursor:pointer;opacity:0.9;z-index:10000",o.addEventListener("click",function(e){e.preventDefault(),t(++n%o.children.length)},!1);var a=(performance||Date).now(),i=a,s=0,l=e(new r.Panel("FPS","#0ff","#002")),c=e(new r.Panel("MS","#0f0","#020"));if(self.performance&&self.performance.memory)var u=e(new r.Panel("MB","#f08","#201"));return t(0),{REVISION:16,dom:o,addPanel:e,showPanel:t,begin:function(){a=(performance||Date).now()},end:function(){s++;var e=(performance||Date).now();if(c.update(e-a,200),e>i+1e3&&(l.update(1e3*s/(e-i),100),i=e,s=0,u)){var t=performance.memory;u.update(t.usedJSHeapSize/1048576,t.jsHeapSizeLimit/1048576)}return e},update:function(){a=this.end()},domElement:o,setMode:t}}).Panel=function(e,t,n){var r=1/0,o=0,a=Math.round,i=a(window.devicePixelRatio||1),s=80*i,l=48*i,c=3*i,u=2*i,d=3*i,f=15*i,h=74*i,m=30*i,p=document.createElement("canvas");p.width=s,p.height=l,p.style.cssText="width:80px;height:48px";var _=p.getContext("2d");return _.font="bold "+9*i+"px Helvetica,Arial,sans-serif",_.textBaseline="top",_.fillStyle=n,_.fillRect(0,0,s,l),_.fillStyle=t,_.fillText(e,c,u),_.fillRect(d,f,h,m),_.fillStyle=n,_.globalAlpha=.9,_.fillRect(d,f,h,m),{dom:p,update:function(l,v){r=Math.min(r,l),o=Math.max(o,l),_.fillStyle=n,_.globalAlpha=1,_.fillRect(0,0,s,f),_.fillStyle=t,_.fillText(a(l)+" "+e+" ("+a(r)+"-"+a(o)+")",c,u),_.drawImage(p,d+i,f,h-i,m,d,f,h-i,m),_.fillRect(d+h-i,f,i,m),_.fillStyle=n,_.globalAlpha=.9,_.fillRect(d+h-i,f,i,a((1-l/v)*m))}}},r)},function(e,t,n){e.exports=n.p+"b19d963fe4fda37a06bf423335734ef6.obj"},function(e,t,n){e.exports=n.p+"a787efdca624ff2cd7e6b8926466f70d.obj"},function(e,t,n){e.exports=n.p+"sintel_skin_diff-87d5f32cefe69e11182cf837e197c5b4.jpg"},function(e,t,n){e.exports=n.p+"sintel_skin_spec-dd9f97e79decb4f1d4edb709ccdb37d1.jpg"},function(e,t,n){e.exports=n.p+"sintel_hair_shadow-f0faf14d78e74f3c841c0a3fab619fd5.jpg"},function(e,t,n){e.exports=n.p+"sintel_eyeball_diff-8f7159d89e8307f4e13bc6906a185bb4.jpg"},function(e,t,n){e.exports=n.p+"39d79c3dc9083eff0e4d5426fe82728e.tfx"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\nuniform mat4 u_MVP;\r\n\r\nlayout(location=0) in vec3 position;\r\n\r\nvoid main() {\r\n  gl_Position = u_MVP * vec4(position, 1.0f);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\n\r\nlayout(location=0) in vec3 in_Position;\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n// https://github.com/Scthe/TressFX-OpenGL/blob/master/src/shaders/gl-tfx/lib/TressFXStrands.glsl\r\n\r\n#define TRESSFX_FLOAT_EPSILON 1e-7\r\n\r\n\r\n///////// uniforms\r\n\r\nuniform mat4 u_mMat;\r\nuniform mat4 u_vpMat;\r\nuniform vec3 u_cameraPosition;\r\nuniform vec2 u_viewportSize;\r\nuniform vec3 u_centerOfGravity;\r\n// data buffers\r\nuniform sampler2D u_vertexPositionsBuffer;\r\nuniform sampler2D u_vertexTangentsBuffer;\r\n// tfx params\r\nuniform int u_numVerticesPerStrand;\r\nuniform float u_thinTip;\r\nuniform float u_fiberRadius;\r\nuniform uint u_followHairs;\r\nuniform float u_followHairSpreadRoot;\r\nuniform float u_followHairSpreadTip;\r\n\r\nconst float EXPAND_PIXELS_FACTOR = 0.71;\r\n\r\n\r\n///////// END: uniforms\r\n\r\n\r\nivec2 getVertexPositionCoords(uint offset) {\r\n  uvec2 texSize = uvec2(textureSize(u_vertexPositionsBuffer, 0));\r\n  return ivec2(offset % texSize.x, offset / texSize.x);\r\n}\r\n\r\nvec2 safeNormalize(vec2 vec) {\r\n  float len = length(vec);\r\n  return len >= TRESSFX_FLOAT_EPSILON ? normalize(vec) : vec2(0, 0);\r\n}\r\n\r\nvec3 safeNormalize(vec3 vec) {\r\n  float len = length(vec);\r\n  return len >= TRESSFX_FLOAT_EPSILON ? normalize(vec) : vec3(0, 0, 0);\r\n}\r\n\r\n/** Returns 1.0 for root vertex, 0.0 for last vertex in strand and values betweeen for others */\r\nfloat getVertexInStrandPercentage (uint index) {\r\n  uint vertexId = index % uint(u_numVerticesPerStrand); // [0-32]\r\n  return 1.0 - (float(vertexId) / float(u_numVerticesPerStrand)); // [0-1]\r\n}\r\n\r\n\r\nstruct TressFXVertex {\r\n  vec4 position; // projected\r\n  vec4 positionWorldSpace;\r\n  vec3 normal;\r\n  vec3 tangent;\r\n  float vertexRootToTipFactor; // 1 := root, 0: = tip\r\n};\r\n\r\nstruct TressFXParams {\r\n  uint vertexId;\r\n  uint instanceId;\r\n  uint strandId;\r\n\r\n  vec3 eye;\r\n  mat4 modelMat;\r\n  mat4 viewProjMat;\r\n  vec2 viewportSize;\r\n\r\n  float thinTip;\r\n  float fiberRadius;\r\n  float followHairSpreadRoot;\r\n  float followHairSpreadTip;\r\n};\r\n\r\nTressFXParams createTfxParams() {\r\n  TressFXParams params;\r\n  params.vertexId = uint(gl_VertexID);\r\n  params.instanceId = uint(gl_InstanceID);\r\n  params.strandId = uint(gl_VertexID / 2 / u_numVerticesPerStrand);\r\n\r\n  params.eye = u_cameraPosition;\r\n  params.modelMat = u_mMat;\r\n  params.viewProjMat = u_vpMat;\r\n  params.viewportSize = u_viewportSize;\r\n\r\n  params.thinTip = u_thinTip;\r\n  params.fiberRadius = u_fiberRadius;\r\n  params.followHairSpreadRoot = u_followHairSpreadRoot;\r\n  params.followHairSpreadTip = u_followHairSpreadTip;\r\n\r\n  return params;\r\n}\r\n\r\n\r\nvec3 randomizeStrandPos(uint instanceId, uint strandId, uint rngFac) {\r\n  vec3 seed = vec3(\r\n    float(instanceId),\r\n    float(strandId),\r\n    float(rngFac) + float(instanceId / 2u) + float(instanceId / 3u)\r\n  );\r\n  vec3 v = hash(seed);\r\n  return to_neg1_1(normalize(v));\r\n}\r\n\r\nvec3 getFollowHairDisplacement (\r\n  TressFXParams params, float vertex_position, vec3 tangent\r\n) {\r\n  if (params.instanceId == 0u) {\r\n    // not required, but why not? It should stick in the middle of follow-hair group\r\n    return vec3(0.0);\r\n  }\r\n\r\n  vec3 rootOffset = randomizeStrandPos(params.instanceId, params.strandId, 1u);\r\n  vec3 tipOffset = randomizeStrandPos(params.instanceId, params.strandId, 2u);\r\n  rootOffset *= params.followHairSpreadRoot;\r\n  tipOffset *= params.followHairSpreadTip;\r\n  return mix(tipOffset, rootOffset, vertex_position);\r\n\r\n  /*\r\n  // TODO make this around normal, so the hair does stay near skull\r\n  vec3 offset = mix(tipOffset, rootOffset, vertex_position);\r\n  vec3 normal   = normalize(offset - tangent * dot(offset, tangent));\r\n  vec3 bitangent = cross(normal, tangent);\r\n\r\n  float offsetMod = mix(params.followHairSpreadTip, params.followHairSpreadRoot, vertex_position);\r\n  return bitangent * offsetMod;\r\n  // return bitangent * params.followHairSpreadRoot;\r\n  // return rootOffset * params.followHairSpreadRoot;\r\n  */\r\n}\r\n\r\n\r\nTressFXVertex getExpandedTressFXVert(TressFXParams params) {\r\n  // Access the current line segment\r\n  // We will move vertices left or right by hair thickness:\r\n  //   - odd vertices are moved left,\r\n  //   - even are moved right.\r\n  // And by 'left' and 'right' we mean according to normal&tangent.\r\n  // And by normal we mean (hair_pos - camera_pos)\r\n  uint index = params.vertexId / 2u;  // vertexId is actually the indexed vertex id when indexed triangles are used\r\n\r\n  // Get updated positions and tangents from simulation result\r\n  ivec2 vertexSamplePos = getVertexPositionCoords(index);\r\n  vec3 v = texelFetch(u_vertexPositionsBuffer, vertexSamplePos, 0).xyz;\r\n  vec3 t = texelFetch(u_vertexTangentsBuffer, vertexSamplePos, 0).xyz;\r\n  v = (params.modelMat * vec4(v, 1.0)).xyz; // transform to world space\r\n  t = normalize(t); // not needed for cross, but useful for debugging\r\n\r\n  // Get hair strand thickness\r\n  float vertex_position = getVertexInStrandPercentage(index); // 1 := root, 0 := tip\r\n  float ratio = mix(params.thinTip, 1.0, vertex_position);\r\n\r\n  v += getFollowHairDisplacement(params, vertex_position, t);\r\n\r\n  // Calculate right and projected right vectors\r\n  vec3 towardsCamera = safeNormalize(v - params.eye);\r\n  vec3 right = safeNormalize(cross(t, towardsCamera));\r\n\r\n  // debug\r\n  // v = v + t * (params.thinTip * 0.1);\r\n  // v = v + towardsCamera * (params.thinTip * 0.1);\r\n  // v = v + right * (params.thinTip * 0.1);\r\n\r\n  // Calculate the negative and positive offset screenspace positions\r\n  vec4 hairEdgePositions[2]; // 0 is for odd vertexId, 1 is positive even vertexId\r\n  vec3 thicknessVector = right * ratio * params.fiberRadius;\r\n  hairEdgePositions[0] = vec4(v - thicknessVector, 1.0); // position 'left'\r\n  hairEdgePositions[1] = vec4(v + thicknessVector, 1.0); // position 'right'\r\n\r\n  // Write output data\r\n  TressFXVertex result;\r\n\tbool isOdd = (params.vertexId & 0x01u) > 0u;\r\n  result.positionWorldSpace = (isOdd ? hairEdgePositions[0] : hairEdgePositions[1]); // may not be 100% accurate with fixes below\r\n  result.position = params.viewProjMat * result.positionWorldSpace;\r\n  result.tangent = t;\r\n  result.vertexRootToTipFactor = vertex_position;\r\n  // result.normal = towardsCamera; // ?! might as well.\r\n  // result.normal = normalize(result.positionWorldSpace.xyz - v);\r\n  result.normal = normalize(result.positionWorldSpace.xyz - u_centerOfGravity);\r\n\r\n  // some additional fixing\r\n  {\r\n    vec2 proj_right = (params.viewProjMat * vec4(right, 0)).xy;\r\n    proj_right = safeNormalize(proj_right);\r\n\r\n    float fDirIndex = isOdd ? -1.0 : 1.0;\r\n    vec4 tmp = vec4(proj_right * EXPAND_PIXELS_FACTOR / params.viewportSize.y, 0.0f, 0.0f);\r\n    float w = isOdd ? hairEdgePositions[0].w : hairEdgePositions[1].w;\r\n    result.position += fDirIndex * tmp * w;\r\n  }\r\n\r\n  return result;\r\n}\r\n\r\n// END TressFXStrands.glsl\r\n\r\n\r\n\r\nvoid main() {\r\n  TressFXParams tfxParams = createTfxParams();\r\n  TressFXVertex tressfxVert = getExpandedTressFXVert(tfxParams);\r\n\r\n  gl_Position = tressfxVert.position;\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\nuniform mat4 u_M;\r\nuniform mat4 u_MVP;\r\nuniform mat4 u_directionalShadowMatrix_MVP;\r\n\r\nlayout(location=0) in vec3 in_Position;\r\nlayout(location=1) in vec3 in_Normal;\r\nlayout(location=2) in vec2 in_UV;\r\n\r\nout vec3 v_Position;\r\nout vec3 v_Normal;\r\nout vec2 v_UV;\r\nout vec4 v_PositionLightShadowSpace;\r\n\r\nvoid main() {\r\n  gl_Position = u_MVP * vec4(in_Position, 1.0f);\r\n  v_Position = (u_M * vec4(in_Position, 1.0f)).xyz;\r\n  v_PositionLightShadowSpace = u_directionalShadowMatrix_MVP * vec4(in_Position, 1.0);\r\n  v_Normal = in_Normal;\r\n  v_UV = in_UV;\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n// precision highp sampler2D;\r\n\r\nuniform vec3 u_cameraPosition;\r\nuniform vec2 u_viewport;\r\n// material\r\nuniform usampler2D u_albedoTexture;\r\nuniform usampler2D u_specularTexture;\r\nuniform usampler2D u_hairShadowTexture;\r\nuniform float u_specular;\r\nuniform float u_specularMul;\r\nuniform int u_materialFlags;\r\nuniform float u_sssTransluency;\r\nuniform float u_sssWidth;\r\nuniform float u_sssBias;\r\nuniform float u_sssGain;\r\nuniform float u_sssStrength;\r\nuniform sampler2D u_sssDepthTex;\r\nuniform vec3 u_sssPosition;\r\n// ao\r\nuniform sampler2D u_aoTex;\r\nuniform float u_aoStrength;\r\nuniform float u_aoExp;\r\n// Shadow\r\nuniform sampler2D u_directionalShadowDepthTex;\r\nuniform vec4 u_directionalShadowCasterPosition; // [position.xyz, bias (negative if pcss)]\r\nuniform int u_directionalShadowSampleRadius;\r\nuniform float u_maxShadowContribution;\r\n#define BIAS_FROM_UI (u_directionalShadowCasterPosition.w)\r\n#define USE_PCSS_SHADOWS (u_directionalShadowCasterPosition.w < 0.0f)\r\n// sss\r\nuniform float u_sssFarPlane;\r\nuniform mat4 u_sssMatrix_VP;\r\n// Lights\r\nuniform vec4 u_lightAmbient;\r\nuniform vec3 u_light0_Position;\r\nuniform vec4 u_light0_Color;\r\nuniform vec3 u_light1_Position;\r\nuniform vec4 u_light1_Color;\r\nuniform vec3 u_light2_Position;\r\nuniform vec4 u_light2_Color;\r\n\r\n\r\nin vec3 v_Position;\r\nin vec3 v_Normal;\r\nin vec2 v_UV;\r\nin vec4 v_PositionLightShadowSpace;\r\n\r\n\r\nlayout(location = 0) out vec4 outColor1;\r\nlayout(location = 1) out vec4 outColor2; // normals\r\n\r\n\r\n// required by SSSSS import, but not used here (used in SSS blur)\r\nfloat SSSSS_sampleDepthLinear (sampler2D depthTex, vec2 texcoord) {\r\n  return 0.0;\r\n}\r\n\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\nstruct Material {\r\n  vec3 positionWS;\r\n  vec3 normal;\r\n  vec3 toEye;\r\n  // pbr\r\n  vec3 albedo;\r\n  float roughness;\r\n  float specularMul; // needed for eyes. Normally You create separate mesh etc, but I'm too lazy\r\n  float isMetallic;\r\n  float ao;\r\n  // shadow\r\n  float shadow; // 0.0 - in shadow, 1.0 - in light\r\n  float hairShadow; // 0.0 - in shadow, 1.0 - in light. This is special Sintel texture!!!\r\n};\r\n\r\nstruct Light {\r\n  vec3 position;\r\n  vec3 color;\r\n  float intensity;\r\n};\r\n\r\nLight unpackLight(vec3 pos, vec4 color) {\r\n  Light light;\r\n  light.position = pos;\r\n  light.color = color.rgb;\r\n  light.intensity = color.a;\r\n  return light;\r\n}\r\n\r\n\r\n/// utils:\r\n\r\n/* Some custom AO handling - specific to this demo */\r\nfloat getCustom_AO(float ao, float aoStrength, float aoExp) {\r\n  ao = 1.0 - pow(1.0 - ao, aoExp);\r\n  return mix(ao, 1.0, 1.0 - aoStrength);\r\n}\r\n\r\n// @i mport ./_skin;\r\nconst vec3 DIELECTRIC_FRESNEL = vec3(0.04, 0.04, 0.04); // nearly black\r\nconst vec3 METALLIC_DIFFUSE_CONTRIBUTION = vec3(0.0); // none\r\n\r\n\r\nvec3 pbr_LambertDiffuse (const Material material) {\r\n  // return material.albedo / PI;\r\n  return material.albedo;\r\n}\r\n\r\n\r\n/**\r\n * Fresnel (F): Schlick's version\r\n *\r\n * If cosTheta 0 means 90dgr, so return big value, if is 1 means 0dgr return\r\n * just F0. Function modeled to have shape of most common fresnel\r\n * reflectance function shape.\r\n *\r\n * @param float cosTheta - cos(viewDirection V, halfway vector H),\r\n * @param vec3 F0 - surface reflectance at 0dgr. vec3 somewhat models wavelengths\r\n */\r\nvec3 FresnelSchlick(float cosTheta, vec3 F0) {\r\n    return F0 + (1.0 - F0) * pow(1.0 - cosTheta, 5.0);\r\n}\r\n\r\n/**\r\n * Normal distribution function (D): GGX\r\n *\r\n * Just standard implementation ('Real Shading in Unreal Engine 4' equation 2)\r\n *\r\n * @param vec3 N - normalized normal\r\n * @param vec3 H - halfway vector\r\n * @param float roughness [0,1]\r\n */\r\nfloat DistributionGGX(vec3 N, vec3 H, float roughness) {\r\n    float a      = roughness*roughness;\r\n    float a2     = a*a;\r\n    float NdotH  = dotMax0(N, H);\r\n    float NdotH2 = NdotH*NdotH;\r\n\r\n    float num   = a2;\r\n    float denom = NdotH2 * (a2 - 1.0) + 1.0;\r\n    denom = PI * denom * denom;\r\n\r\n    return num / denom;\r\n}\r\n\r\n/**\r\n * Self-shadowing Smith helper function.\r\n *\r\n * @see 'Real Shading in Unreal Engine 4' equation 4 line 1,2\r\n *\r\n * @param vec3 NdotV dot prod. between normal and vector to camera/light source\r\n * @param float roughness material property\r\n */\r\nfloat GeometrySchlickGGX(float NdotV, float roughness) {\r\n    float r = (roughness + 1.0);\r\n    float k = (r*r) / 8.0;\r\n\r\n    float num   = NdotV;\r\n    float denom = NdotV * (1.0 - k) + k;\r\n\r\n    return num / denom;\r\n}\r\n\r\n/**\r\n * Self-shadowing (G): GGX\r\n *\r\n * Just standard implementation ('Real Shading in Unreal Engine 4' equation 4 line 3). We do calculate self-shadowing in directions light-point and point-camera, then mul.\r\n *\r\n * @param vec3 N normal at current frag\r\n * @param vec3 V frag -> point\r\n * @param vec3 L frag -> light\r\n * @param float roughness material property\r\n *\r\n */\r\nfloat GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness) {\r\n    float NdotV = dotMax0(N, V);\r\n    float NdotL = dotMax0(N, L);\r\n    float ggx2  = GeometrySchlickGGX(NdotV, roughness);\r\n    float ggx1  = GeometrySchlickGGX(NdotL, roughness);\r\n\r\n    return ggx1 * ggx2;\r\n}\r\n\r\nvec3 pbr_CookTorrance (const Material material, vec3 V, vec3 L, out vec3 F) {\r\n  vec3 H = normalize(V + L); // halfway vector\r\n  vec3 N = material.normal; // normal at fragment\r\n\r\n  // F - Fresnel\r\n  vec3 F0 = mix(DIELECTRIC_FRESNEL, material.albedo, material.isMetallic);\r\n  F = FresnelSchlick(dotMax0(H, V), F0);\r\n  // G - microfacet self-shadowing\r\n  float G = GeometrySmith(N, V, L, material.roughness);\r\n  // D - Normals distribution\r\n  float NDF = DistributionGGX(N, H, material.roughness);\r\n\r\n  // Cook-Torrance BRDF using NDF,G,F\r\n  vec3 numerator = NDF * G * F;\r\n  float denominator = 4.0 * dotMax0(N, V) * dotMax0(N, L);\r\n  return numerator / max(denominator, 0.001);\r\n}\r\n\r\nvec3 pbr_mixDiffuseAndSpecular (const Material material, vec3 diffuse, vec3 specular, vec3 F) {\r\n  vec3 kS = F;\r\n  // kD for metalics is ~0 (means they have pure black diffuse color, but take color of specular)\r\n  vec3 kD = mix(vec3(1.0) - kS, METALLIC_DIFFUSE_CONTRIBUTION, material.isMetallic);\r\n  return kD * diffuse + specular;\r\n}\r\n\r\n\r\nvec3 pbr (const Material material, const Light light) {\r\n  vec3 N = material.normal; // normal at fragment\r\n  vec3 V = normalize(u_cameraPosition - material.positionWS); // viewDir\r\n  vec3 L = light.position - material.positionWS; // wi in integral\r\n  // float attenuation = lightAttenuation(length(L), light.radius);\r\n  float attenuation = 1.0; // hardcoded for this demo\r\n  L = normalize(L);\r\n\r\n  // diffuse\r\n  vec3 lambert = pbr_LambertDiffuse(material);\r\n\r\n  // specular\r\n  vec3 F;\r\n  vec3 specular = pbr_CookTorrance(material, V, L, F);\r\n  specular = specular * material.specularMul; // not PBR, but simplifies material setup\r\n\r\n  // final light calc.\r\n  float NdotL = dotMax0(N, L);\r\n  vec3 brdfFinal = pbr_mixDiffuseAndSpecular(material, lambert, specular, F);\r\n  vec3 radiance = light.color * attenuation * light.intensity; // incoming color from light\r\n  return brdfFinal * radiance * NdotL;\r\n}\r\n\r\n/** returns inShadow(1.0) or notInShadow(0.0) */\r\n/*\r\nfloat calculateDirectionalShadow(vec4 lightPosInterp, vec3 normal, vec3 toShadowCaster) {\r\n  vec3 lightPosProj = lightPosInterp.xyz / lightPosInterp.w; // not build-in gl_Position. Useless for ORTHO, only PERSP.\r\n  lightPosProj = lightPosProj * 0.5 + 0.5; // from opengl [-1, 1] to depth-texture-like [0..1]\r\n\r\n  // depth from shadow map\r\n  float shadowMapDepth = texture(u_directionalShadowDepthTex, lightPosProj.xy).r;\r\n  // depth of current fragment (we multiplied by light-shadow matrix\r\n  // in vert. shader, did w-divide here)\r\n  float fragmentDepth = lightPosProj.z;\r\n\r\n  // GDC_Poster_NormalOffset.png\r\n  float bias = max(0.05 * (1.0 - dot(normal, toShadowCaster)), 0.005);\r\n\r\n  // There are following cases:\r\n  //  * fragmentDepth > shadowMapDepth\r\n  //      there exist some object that is closer to shadow source than object\r\n  //      Means object is IN SHADOW\r\n  //  * fragmentDepth == shadowMapDepth\r\n  //      this is the object that casts the shadow\r\n  //      Means NO SHADOW\r\n  //  * fragmentDepth < shadowMapDepth\r\n  //      would probably happen if object is not shadow-caster\r\n  //      Means NO SHADOW\r\n  return fragmentDepth - bias > shadowMapDepth  ? 1.0 : 0.0;\r\n}\r\n*/\r\n\r\nconst float IN_SHADOW = 1.0f;\r\nconst float NOT_IN_SHADOW = 0.0f;\r\n\r\n// settings\r\nconst float PCSS_PENUMBRA_WIDTH = 10.0;\r\nconst int PCSS_PENUMBRA_BASE = 1; // we want at least some blur\r\n\r\nfloat sampleShadowMap (int sampleRadius, vec3 lightPosProj, float bias) {\r\n  // depth of current fragment (we multiplied by light-shadow matrix\r\n  // in vert. shader, did w-divide here)\r\n  float fragmentDepth = lightPosProj.z;\r\n\r\n  float shadow = 0.0;\r\n  vec2 texelSize = 1.0 / vec2(textureSize(u_directionalShadowDepthTex, 0));\r\n  for (int x = -sampleRadius; x <= sampleRadius; ++x) {\r\n    for (int y = -sampleRadius; y <= sampleRadius; ++y) {\r\n      // depth from shadow map\r\n      float shadowMapDepth = texture(\r\n        u_directionalShadowDepthTex,\r\n        lightPosProj.xy + vec2(x, y) * texelSize\r\n      ).r;\r\n\r\n      // There are following cases:\r\n      //  * fragmentDepth > shadowMapDepth\r\n      //      there exist some object that is closer to shadow source than object\r\n      //      Means object is IN SHADOW\r\n      //  * fragmentDepth == shadowMapDepth\r\n      //      this is the object that casts the shadow\r\n      //      Means NO SHADOW\r\n      //  * fragmentDepth < shadowMapDepth\r\n      //      would probably happen if object is not shadow-caster\r\n      //      Means NO SHADOW\r\n      shadow += fragmentDepth - bias > shadowMapDepth  ? IN_SHADOW : NOT_IN_SHADOW;\r\n    }\r\n  }\r\n\r\n  float pcfTmp = float(sampleRadius * 2 + 1);\r\n  return shadow /= pcfTmp * pcfTmp;\r\n}\r\n\r\nfloat calculateDirectionalShadow(vec4 lightPosInterp, vec3 normal, vec3 toShadowCaster) {\r\n  // position of fragment as rendered from light POV\r\n  vec3 lightPosProj = lightPosInterp.xyz / lightPosInterp.w; // Useless for ORTHO, only PERSP.\r\n  lightPosProj = to_0_1(lightPosProj); // from opengl [-1, 1] to depth-texture-like [0..1]\r\n\r\n  // Special case if we went beyond the far plane of the frustum.\r\n  // Mark no shadow, cause it's better than dark region\r\n  // far away (or whatever relative light-camera postion is)\r\n  if (lightPosProj.z > 1.0) {\r\n    return NOT_IN_SHADOW;\r\n  }\r\n  // would cause 'invalid' sampling, mark as no shadow too.\r\n  if (outOfScreen(lightPosProj.xy)) {\r\n    return NOT_IN_SHADOW;\r\n  }\r\n\r\n  // GDC_Poster_NormalOffset.png\r\n  float bias = max(abs(BIAS_FROM_UI) * (1.0 - dot(normal, toShadowCaster)), 0.005);\r\n\r\n  if (USE_PCSS_SHADOWS) {\r\n    // PCSS\r\n    float fragmentDepth = lightPosProj.z;\r\n    float shadowMapDepth = texture(u_directionalShadowDepthTex, lightPosProj.xy).r; // sample center\r\n    float depthDiff = max(fragmentDepth - shadowMapDepth, 0.0);\r\n    int sampleRadius = PCSS_PENUMBRA_BASE + int(depthDiff / shadowMapDepth * PCSS_PENUMBRA_WIDTH);\r\n    return sampleShadowMap(sampleRadius, lightPosProj, bias);\r\n  } else {\r\n    // PCF\r\n    return sampleShadowMap(u_directionalShadowSampleRadius, lightPosProj, bias);\r\n  }\r\n}\r\n\r\n#define SSSS_GLSL_3 1\r\n/**\r\n * Copyright (C) 2012 Jorge Jimenez (jorge@iryoku.com)\r\n * Copyright (C) 2012 Diego Gutierrez (diegog@unizar.es)\r\n * All rights reserved.\r\n *\r\n * Redistribution and use in source and binary forms, with or without\r\n * modification, are permitted provided that the following conditions are met:\r\n *\r\n *    1. Redistributions of source code must retain the above copyright notice,\r\n *       this list of conditions and the following disclaimer.\r\n *\r\n *    2. Redistributions in binary form must reproduce the following disclaimer\r\n *       in the documentation and/or other materials provided with the\r\n *       distribution:\r\n *\r\n *       \"Uses Separable SSS. Copyright (C) 2012 by Jorge Jimenez and Diego\r\n *        Gutierrez.\"\r\n *\r\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS\r\n * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\r\n * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\r\n * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL COPYRIGHT HOLDERS OR CONTRIBUTORS\r\n * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\r\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\r\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\r\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\r\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\r\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\r\n * POSSIBILITY OF SUCH DAMAGE.\r\n *\r\n * The views and conclusions contained in the software and documentation are\r\n * those of the authors and should not be interpreted as representing official\r\n * policies, either expressed or implied, of the copyright holders.\r\n */\r\n\r\n\r\n/**\r\n *                  _______      _______      _______      _______\r\n *                 /       |    /       |    /       |    /       |\r\n *                |   (----    |   (----    |   (----    |   (----\r\n *                 \\   \\        \\   \\        \\   \\        \\   \\\r\n *              ----)   |    ----)   |    ----)   |    ----)   |\r\n *             |_______/    |_______/    |_______/    |_______/\r\n *\r\n *        S E P A R A B L E   S U B S U R F A C E   S C A T T E R I N G\r\n *\r\n *                           http://www.iryoku.com/\r\n *\r\n * Hi, thanks for your interest in Separable SSS!\r\n *\r\n * It's a simple shader composed of two components:\r\n *\r\n * 1) A transmittance function, 'SSSSTransmittance', which allows to calculate\r\n *    light transmission in thin slabs, useful for ears and nostrils. It should\r\n *    be applied during the main rendering pass as follows:\r\n *\r\n *        float3 t = albedo.rgb * lights[i].color * attenuation * spot;\r\n *        color.rgb += t * SSSSTransmittance(...)\r\n *\r\n *    (See 'Main.fx' for more details).\r\n *\r\n * 2) A simple two-pass reflectance post-processing shader, 'SSSSBlur*', which\r\n *    softens the skin appearance. It should be applied as a regular\r\n *    post-processing effect like bloom (the usual framebuffer ping-ponging):\r\n *\r\n *    a) The first pass (horizontal) must be invoked by taking the final color\r\n *       framebuffer as input, and storing the results into a temporal\r\n *       framebuffer.\r\n *    b) The second pass (vertical) must be invoked by taking the temporal\r\n *       framebuffer as input, and storing the results into the original final\r\n *       color framebuffer.\r\n *\r\n *    Note that This SSS filter should be applied *before* tonemapping.\r\n *\r\n * Before including SeparableSSS.h you'll have to setup the target. The\r\n * following targets are available:\r\n *         SMAA_HLSL_3\r\n *         SMAA_HLSL_4\r\n *         SMAA_GLSL_3\r\n *\r\n * For more information of what's under the hood, you can check the following\r\n * URLs (but take into account that the shader has evolved a little bit since\r\n * these publications):\r\n *\r\n * 1) Reflectance: http://www.iryoku.com/sssss/\r\n * 2) Transmittance: http://www.iryoku.com/translucency/\r\n *\r\n * If you've got any doubts, just contact us!\r\n */\r\n\r\n\r\n //-----------------------------------------------------------------------------\r\n // Porting Functions\r\n\r\n #ifdef SSSS_HLSL_3\r\n #define SSSSTexture2D sampler2D\r\n #define SSSSSampleLevelZero(tex, coord) tex2Dlod(tex, float4(coord, 0.0, 0.0))\r\n #define SSSSSampleLevelZeroPoint(tex, coord) tex2Dlod(tex, float4(coord, 0.0, 0.0))\r\n #define SSSSSample(tex, coord) tex2D(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) tex2D(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) tex2Dlod(tex, float4(coord + offset * SSSS_PIXEL_SIZE, 0.0, 0.0))\r\n #define SSSSSampleOffset(tex, coord, offset) tex2D(tex, coord + offset * SSSS_PIXEL_SIZE)\r\n #define SSSSLerp(a, b, t) lerp(a, b, t)\r\n #define SSSSSaturate(a) saturate(a)\r\n #define SSSSMad(a, b, c) mad(a, b, c)\r\n #define SSSSMul(v, m) mul(v, m)\r\n #define SSSS_FLATTEN [flatten]\r\n #define SSSS_BRANCH [branch]\r\n #define SSSS_UNROLL [unroll]\r\n #endif\r\n #ifdef SSSS_HLSL_4\r\n SamplerState LinearSampler { Filter = MIN_MAG_LINEAR_MIP_POINT; AddressU = Clamp; AddressV = Clamp; };\r\n SamplerState PointSampler { Filter = MIN_MAG_MIP_POINT; AddressU = Clamp; AddressV = Clamp; };\r\n #define SSSSTexture2D Texture2D\r\n #define SSSSSampleLevelZero(tex, coord) tex.SampleLevel(LinearSampler, coord, 0)\r\n #define SSSSSampleLevelZeroPoint(tex, coord) tex.SampleLevel(PointSampler, coord, 0)\r\n #define SSSSSample(tex, coord) SSSSSampleLevelZero(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) SSSSSampleLevelZeroPoint(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) tex.SampleLevel(LinearSampler, coord, 0, offset)\r\n #define SSSSSampleOffset(tex, coord, offset) SSSSSampleLevelZeroOffset(tex, coord, offset)\r\n #define SSSSLerp(a, b, t) lerp(a, b, t)\r\n #define SSSSSaturate(a) saturate(a)\r\n #define SSSSMad(a, b, c) mad(a, b, c)\r\n #define SSSSMul(v, m) mul(v, m)\r\n #define SSSS_FLATTEN [flatten]\r\n #define SSSS_BRANCH [branch]\r\n #define SSSS_UNROLL [unroll]\r\n #endif\r\n #ifdef SSSS_GLSL_3\r\n #define SSSSTexture2D sampler2D\r\n #define SSSSSampleLevelZero(tex, coord) textureLod(tex, coord, 0.0)\r\n #define SSSSSampleLevelZeroPoint(tex, coord) textureLod(tex, coord, 0.0)\r\n #define SSSSSample(tex, coord) texture(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) texture(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) textureLodOffset(tex, coord, 0.0, offset)\r\n #define SSSSSampleOffset(tex, coord, offset) texture(tex, coord, offset)\r\n #define SSSSLerp(a, b, t) mix(a, b, t)\r\n #define SSSSSaturate(a) clamp(a, 0.0, 1.0)\r\n #define SSSSMad(a, b, c) (a * b + c)\r\n #define SSSSMul(v, m) (m * v)\r\n #define SSSS_FLATTEN\r\n #define SSSS_BRANCH\r\n #define SSSS_UNROLL\r\n #define float2 vec2\r\n #define float3 vec3\r\n #define float4 vec4\r\n #define int2 ivec2\r\n #define int3 ivec3\r\n #define int4 ivec4\r\n #define float4x4 mat4x4\r\n #endif\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Configurable Defines\r\n\r\n/**\r\n * SSSS_FOV must be set to the value used to render the scene.\r\n */\r\n#ifndef SSSS_FOVY\r\n#define SSSS_FOVY 20.0\r\n#endif\r\n\r\n/**\r\n * Light diffusion should occur on the surface of the object, not in a screen\r\n * oriented plane. Setting SSSS_FOLLOW_SURFACE to 1 will ensure that diffusion\r\n * is more accurately calculated, at the expense of more memory accesses.\r\n */\r\n#ifndef SSSS_FOLLOW_SURFACE\r\n#define SSSS_FOLLOW_SURFACE 0\r\n#endif\r\n\r\n/**\r\n * This define allows to specify a different source for the SSS strength\r\n * (instead of using the alpha channel of the color framebuffer). This is\r\n * useful when the alpha channel of the mian color buffer is used for something\r\n * else.\r\n */\r\n#ifndef SSSS_STREGTH_SOURCE\r\n#define SSSS_STREGTH_SOURCE (colorM.a)\r\n#endif\r\n\r\n/**\r\n * If SSSS_N_SAMPLES is defined at this point, a custom filter kernel must be\r\n * set by the runtime.\r\n */\r\n#ifdef SSSS_N_SAMPLES\r\n/**\r\n * Filter kernel layout is as follows:\r\n *   - Weights in the RGB channels.\r\n *   - Offsets in the A channel.\r\n */\r\nfloat4 kernel[SSSS_N_SAMPLES];\r\n#else\r\n/**\r\n * Here you have ready-to-use kernels for quickstarters. Three kernels are\r\n * readily available, with varying quality.\r\n * To create new kernels take a look into SSS::calculateKernel, or simply\r\n * push CTRL+C in the demo to copy the customized kernel into the clipboard.\r\n *\r\n * Note: these preset kernels are not used by the demo. They are calculated on\r\n * the fly depending on the selected values in the interface, by directly using\r\n * SSS::calculateKernel.\r\n *\r\n * Quality ranges from 0 to 2, being 2 the highest quality available.\r\n * The quality is with respect to 1080p; for 720p Quality=0 suffices.\r\n */\r\n#define SSSS_QUALITY 1\r\n\r\n#if SSSS_QUALITY == 2\r\n#define SSSS_N_SAMPLES 25\r\nfloat4 kernel[] = float4[](\r\n    float4(0.530605, 0.613514, 0.739601, 0),\r\n    float4(0.000973794, 1.11862e-005, 9.43437e-007, -3),\r\n    float4(0.00333804, 7.85443e-005, 1.2945e-005, -2.52083),\r\n    float4(0.00500364, 0.00020094, 5.28848e-005, -2.08333),\r\n    float4(0.00700976, 0.00049366, 0.000151938, -1.6875),\r\n    float4(0.0094389, 0.00139119, 0.000416598, -1.33333),\r\n    float4(0.0128496, 0.00356329, 0.00132016, -1.02083),\r\n    float4(0.017924, 0.00711691, 0.00347194, -0.75),\r\n    float4(0.0263642, 0.0119715, 0.00684598, -0.520833),\r\n    float4(0.0410172, 0.0199899, 0.0118481, -0.333333),\r\n    float4(0.0493588, 0.0367726, 0.0219485, -0.1875),\r\n    float4(0.0402784, 0.0657244, 0.04631, -0.0833333),\r\n    float4(0.0211412, 0.0459286, 0.0378196, -0.0208333),\r\n    float4(0.0211412, 0.0459286, 0.0378196, 0.0208333),\r\n    float4(0.0402784, 0.0657244, 0.04631, 0.0833333),\r\n    float4(0.0493588, 0.0367726, 0.0219485, 0.1875),\r\n    float4(0.0410172, 0.0199899, 0.0118481, 0.333333),\r\n    float4(0.0263642, 0.0119715, 0.00684598, 0.520833),\r\n    float4(0.017924, 0.00711691, 0.00347194, 0.75),\r\n    float4(0.0128496, 0.00356329, 0.00132016, 1.02083),\r\n    float4(0.0094389, 0.00139119, 0.000416598, 1.33333),\r\n    float4(0.00700976, 0.00049366, 0.000151938, 1.6875),\r\n    float4(0.00500364, 0.00020094, 5.28848e-005, 2.08333),\r\n    float4(0.00333804, 7.85443e-005, 1.2945e-005, 2.52083),\r\n    float4(0.000973794, 1.11862e-005, 9.43437e-007, 3)\r\n);\r\n#elif SSSS_QUALITY == 1\r\n#define SSSS_N_SAMPLES 17\r\nfloat4 kernel[] = float4[](\r\n    float4(0.536343, 0.624624, 0.748867, 0),\r\n    float4(0.00317394, 0.000134823, 3.77269e-005, -2),\r\n    float4(0.0100386, 0.000914679, 0.000275702, -1.53125),\r\n    float4(0.0144609, 0.00317269, 0.00106399, -1.125),\r\n    float4(0.0216301, 0.00794618, 0.00376991, -0.78125),\r\n    float4(0.0347317, 0.0151085, 0.00871983, -0.5),\r\n    float4(0.0571056, 0.0287432, 0.0172844, -0.28125),\r\n    float4(0.0582416, 0.0659959, 0.0411329, -0.125),\r\n    float4(0.0324462, 0.0656718, 0.0532821, -0.03125),\r\n    float4(0.0324462, 0.0656718, 0.0532821, 0.03125),\r\n    float4(0.0582416, 0.0659959, 0.0411329, 0.125),\r\n    float4(0.0571056, 0.0287432, 0.0172844, 0.28125),\r\n    float4(0.0347317, 0.0151085, 0.00871983, 0.5),\r\n    float4(0.0216301, 0.00794618, 0.00376991, 0.78125),\r\n    float4(0.0144609, 0.00317269, 0.00106399, 1.125),\r\n    float4(0.0100386, 0.000914679, 0.000275702, 1.53125),\r\n    float4(0.00317394, 0.000134823, 3.77269e-005, 2)\r\n);\r\n#elif SSSS_QUALITY == 0\r\n#define SSSS_N_SAMPLES 11\r\nfloat4 kernel[] = float4[](\r\n    float4(0.560479, 0.669086, 0.784728, 0),\r\n    float4(0.00471691, 0.000184771, 5.07566e-005, -2),\r\n    float4(0.0192831, 0.00282018, 0.00084214, -1.28),\r\n    float4(0.03639, 0.0130999, 0.00643685, -0.72),\r\n    float4(0.0821904, 0.0358608, 0.0209261, -0.32),\r\n    float4(0.0771802, 0.113491, 0.0793803, -0.08),\r\n    float4(0.0771802, 0.113491, 0.0793803, 0.08),\r\n    float4(0.0821904, 0.0358608, 0.0209261, 0.32),\r\n    float4(0.03639, 0.0130999, 0.00643685, 0.72),\r\n    float4(0.0192831, 0.00282018, 0.00084214, 1.28),\r\n    float4(0.00471691, 0.000184771, 5.07565e-005, 2)\r\n);\r\n#else\r\n#error Quality must be one of {0,1,2}\r\n#endif\r\n#endif\r\n\r\n\r\n// Translucency profile weights and variances\r\n// float3 weights[5];\r\n// float3 variances[5];\r\n\r\nfloat maxOffsetMm;\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Separable SSS Transmittance Function\r\n\r\nfloat3 SSSSTransmittance(\r\n   // This parameter allows to control the transmittance effect. Its range\r\n   // should be 0..1. Higher values translate to a stronger effect.\r\n  float translucency,\r\n  // This parameter should be the same as the 'SSSSBlurPS' one. See below\r\n  // for more details.\r\n  float sssWidth,\r\n  // Position in world space.\r\n  float3 worldPosition,\r\n  // Normal in world space.\r\n  float3 worldNormal,\r\n  // Light vector: lightWorldPosition - worldPosition.\r\n  float3 light,\r\n  // Linear 0..1 shadow map.\r\n  SSSSTexture2D shadowMap,\r\n  // Regular world to light space matrix.\r\n  float4x4 lightViewProjection,\r\n  // Far plane distance used in the light projection matrix.\r\n  float lightFarPlane,\r\n  // custom params:\r\n  float sssBias,\r\n  float sssGain\r\n) {\r\n  // Calculate the scale of the effect.\r\n  float scale = sssWidth * (1.0 - translucency); // sssWidth in  mm / world space unit\r\n\r\n  // First we shrink the position inwards the surface to avoid artifacts:\r\n  // (Note that this can be done once for all the lights)\r\n  // NOTE: sssBias = 0.005\r\n  float4 shrinkedPos = float4(worldPosition - sssBias * worldNormal, 1.0);\r\n\r\n  // Now we calculate the thickness from the light point of view:\r\n  float4 shadowPosition = SSSSMul(shrinkedPos, lightViewProjection); // NOPE, shadowMatrix also has model matrix!\r\n  shadowPosition.xyz = shadowPosition.xyz / shadowPosition.w;\r\n  shadowPosition.xyz = to_0_1(shadowPosition.xyz);\r\n  float d1 = SSSSSample(shadowMap, shadowPosition.xy).r; // 'd1' has a range of 0..1\r\n  float d2 = shadowPosition.z; // 'd2' has a range of 0..'lightFarPlane'\r\n  // thickness - distance between:\r\n  //   * pixel world position\r\n  //   * projected point from light point of view\r\n  float d = scale * abs(d1 - d2);\r\n  d *= lightFarPlane;\r\n\r\n  // Armed with the thickness, we can now calculate the color by means of the\r\n  // precalculated transmittance profile.\r\n  // (It can be precomputed into a texture, for maximum performance):\r\n  float dd = -d * d;\r\n\r\n  // UE4: Engine/Shaders/Private/SeparableSSS.ush\r\n  float3 profile =\r\n    float3(0.233, 0.455, 0.649) * exp(dd / 0.0064) +\r\n    float3(0.1,   0.336, 0.344) * exp(dd / 0.0484) +\r\n    float3(0.118, 0.198, 0.0  ) * exp(dd / 0.187)  +\r\n    float3(0.113, 0.007, 0.007) * exp(dd / 0.567)  +\r\n    float3(0.358, 0.004, 0.0  ) * exp(dd / 1.99)   +\r\n    float3(0.078, 0.0,   0.0  ) * exp(dd / 7.41);\r\n\r\n  // Using the profile, we finally approximate the transmitted lighting from\r\n  // the back of the object:\r\n  // NOTE: sssGain = 0.3\r\n  // we negate normal, cause we are interested in FORWARD scattering\r\n  return profile * SSSSSaturate(sssGain + dot(light, -worldNormal));\r\n}\r\n\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Separable SSS Reflectance Pixel Shader\r\n\r\n\r\nfloat4 SSSSBlurPS(\r\n  // The usual quad texture coordinates.\r\n  float2 texcoord,\r\n  /**\r\n   * This is a SRGB or HDR color input buffer, which should be the final\r\n   * color frame, resolved in case of using multisampling. The desired\r\n   * SSS strength should be stored in the alpha channel (1 for full\r\n   * strength, 0 for disabling SSS). If this is not possible, you an\r\n   * customize the source of this value using SSSS_STREGTH_SOURCE.\r\n   *\r\n   * When using non-SRGB buffers, you\r\n   * should convert to linear before processing, and back again to gamma\r\n   * space before storing the pixels (see Chapter 24 of GPU Gems 3 for\r\n   * more info)\r\n   *\r\n   * IMPORTANT: WORKING IN A NON-LINEAR SPACE WILL TOTALLY RUIN SSS!\r\n   */\r\n  SSSSTexture2D colorTex,\r\n  // The linear depth buffer of the scene, resolved in case of using\r\n  // multisampling. The resolve should be a simple average to avoid\r\n  // artifacts in the silhouette of objects.\r\n  SSSSTexture2D depthTex,\r\n  // This parameter specifies the global level of subsurface scattering\r\n  // or, in other words, the width of the filter. It's specified in\r\n  // mm / world space unit.\r\n  float sssWidth,\r\n  // Direction of the blur:\r\n  //   - First pass:   float2(1.0, 0.0)\r\n  //   - Second pass:  float2(0.0, 1.0)\r\n  float2 dir,\r\n  // replaced macros:\r\n  float sssFovy,\r\n  float sssStrength,\r\n  bool sssFollowSurface\r\n) {\r\n  // NOTE: UE4 calcualtes some of params on CPU, see:\r\n  // Engine/Source/Runtime/Renderer/Private/PostProcess/PostProcessSubsurface.cpp\r\n  // Engine/Shaders/Private/PostProcessSubsurface.usf\r\n  // Engine/Shaders/Private/SeparableSSS.ush\r\n\r\n  // Fetch color of current pixel:\r\n  float4 colorM = SSSSSamplePoint(colorTex, texcoord);\r\n\r\n  // Fetch linear depth of current pixel:\r\n  // NOTE: LINEAR DEPTH!\r\n  float depthM = SSSSS_sampleDepthLinear(depthTex, texcoord);\r\n\r\n  // Calculate the sssWidth scale (1.0 for a unit plane sitting on the\r\n  // projection window):\r\n  float distanceToProjectionWindow = 1.0 / tan(0.5 * radians(sssFovy));\r\n  float scale = distanceToProjectionWindow / depthM;\r\n\r\n\t// Calculate the final step to fetch the surrounding pixels:\r\n  float2 finalStep = scale * dir;\r\n  finalStep *= sssStrength; // Modulate it using the alpha channel.\r\n  finalStep *= 1.0 / (2.0 * sssWidth); // sssWidth in mm / world space unit, divided by 2 as uv coords are from [0 1]\r\n\r\n  // Accumulate the center sample:\r\n  float4 colorBlurred = colorM;\r\n  colorBlurred.rgb *= kernel[0].rgb;\r\n\r\n  // Accumulate the other samples:\r\n  SSSS_UNROLL\r\n  for (int i = 1; i < SSSS_N_SAMPLES; i++) {\r\n    // Fetch color and depth for current sample:\r\n    float2 offset = texcoord + kernel[i].a * finalStep;\r\n    float4 color = SSSSSample(colorTex, offset);\r\n\r\n    if (sssFollowSurface) {\r\n      // If the difference in depth is huge, we lerp color back to \"colorM\":\r\n      float depth = SSSSS_sampleDepthLinear(depthTex, offset);\r\n\r\n      // Original:\r\n      // float s = SSSSSaturate(\r\n        // abs(depthM - depth) / (distanceToProjectionWindow * (maxOffsetMm / sssWidth))\r\n      // );\r\n      // s = min(1.0, s * 1.5); // custom / user definable scaling\r\n      // UE4:\r\n      float s = saturate(12.0f / 400.0f * sssWidth * abs(depthM - depth));\r\n\r\n      color.rgb = SSSSLerp(color.rgb, colorM.rgb, s);\r\n    }\r\n\r\n    // Accumulate:\r\n    colorBlurred.rgb += kernel[i].rgb * color.rgb;\r\n  }\r\n\r\n  return colorBlurred;\r\n}\r\n\r\n\r\n\r\nconst int FLAG_IS_METALIC = 1;\r\nconst int FLAG_USE_SPECULAR_TEXTURE = 2;\r\nconst int FLAG_USE_HAIR_SHADOW_TEXTURE = 4;\r\n\r\n\r\nvec3 readModelTexture_RGB8UI(usampler2D tex, vec2 coords, bool reverseGamma) {\r\n  coords = fixOpenGLTextureCoords_AxisY(coords);\r\n  uvec3 texAsUint = texture(tex, coords).rgb; // as uint [0-255]\r\n  vec3 texAsFloat = vec3(texAsUint) / 255.0;\r\n  if (reverseGamma) {\r\n    texAsFloat = sRGBtoLinear(texAsFloat, 2.4);\r\n  }\r\n  return texAsFloat;\r\n}\r\n\r\nfloat readSpecular() {\r\n  // we are going to pretend that specular is same as smoothness. Probably is not, but..\r\n  if (isFlag(u_materialFlags, FLAG_USE_SPECULAR_TEXTURE)) {\r\n    return readModelTexture_RGB8UI(u_specularTexture, v_UV, false).r;\r\n  } else {\r\n    return u_specular;\r\n  }\r\n}\r\n\r\nfloat readHairShadow() {\r\n  if (isFlag(u_materialFlags, FLAG_USE_HAIR_SHADOW_TEXTURE)) {\r\n    // special code for this demo\r\n    // the texture is square, so we have toadjust UVs\r\n    vec2 adjustedUV = vec2(v_UV.x * 2.0 - 1.0, v_UV.y);\r\n    if (outOfScreen(adjustedUV)) {\r\n      return NOT_IN_SHADOW;\r\n    }\r\n    float hairShadowVal = readModelTexture_RGB8UI(u_hairShadowTexture, adjustedUV, false).r;\r\n    return hairShadowVal;\r\n  } else {\r\n    return NOT_IN_SHADOW;\r\n  }\r\n}\r\n\r\n\r\nMaterial createMaterial() {\r\n  Material material;\r\n  material.normal = v_Normal;\r\n  material.toEye = normalize(u_cameraPosition - v_Position);\r\n  material.albedo = readModelTexture_RGB8UI(u_albedoTexture, v_UV, true);\r\n  material.positionWS = v_Position;\r\n  material.isMetallic = isFlag(u_materialFlags, FLAG_IS_METALIC) ? 1.0 : 0.0;\r\n  material.specularMul = u_specularMul;\r\n  material.ao = texture(u_aoTex, gl_FragCoord.xy / u_viewport).r;\r\n  // convert specular/smoothness -> roughness\r\n  material.roughness = 1.0 - readSpecular();\r\n\r\n  vec3 toCaster = normalize(u_directionalShadowCasterPosition.xyz - v_Position);\r\n  material.shadow = 1.0 - calculateDirectionalShadow(\r\n    v_PositionLightShadowSpace, material.normal, toCaster\r\n  );\r\n  material.hairShadow = 1.0 - readHairShadow();\r\n\r\n  return material;\r\n}\r\n\r\n\r\nvec3 doShading(Material material, Light lights[3]) {\r\n  vec3 ambient = u_lightAmbient.rgb * u_lightAmbient.a * material.ao;\r\n  vec3 radianceSum = vec3(0.0);\r\n\r\n  for (uint i = 0u; i < 3u; i++) {\r\n    Light light = lights[i];\r\n\r\n    vec3 contrib = pbr(material, light);\r\n\r\n    /* // OR instead of PBR:\r\n    vec3 L = normalize(light.position - material.positionWS); // wi in integral\r\n    float NdotL = dotMax0(material.normal, L);\r\n    vec3 radiance = light.color * light.intensity; // incoming color from light\r\n    vec3 contrib = material.albedo * radiance * NdotL;\r\n    */\r\n\r\n    radianceSum += contrib;\r\n  }\r\n\r\n  // ambient occlusion\r\n  // not PBR, I know, but we need this to highlight some details like collarbones etc.\r\n  float aoRadianceFactor = getCustom_AO(material.ao, u_aoStrength, u_aoExp);\r\n  radianceSum *= aoRadianceFactor;\r\n\r\n  // add SSSSS forward scattering - transluency\r\n  vec3 sssL = normalize(u_sssPosition - material.positionWS);\r\n  vec3 contribSSS = SSSSTransmittance(\r\n    u_sssTransluency, // float translucency,\r\n    u_sssWidth, // float sssWidth,\r\n    material.positionWS, // float3 worldPosition,\r\n    material.normal, // float3 worldNormal,\r\n    sssL, // float3 light,\r\n    u_sssDepthTex, // SSSSTexture2D shadowMap,\r\n    u_sssMatrix_VP, // float4x4 lightViewProjection,\r\n    u_sssFarPlane, // float lightFarPlane\r\n    u_sssBias, u_sssGain\r\n  );\r\n  contribSSS = contribSSS * radianceSum * u_sssStrength;\r\n\r\n  // add shadow, combine\r\n  float shadow = min(material.shadow, material.hairShadow);\r\n  radianceSum = radianceSum * clamp(shadow, 1.0 - u_maxShadowContribution, 1.0);\r\n  return ambient + radianceSum + contribSSS;\r\n}\r\n\r\n\r\nvoid main() {\r\n  Light lights[3];\r\n  lights[0] = unpackLight(u_light0_Position, u_light0_Color);\r\n  lights[1] = unpackLight(u_light1_Position, u_light1_Color);\r\n  lights[2] = unpackLight(u_light2_Position, u_light2_Color);\r\n\r\n  vec3 color;\r\n  Material material = createMaterial();\r\n  // SkinParams skinParams = createSkinParams();\r\n  // material.skin = skinShader(material, skinParams);\r\n  color = doShading(material, lights);\r\n\r\n  outColor1 = vec4(color, 1.0);\r\n  outColor2 = vec4(to_0_1(material.normal), 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n\r\nuniform float u_gamma;\r\nuniform vec2 u_viewport;\r\nuniform vec2 u_nearAndFar;\r\nuniform int u_displayMode;\r\nuniform sampler2D u_tonemappedTex;\r\nuniform sampler2D u_linearDepthTex;\r\nuniform sampler2D u_normalsTex;\r\nuniform sampler2D u_ssaoTex;\r\n// FXAA\r\nuniform float u_subpixel;\r\nuniform float u_edgeThreshold;\r\nuniform float u_edgeThresholdMin;\r\n\r\n\r\nin vec2 v_position;\r\n\r\nlayout(location = 0) out vec4 color1;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n// https://github.com/pyalot/webgl-deferred-irradiance-volumes/blob/master/src/antialias/fxaa3_11_preprocessed.shaderlib\r\n// Honestly, this is just standard Nvidia FXAA 3.11\r\n// Nothing much to add to the code..\r\n\r\n\r\nfloat FxaaLuma(vec4 rgba) { return rgba.a; }\r\n\r\nvec4 FxaaPixelShader(\r\n    vec2 pos\r\n    ,sampler2D tex\r\n    ,sampler2D lumaTex\r\n    ,vec2 fxaaQualityRcpFrame\r\n    ,float fxaaQualitySubpix\r\n    ,float fxaaQualityEdgeThreshold\r\n    ,float fxaaQualityEdgeThresholdMin\r\n) {\r\n    vec2 posM;\r\n    posM.x = pos.x;\r\n    posM.y = pos.y;\r\n    vec4 rgbyM = texture(tex, posM, 0.0);\r\n    rgbyM.a = FxaaLuma(texture(lumaTex, posM, 0.0));\r\n    float lumaS = FxaaLuma(texture(lumaTex, posM + (vec2( 0.0, 1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaE = FxaaLuma(texture(lumaTex, posM + (vec2( 1.0, 0.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaN = FxaaLuma(texture(lumaTex, posM + (vec2( 0.0,-1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaW = FxaaLuma(texture(lumaTex, posM + (vec2(-1.0, 0.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n\r\n    float maxSM = max(lumaS, rgbyM.y);\r\n    float minSM = min(lumaS, rgbyM.y);\r\n    float maxESM = max(lumaE, maxSM);\r\n    float minESM = min(lumaE, minSM);\r\n    float maxWN = max(lumaN, lumaW);\r\n    float minWN = min(lumaN, lumaW);\r\n    float rangeMax = max(maxWN, maxESM);\r\n    float rangeMin = min(minWN, minESM);\r\n    float rangeMaxScaled = rangeMax * fxaaQualityEdgeThreshold;\r\n    float range = rangeMax - rangeMin;\r\n    float rangeMaxClamped = max(fxaaQualityEdgeThresholdMin, rangeMaxScaled);\r\n    bool earlyExit = range < rangeMaxClamped;\r\n    if(earlyExit) return rgbyM;\r\n    float lumaNW = FxaaLuma(texture(lumaTex, posM + (vec2(-1.0,-1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaSE = FxaaLuma(texture(lumaTex, posM + (vec2( 1.0, 1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaNE = FxaaLuma(texture(lumaTex, posM + (vec2( 1.0,-1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n    float lumaSW = FxaaLuma(texture(lumaTex, posM + (vec2(-1.0, 1.0) * fxaaQualityRcpFrame.xy), 0.0));\r\n\r\n    float lumaNS = lumaN + lumaS;\r\n    float lumaWE = lumaW + lumaE;\r\n    float subpixRcpRange = 1.0/range;\r\n    float subpixNSWE = lumaNS + lumaWE;\r\n    float edgeHorz1 = (-2.0 * rgbyM.y) + lumaNS;\r\n    float edgeVert1 = (-2.0 * rgbyM.y) + lumaWE;\r\n    float lumaNESE = lumaNE + lumaSE;\r\n    float lumaNWNE = lumaNW + lumaNE;\r\n    float edgeHorz2 = (-2.0 * lumaE) + lumaNESE;\r\n    float edgeVert2 = (-2.0 * lumaN) + lumaNWNE;\r\n    float lumaNWSW = lumaNW + lumaSW;\r\n    float lumaSWSE = lumaSW + lumaSE;\r\n    float edgeHorz4 = (abs(edgeHorz1) * 2.0) + abs(edgeHorz2);\r\n    float edgeVert4 = (abs(edgeVert1) * 2.0) + abs(edgeVert2);\r\n    float edgeHorz3 = (-2.0 * lumaW) + lumaNWSW;\r\n    float edgeVert3 = (-2.0 * lumaS) + lumaSWSE;\r\n    float edgeHorz = abs(edgeHorz3) + edgeHorz4;\r\n    float edgeVert = abs(edgeVert3) + edgeVert4;\r\n    float subpixNWSWNESE = lumaNWSW + lumaNESE;\r\n    float lengthSign = fxaaQualityRcpFrame.x;\r\n    bool horzSpan = edgeHorz >= edgeVert;\r\n    float subpixA = subpixNSWE * 2.0 + subpixNWSWNESE;\r\n    if(!horzSpan) lumaN = lumaW;\r\n    if(!horzSpan) lumaS = lumaE;\r\n    if(horzSpan) lengthSign = fxaaQualityRcpFrame.y;\r\n    float subpixB = (subpixA * (1.0/12.0)) - rgbyM.y;\r\n    float gradientN = lumaN - rgbyM.y;\r\n    float gradientS = lumaS - rgbyM.y;\r\n    float lumaNN = lumaN + rgbyM.y;\r\n    float lumaSS = lumaS + rgbyM.y;\r\n    bool pairN = abs(gradientN) >= abs(gradientS);\r\n    float gradient = max(abs(gradientN), abs(gradientS));\r\n    if(pairN) lengthSign = -lengthSign;\r\n    float subpixC = clamp(abs(subpixB) * subpixRcpRange, 0.0, 1.0);\r\n    vec2 posB;\r\n    posB.x = posM.x;\r\n    posB.y = posM.y;\r\n    vec2 offNP;\r\n    offNP.x = (!horzSpan) ? 0.0 : fxaaQualityRcpFrame.x;\r\n    offNP.y = ( horzSpan) ? 0.0 : fxaaQualityRcpFrame.y;\r\n    if(!horzSpan) posB.x += lengthSign * 0.5;\r\n    if( horzSpan) posB.y += lengthSign * 0.5;\r\n    vec2 posN;\r\n    posN.x = posB.x - offNP.x * 1.0;\r\n    posN.y = posB.y - offNP.y * 1.0;\r\n    vec2 posP;\r\n    posP.x = posB.x + offNP.x * 1.0;\r\n    posP.y = posB.y + offNP.y * 1.0;\r\n    float subpixD = ((-2.0)*subpixC) + 3.0;\r\n    float lumaEndN = FxaaLuma(texture(lumaTex, posN, 0.0));\r\n    float subpixE = subpixC * subpixC;\r\n    float lumaEndP = FxaaLuma(texture(lumaTex, posP, 0.0));\r\n    if(!pairN) lumaNN = lumaSS;\r\n    float gradientScaled = gradient * 1.0/4.0;\r\n    float lumaMM = rgbyM.y - lumaNN * 0.5;\r\n    float subpixF = subpixD * subpixE;\r\n    bool lumaMLTZero = lumaMM < 0.0;\r\n    lumaEndN -= lumaNN * 0.5;\r\n    lumaEndP -= lumaNN * 0.5;\r\n    bool doneN = abs(lumaEndN) >= gradientScaled;\r\n    bool doneP = abs(lumaEndP) >= gradientScaled;\r\n    if(!doneN) posN.x -= offNP.x * 1.5;\r\n    if(!doneN) posN.y -= offNP.y * 1.5;\r\n    bool doneNP = (!doneN) || (!doneP);\r\n    if(!doneP) posP.x += offNP.x * 1.5;\r\n    if(!doneP) posP.y += offNP.y * 1.5;\r\n    if(doneNP) {\r\n        if(!doneN) lumaEndN = FxaaLuma(texture(lumaTex, posN.xy, 0.0));\r\n        if(!doneP) lumaEndP = FxaaLuma(texture(lumaTex, posP.xy, 0.0));\r\n        if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\r\n        if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\r\n        doneN = abs(lumaEndN) >= gradientScaled;\r\n        doneP = abs(lumaEndP) >= gradientScaled;\r\n        if(!doneN) posN.x -= offNP.x * 2.0;\r\n        if(!doneN) posN.y -= offNP.y * 2.0;\r\n        doneNP = (!doneN) || (!doneP);\r\n        if(!doneP) posP.x += offNP.x * 2.0;\r\n        if(!doneP) posP.y += offNP.y * 2.0;\r\n\r\n        if(doneNP) {\r\n            if(!doneN) lumaEndN = FxaaLuma(texture(lumaTex, posN.xy, 0.0));\r\n            if(!doneP) lumaEndP = FxaaLuma(texture(lumaTex, posP.xy, 0.0));\r\n            if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\r\n            if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\r\n            doneN = abs(lumaEndN) >= gradientScaled;\r\n            doneP = abs(lumaEndP) >= gradientScaled;\r\n            if(!doneN) posN.x -= offNP.x * 4.0;\r\n            if(!doneN) posN.y -= offNP.y * 4.0;\r\n            doneNP = (!doneN) || (!doneP);\r\n            if(!doneP) posP.x += offNP.x * 4.0;\r\n            if(!doneP) posP.y += offNP.y * 4.0;\r\n\r\n            if(doneNP) {\r\n                if(!doneN) lumaEndN = FxaaLuma(texture(lumaTex, posN.xy, 0.0));\r\n                if(!doneP) lumaEndP = FxaaLuma(texture(lumaTex, posP.xy, 0.0));\r\n                if(!doneN) lumaEndN = lumaEndN - lumaNN * 0.5;\r\n                if(!doneP) lumaEndP = lumaEndP - lumaNN * 0.5;\r\n                doneN = abs(lumaEndN) >= gradientScaled;\r\n                doneP = abs(lumaEndP) >= gradientScaled;\r\n                if(!doneN) posN.x -= offNP.x * 12.0;\r\n                if(!doneN) posN.y -= offNP.y * 12.0;\r\n                doneNP = (!doneN) || (!doneP);\r\n                if(!doneP) posP.x += offNP.x * 12.0;\r\n                if(!doneP) posP.y += offNP.y * 12.0;\r\n            }\r\n\r\n        }\r\n\r\n    }\r\n    float dstN = posM.x - posN.x;\r\n    float dstP = posP.x - posM.x;\r\n    if(!horzSpan) dstN = posM.y - posN.y;\r\n    if(!horzSpan) dstP = posP.y - posM.y;\r\n    bool goodSpanN = (lumaEndN < 0.0) != lumaMLTZero;\r\n    float spanLength = (dstP + dstN);\r\n    bool goodSpanP = (lumaEndP < 0.0) != lumaMLTZero;\r\n    float spanLengthRcp = 1.0/spanLength;\r\n    bool directionN = dstN < dstP;\r\n    float dst = min(dstN, dstP);\r\n    bool goodSpan = directionN ? goodSpanN : goodSpanP;\r\n    float subpixG = subpixF * subpixF;\r\n    float pixelOffset = (dst * (-spanLengthRcp)) + 0.5;\r\n    float subpixH = subpixG * fxaaQualitySubpix;\r\n    float pixelOffsetGood = goodSpan ? pixelOffset : 0.0;\r\n    float pixelOffsetSubpix = max(pixelOffsetGood, subpixH);\r\n    if(!horzSpan) posM.x += pixelOffsetSubpix * lengthSign;\r\n    if( horzSpan) posM.y += pixelOffsetSubpix * lengthSign;\r\n    return vec4(texture(tex, posM, 0.0).xyz, rgbyM.y);\r\n\r\n}\r\n\r\n\r\n\r\nconst int DISPLAY_MODE_FINAL = 0;\r\nconst int DISPLAY_MODE_LINEAR_DEPTH = 1;\r\nconst int DISPLAY_MODE_NORMALS = 2;\r\nconst int DISPLAY_MODE_SSAO = 3;\r\n\r\n\r\nvec3 doFxaa (vec2 uv) {\r\n  vec4 color;\r\n\r\n  if (u_edgeThreshold == 0.0) {\r\n    color = texture(u_tonemappedTex, uv);\r\n  } else {\r\n    color = FxaaPixelShader(\r\n      uv, // in [0-1]\r\n      u_tonemappedTex,\r\n      u_tonemappedTex,\r\n      vec2(1.0) / u_viewport,\r\n      u_subpixel,\r\n      u_edgeThreshold,\r\n      u_edgeThresholdMin\r\n    );\r\n  }\r\n\r\n  return color.rgb;\r\n}\r\n\r\n\r\n\r\n\r\nvoid main() {\r\n  vec2 uv = to_0_1(v_position);\r\n  vec3 result;\r\n\r\n  switch(u_displayMode) {\r\n    case DISPLAY_MODE_LINEAR_DEPTH: {\r\n      float depth = texture(u_linearDepthTex, uv).r;\r\n      float d = u_nearAndFar.y - u_nearAndFar.x;\r\n      result = vec3(depth / d);\r\n      break;\r\n    }\r\n\r\n    case DISPLAY_MODE_NORMALS: {\r\n      vec3 normal = texture(u_normalsTex, uv).xyz;\r\n      result = abs(to_neg1_1(normal));\r\n      break;\r\n    }\r\n\r\n    case DISPLAY_MODE_SSAO: {\r\n      float ssao = texture(u_ssaoTex, uv).r;\r\n      result = vec3(ssao);\r\n      break;\r\n    }\r\n\r\n    default:\r\n    case DISPLAY_MODE_FINAL: {\r\n      vec3 tex = doFxaa(uv);\r\n      result = doGamma(tex, u_gamma);\r\n      break;\r\n    }\r\n  }\r\n\r\n  color1 = vec4(result, 1.0f);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n\r\nuniform sampler2D u_depthTex;\r\n\r\nin vec2 v_position;\r\n\r\nlayout(location = 0) out vec4 color1;\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n\r\nvoid main() {\r\n  vec2 posTextureSpace = to_0_1(v_position);\r\n  float depth = texture(u_depthTex, posTextureSpace).r;\r\n  color1 = vec4(depth, depth, depth, 1.0f);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\nuniform vec3 u_position;\r\nuniform float u_scale;\r\nuniform mat4 u_VP;\r\n\r\nlayout(location=0) in vec3 in_Position;\r\n\r\nvoid main() {\r\n  vec3 pos = in_Position * u_scale;\r\n  gl_Position = u_VP * vec4(u_position + pos, 1.0f);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\nuniform vec3 u_color;\r\n\r\nlayout(location = 0) out vec4 outColor1;\r\n\r\n\r\nvoid main() {\r\n  outColor1 = vec4(u_color, 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n\r\nuniform sampler2D u_source;\r\nuniform float u_gamma;\r\nuniform float u_exposure;\r\nuniform float u_whitePoint;\r\nuniform float u_acesC;\r\nuniform float u_acesS;\r\nuniform int u_tonemappingMode;\r\nuniform float u_ditherStrength;\r\n\r\n\r\nin vec2 v_position; // TexCoords\r\n\r\nlayout(location = 0) out vec4 outColor;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n// usual 8x8 Bayer matrix dithering\r\n\r\n\r\nconst float DITHER_ELEMENT_RANGE = 64.0;\r\nconst float DITHER_LINEAR_COLORSPACE_COLORS = 256.0;\r\n\r\n\r\n/* returns 0-1 dithered value */\r\nfloat getDitherMatrixMod() {\r\n  const int DITHER_MATRIX[64] = int[](\r\n     0, 32,  8, 40,  2, 34, 10, 42,\r\n    48, 16, 56, 24, 50, 18, 58, 26,\r\n    12, 44,  4, 36, 14, 46,  6, 38,\r\n    60, 28, 52, 20, 62, 30, 54, 22,\r\n     3, 35, 11, 43,  1, 33,  9, 41,\r\n    51, 19, 59, 27, 49, 17, 57, 25,\r\n    15, 47,  7, 39, 13, 45,  5, 37,\r\n    63, 31, 55, 23, 61, 29, 53, 21\r\n  );\r\n\r\n  ivec2 pxPos = ivec2(\r\n    mod(gl_FragCoord.x, 8.0),\r\n    mod(gl_FragCoord.y, 8.0)\r\n  );\r\n  int idx = pxPos.y * 8 + pxPos.x;\r\n  int matValue = DITHER_MATRIX[idx] + 1; // [1-64]\r\n  return float(matValue) / DITHER_ELEMENT_RANGE / DITHER_LINEAR_COLORSPACE_COLORS;\r\n}\r\n\r\n/**\r\n * Add some random value to each pixel,\r\n * hoping it would make it different than neighbours\r\n */\r\nvec3 doDither (vec3 originalColor, float strength) {\r\n  float ditherMod = getDitherMatrixMod() * strength;\r\n  return originalColor + ditherMod;\r\n}\r\n\r\n\r\nvec3 tonemapLinear(vec3 hdrColor) {\r\n  return u_exposure * hdrColor;\r\n}\r\n\r\nvec3 tonemapReinhard(vec3 hdrColor) {\r\n  hdrColor *= u_exposure;\r\n  return hdrColor / (hdrColor + vec3(1.0));\r\n}\r\n\r\nfloat A = 0.15;\r\nfloat B = 0.50;\r\nfloat C = 0.10;\r\nfloat D = 0.20;\r\nfloat E = 0.02;\r\nfloat F = 0.30;\r\nfloat W = 11.2;\r\nvec3 Uncharted2Tonemap(vec3 x) {\r\n  return max(\r\n    ((x * (A * x + C * B) + D * E) / (x * (A * x + B) + D * F)) - E / F,\r\n    vec3(0.0)\r\n  );\r\n}\r\n\r\nvec3 tonemapUncharted2(vec3 hdrColor) {\r\n\thdrColor *= u_exposure;\r\n  vec3 denom = Uncharted2Tonemap(vec3(u_whitePoint));\r\n\treturn Uncharted2Tonemap(hdrColor) / denom;\r\n}\r\n\r\nvec3 tonemapPhotographic(vec3 hdrColor) {\r\n  float Lm = 0.5 * (max3(hdrColor) + min3(hdrColor));\r\n  float mod1 = Lm / (1.0 + Lm);\r\n  float mod2 = 1.0 + Lm / (u_whitePoint * u_whitePoint);\r\n  return hdrColor / Lm * mod1 * mod2;\r\n}\r\n\r\nvec3 tonemapACES(vec3 hdrColor) {\r\n  // https://www.desmos.com/calculator/h8rbdpawxj\r\n  // https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\r\n  // https://www.youtube.com/watch?v=A-wectYNfRQ\r\n  // https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/ACES.ush , tho not that useful\r\n  float a = 2.51f;\r\n  float b = 0.03f;\r\n  float c = 2.43f;\r\n  float d = 0.59f;\r\n  float e = 0.14f;\r\n  vec3 x = hdrColor * u_acesC;\r\n\r\n  vec3 nom = x * (a * x + b);\r\n  vec3 denom = x * (c * x + d) + e;\r\n  vec3 aces = nom / denom;\r\n\r\n  return aces * u_acesS;\r\n}\r\n\r\n/*\r\n  Don't ask me what is going on in this file. Copied straight from UE4.\r\n  I probably better get some book on the subject. Any recommendations?\r\n  Honeslty, I'm not even sure everythin is 100% in the right color space.\r\n\r\n  @see vec3 ColorCorrectAll( vec3 WorkingColor )\r\n    in Engine\\Shaders\\Private\\PostProcessCombineLUTs.usf\r\n    in release-4.22.0 #7d9919ac7bfd80b7483012eab342cb427d60e8c9\r\n*/\r\n\r\n\r\n// const defined in:\r\n// Engine\\Shaders\\Private\\ACES.ush\r\nconst vec3 AP1_RGB2Y = vec3(\r\n\t0.2722287168,\r\n\t0.6740817658,\r\n\t0.0536895174\r\n);\r\n\r\n\r\nuniform vec4 u_colorSaturation;\r\nuniform vec4 u_colorContrast;\r\nuniform vec4 u_colorGamma;\r\nuniform vec4 u_colorGain;\r\nuniform vec4 u_colorOffset;\r\n\r\nuniform vec4 u_colorSaturationShadows;\r\nuniform vec4 u_colorContrastShadows;\r\nuniform vec4 u_colorGammaShadows;\r\nuniform vec4 u_colorGainShadows;\r\nuniform vec4 u_colorOffsetShadows;\r\n\r\nuniform vec4 u_colorSaturationMidtones;\r\nuniform vec4 u_colorContrastMidtones;\r\nuniform vec4 u_colorGammaMidtones;\r\nuniform vec4 u_colorGainMidtones;\r\nuniform vec4 u_colorOffsetMidtones;\r\n\r\nuniform vec4 u_colorSaturationHighlights;\r\nuniform vec4 u_colorContrastHighlights;\r\nuniform vec4 u_colorGammaHighlights;\r\nuniform vec4 u_colorGainHighlights;\r\nuniform vec4 u_colorOffsetHighlights;\r\n\r\nuniform float u_colorCorrectionShadowsMax;\r\nuniform float u_colorCorrectionHighlightsMin;\r\n\r\n\r\nvec3 colorCorrect(\r\n  vec3 WorkingColor,\r\n\tvec4 ColorSaturation,\r\n\tvec4 ColorContrast,\r\n\tvec4 ColorGamma,\r\n\tvec4 ColorGain,\r\n\tvec4 ColorOffset\r\n) {\r\n\tfloat Luma = dot(WorkingColor, AP1_RGB2Y);\r\n\tWorkingColor = max(vec3(0.0), mix(\r\n    vec3(Luma, Luma, Luma),\r\n    WorkingColor,\r\n    ColorSaturation.xyz * ColorSaturation.w\r\n  ));\r\n\tWorkingColor = pow(WorkingColor * (1.0 / 0.18), ColorContrast.xyz * ColorContrast.w) * 0.18;\r\n\tWorkingColor = pow(WorkingColor, 1.0 / (ColorGamma.xyz * ColorGamma.w) );\r\n\tWorkingColor = WorkingColor * (ColorGain.xyz * ColorGain.w) + (ColorOffset.xyz + ColorOffset.w);\r\n\treturn WorkingColor;\r\n}\r\n\r\n// Nuke-style Color Correct\r\nvec3 colorCorrectAll(vec3 WorkingColor) {\r\n\tfloat Luma = dot(WorkingColor, AP1_RGB2Y);\r\n\r\n\t// Shadow CC\r\n\tvec3 CCColorShadows = colorCorrect(\r\n    WorkingColor,\r\n\t\tu_colorSaturationShadows * u_colorSaturation,\r\n\t\tu_colorContrastShadows * u_colorContrast,\r\n\t\tu_colorGammaShadows * u_colorGamma,\r\n\t\tu_colorGainShadows * u_colorGain,\r\n\t\tu_colorOffsetShadows + u_colorOffset);\r\n\tfloat CCWeightShadows = 1.0 - smoothstep(0.0, u_colorCorrectionShadowsMax, Luma);\r\n\r\n\t// Highlight CC\r\n\tvec3 CCColorHighlights = colorCorrect(\r\n    WorkingColor,\r\n\t\tu_colorSaturationHighlights * u_colorSaturation,\r\n\t\tu_colorContrastHighlights * u_colorContrast,\r\n\t\tu_colorGammaHighlights * u_colorGamma,\r\n\t\tu_colorGainHighlights * u_colorGain,\r\n\t\tu_colorOffsetHighlights + u_colorOffset);\r\n\tfloat CCWeightHighlights = smoothstep(u_colorCorrectionHighlightsMin, 1.0, Luma);\r\n\r\n\t// Midtone CC\r\n\tvec3 CCColorMidtones = colorCorrect(\r\n    WorkingColor,\r\n\t\tu_colorSaturationMidtones * u_colorSaturation,\r\n\t\tu_colorContrastMidtones * u_colorContrast,\r\n\t\tu_colorGammaMidtones * u_colorGamma,\r\n\t\tu_colorGainMidtones * u_colorGain,\r\n\t\tu_colorOffsetMidtones + u_colorOffset);\r\n\tfloat CCWeightMidtones = 1.0 - CCWeightShadows - CCWeightHighlights;\r\n\r\n\t// Blend Shadow, Midtone and Highlight CCs\r\n\tvec3 WorkingColorSMH =\r\n    CCColorShadows * CCWeightShadows +\r\n    CCColorMidtones * CCWeightMidtones +\r\n    CCColorHighlights * CCWeightHighlights;\r\n\r\n\treturn WorkingColorSMH;\r\n}\r\n\r\n\r\nconst int TONEMAP_LINEAR = 0;\r\nconst int TONEMAP_REINHARD = 1;\r\nconst int TONEMAP_U2 = 2;\r\nconst int TONEMAP_PHOTOGRAPHIC = 3;\r\nconst int TONEMAP_ACES = 4;\r\n\r\n\r\nvec3 doTonemapping(int tonemapMode, vec3 hdrColor) {\r\n  switch (tonemapMode) {\r\n    case TONEMAP_U2: return Uncharted2Tonemap(hdrColor);\r\n    case TONEMAP_LINEAR: return tonemapLinear(hdrColor);\r\n    case TONEMAP_PHOTOGRAPHIC: return tonemapPhotographic(hdrColor);\r\n    case TONEMAP_REINHARD: return tonemapReinhard(hdrColor);\r\n    default:\r\n    case TONEMAP_ACES: return tonemapACES(hdrColor);\r\n  }\r\n}\r\n\r\n\r\nvoid main() {\r\n  vec2 pixelTS = to_0_1(v_position);\r\n  vec3 colorHDR = texture(u_source, pixelTS).rgb;\r\n\r\n  // do dithering to break up banding\r\n  colorHDR = doDither(colorHDR, u_ditherStrength);\r\n\r\n  // color grade raw HDR\r\n  // In old days we used LUTs for this, but LUTs require conversion to LDR.\r\n  // Since HDR displays are now available, we do color grading in HDR,\r\n  // skipping LDR conversion. This, and also cause we can.\r\n  vec3 colorAfterColorGrading = colorCorrectAll(colorHDR);\r\n\r\n  outColor.rgb = saturate(\r\n    doTonemapping(u_tonemappingMode, colorAfterColorGrading)\r\n  );\r\n\r\n  float luma = toLuma_fromLinear(outColor.rgb);\r\n  // just SOME gamma, does not matter exact. We need to convert into SOME perceptual space\r\n  outColor.a = doGamma(luma, u_gamma);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp sampler2D;\r\n\r\nuniform sampler2D u_sourceTex;\r\nuniform sampler2D u_linearDepthTex;\r\nuniform float u_sssWidth;\r\n// Direction of the blur:\r\n//   - First pass:   float2(1.0, 0.0)\r\n//   - Second pass:  float2(0.0, 1.0)\r\nuniform vec2 u_sssDirection;\r\n// replaced macros:\r\nuniform float u_sssStrength; // SSSS_STREGTH_SOURCE\r\nuniform int u_sssFollowSurface; // SSSS_FOLLOW_SURFACE: 0 or 1\r\nuniform float u_sssFovy; // SSSS_FOVY 20.0\r\n\r\n\r\n\r\nin vec2 v_position;\r\n\r\nlayout(location = 0) out vec4 outColor1;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n\r\nfloat SSSSS_sampleDepthLinear (sampler2D depthTex, vec2 texcoord) {\r\n  return texture(u_linearDepthTex, texcoord).r;\r\n}\r\n\r\n#define SSSS_GLSL_3 1\r\n/**\r\n * Copyright (C) 2012 Jorge Jimenez (jorge@iryoku.com)\r\n * Copyright (C) 2012 Diego Gutierrez (diegog@unizar.es)\r\n * All rights reserved.\r\n *\r\n * Redistribution and use in source and binary forms, with or without\r\n * modification, are permitted provided that the following conditions are met:\r\n *\r\n *    1. Redistributions of source code must retain the above copyright notice,\r\n *       this list of conditions and the following disclaimer.\r\n *\r\n *    2. Redistributions in binary form must reproduce the following disclaimer\r\n *       in the documentation and/or other materials provided with the\r\n *       distribution:\r\n *\r\n *       \"Uses Separable SSS. Copyright (C) 2012 by Jorge Jimenez and Diego\r\n *        Gutierrez.\"\r\n *\r\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ``AS\r\n * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\r\n * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\r\n * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL COPYRIGHT HOLDERS OR CONTRIBUTORS\r\n * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\r\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\r\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\r\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\r\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\r\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\r\n * POSSIBILITY OF SUCH DAMAGE.\r\n *\r\n * The views and conclusions contained in the software and documentation are\r\n * those of the authors and should not be interpreted as representing official\r\n * policies, either expressed or implied, of the copyright holders.\r\n */\r\n\r\n\r\n/**\r\n *                  _______      _______      _______      _______\r\n *                 /       |    /       |    /       |    /       |\r\n *                |   (----    |   (----    |   (----    |   (----\r\n *                 \\   \\        \\   \\        \\   \\        \\   \\\r\n *              ----)   |    ----)   |    ----)   |    ----)   |\r\n *             |_______/    |_______/    |_______/    |_______/\r\n *\r\n *        S E P A R A B L E   S U B S U R F A C E   S C A T T E R I N G\r\n *\r\n *                           http://www.iryoku.com/\r\n *\r\n * Hi, thanks for your interest in Separable SSS!\r\n *\r\n * It's a simple shader composed of two components:\r\n *\r\n * 1) A transmittance function, 'SSSSTransmittance', which allows to calculate\r\n *    light transmission in thin slabs, useful for ears and nostrils. It should\r\n *    be applied during the main rendering pass as follows:\r\n *\r\n *        float3 t = albedo.rgb * lights[i].color * attenuation * spot;\r\n *        color.rgb += t * SSSSTransmittance(...)\r\n *\r\n *    (See 'Main.fx' for more details).\r\n *\r\n * 2) A simple two-pass reflectance post-processing shader, 'SSSSBlur*', which\r\n *    softens the skin appearance. It should be applied as a regular\r\n *    post-processing effect like bloom (the usual framebuffer ping-ponging):\r\n *\r\n *    a) The first pass (horizontal) must be invoked by taking the final color\r\n *       framebuffer as input, and storing the results into a temporal\r\n *       framebuffer.\r\n *    b) The second pass (vertical) must be invoked by taking the temporal\r\n *       framebuffer as input, and storing the results into the original final\r\n *       color framebuffer.\r\n *\r\n *    Note that This SSS filter should be applied *before* tonemapping.\r\n *\r\n * Before including SeparableSSS.h you'll have to setup the target. The\r\n * following targets are available:\r\n *         SMAA_HLSL_3\r\n *         SMAA_HLSL_4\r\n *         SMAA_GLSL_3\r\n *\r\n * For more information of what's under the hood, you can check the following\r\n * URLs (but take into account that the shader has evolved a little bit since\r\n * these publications):\r\n *\r\n * 1) Reflectance: http://www.iryoku.com/sssss/\r\n * 2) Transmittance: http://www.iryoku.com/translucency/\r\n *\r\n * If you've got any doubts, just contact us!\r\n */\r\n\r\n\r\n //-----------------------------------------------------------------------------\r\n // Porting Functions\r\n\r\n #ifdef SSSS_HLSL_3\r\n #define SSSSTexture2D sampler2D\r\n #define SSSSSampleLevelZero(tex, coord) tex2Dlod(tex, float4(coord, 0.0, 0.0))\r\n #define SSSSSampleLevelZeroPoint(tex, coord) tex2Dlod(tex, float4(coord, 0.0, 0.0))\r\n #define SSSSSample(tex, coord) tex2D(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) tex2D(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) tex2Dlod(tex, float4(coord + offset * SSSS_PIXEL_SIZE, 0.0, 0.0))\r\n #define SSSSSampleOffset(tex, coord, offset) tex2D(tex, coord + offset * SSSS_PIXEL_SIZE)\r\n #define SSSSLerp(a, b, t) lerp(a, b, t)\r\n #define SSSSSaturate(a) saturate(a)\r\n #define SSSSMad(a, b, c) mad(a, b, c)\r\n #define SSSSMul(v, m) mul(v, m)\r\n #define SSSS_FLATTEN [flatten]\r\n #define SSSS_BRANCH [branch]\r\n #define SSSS_UNROLL [unroll]\r\n #endif\r\n #ifdef SSSS_HLSL_4\r\n SamplerState LinearSampler { Filter = MIN_MAG_LINEAR_MIP_POINT; AddressU = Clamp; AddressV = Clamp; };\r\n SamplerState PointSampler { Filter = MIN_MAG_MIP_POINT; AddressU = Clamp; AddressV = Clamp; };\r\n #define SSSSTexture2D Texture2D\r\n #define SSSSSampleLevelZero(tex, coord) tex.SampleLevel(LinearSampler, coord, 0)\r\n #define SSSSSampleLevelZeroPoint(tex, coord) tex.SampleLevel(PointSampler, coord, 0)\r\n #define SSSSSample(tex, coord) SSSSSampleLevelZero(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) SSSSSampleLevelZeroPoint(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) tex.SampleLevel(LinearSampler, coord, 0, offset)\r\n #define SSSSSampleOffset(tex, coord, offset) SSSSSampleLevelZeroOffset(tex, coord, offset)\r\n #define SSSSLerp(a, b, t) lerp(a, b, t)\r\n #define SSSSSaturate(a) saturate(a)\r\n #define SSSSMad(a, b, c) mad(a, b, c)\r\n #define SSSSMul(v, m) mul(v, m)\r\n #define SSSS_FLATTEN [flatten]\r\n #define SSSS_BRANCH [branch]\r\n #define SSSS_UNROLL [unroll]\r\n #endif\r\n #ifdef SSSS_GLSL_3\r\n #define SSSSTexture2D sampler2D\r\n #define SSSSSampleLevelZero(tex, coord) textureLod(tex, coord, 0.0)\r\n #define SSSSSampleLevelZeroPoint(tex, coord) textureLod(tex, coord, 0.0)\r\n #define SSSSSample(tex, coord) texture(tex, coord)\r\n #define SSSSSamplePoint(tex, coord) texture(tex, coord)\r\n #define SSSSSampleLevelZeroOffset(tex, coord, offset) textureLodOffset(tex, coord, 0.0, offset)\r\n #define SSSSSampleOffset(tex, coord, offset) texture(tex, coord, offset)\r\n #define SSSSLerp(a, b, t) mix(a, b, t)\r\n #define SSSSSaturate(a) clamp(a, 0.0, 1.0)\r\n #define SSSSMad(a, b, c) (a * b + c)\r\n #define SSSSMul(v, m) (m * v)\r\n #define SSSS_FLATTEN\r\n #define SSSS_BRANCH\r\n #define SSSS_UNROLL\r\n #define float2 vec2\r\n #define float3 vec3\r\n #define float4 vec4\r\n #define int2 ivec2\r\n #define int3 ivec3\r\n #define int4 ivec4\r\n #define float4x4 mat4x4\r\n #endif\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Configurable Defines\r\n\r\n/**\r\n * SSSS_FOV must be set to the value used to render the scene.\r\n */\r\n#ifndef SSSS_FOVY\r\n#define SSSS_FOVY 20.0\r\n#endif\r\n\r\n/**\r\n * Light diffusion should occur on the surface of the object, not in a screen\r\n * oriented plane. Setting SSSS_FOLLOW_SURFACE to 1 will ensure that diffusion\r\n * is more accurately calculated, at the expense of more memory accesses.\r\n */\r\n#ifndef SSSS_FOLLOW_SURFACE\r\n#define SSSS_FOLLOW_SURFACE 0\r\n#endif\r\n\r\n/**\r\n * This define allows to specify a different source for the SSS strength\r\n * (instead of using the alpha channel of the color framebuffer). This is\r\n * useful when the alpha channel of the mian color buffer is used for something\r\n * else.\r\n */\r\n#ifndef SSSS_STREGTH_SOURCE\r\n#define SSSS_STREGTH_SOURCE (colorM.a)\r\n#endif\r\n\r\n/**\r\n * If SSSS_N_SAMPLES is defined at this point, a custom filter kernel must be\r\n * set by the runtime.\r\n */\r\n#ifdef SSSS_N_SAMPLES\r\n/**\r\n * Filter kernel layout is as follows:\r\n *   - Weights in the RGB channels.\r\n *   - Offsets in the A channel.\r\n */\r\nfloat4 kernel[SSSS_N_SAMPLES];\r\n#else\r\n/**\r\n * Here you have ready-to-use kernels for quickstarters. Three kernels are\r\n * readily available, with varying quality.\r\n * To create new kernels take a look into SSS::calculateKernel, or simply\r\n * push CTRL+C in the demo to copy the customized kernel into the clipboard.\r\n *\r\n * Note: these preset kernels are not used by the demo. They are calculated on\r\n * the fly depending on the selected values in the interface, by directly using\r\n * SSS::calculateKernel.\r\n *\r\n * Quality ranges from 0 to 2, being 2 the highest quality available.\r\n * The quality is with respect to 1080p; for 720p Quality=0 suffices.\r\n */\r\n#define SSSS_QUALITY 1\r\n\r\n#if SSSS_QUALITY == 2\r\n#define SSSS_N_SAMPLES 25\r\nfloat4 kernel[] = float4[](\r\n    float4(0.530605, 0.613514, 0.739601, 0),\r\n    float4(0.000973794, 1.11862e-005, 9.43437e-007, -3),\r\n    float4(0.00333804, 7.85443e-005, 1.2945e-005, -2.52083),\r\n    float4(0.00500364, 0.00020094, 5.28848e-005, -2.08333),\r\n    float4(0.00700976, 0.00049366, 0.000151938, -1.6875),\r\n    float4(0.0094389, 0.00139119, 0.000416598, -1.33333),\r\n    float4(0.0128496, 0.00356329, 0.00132016, -1.02083),\r\n    float4(0.017924, 0.00711691, 0.00347194, -0.75),\r\n    float4(0.0263642, 0.0119715, 0.00684598, -0.520833),\r\n    float4(0.0410172, 0.0199899, 0.0118481, -0.333333),\r\n    float4(0.0493588, 0.0367726, 0.0219485, -0.1875),\r\n    float4(0.0402784, 0.0657244, 0.04631, -0.0833333),\r\n    float4(0.0211412, 0.0459286, 0.0378196, -0.0208333),\r\n    float4(0.0211412, 0.0459286, 0.0378196, 0.0208333),\r\n    float4(0.0402784, 0.0657244, 0.04631, 0.0833333),\r\n    float4(0.0493588, 0.0367726, 0.0219485, 0.1875),\r\n    float4(0.0410172, 0.0199899, 0.0118481, 0.333333),\r\n    float4(0.0263642, 0.0119715, 0.00684598, 0.520833),\r\n    float4(0.017924, 0.00711691, 0.00347194, 0.75),\r\n    float4(0.0128496, 0.00356329, 0.00132016, 1.02083),\r\n    float4(0.0094389, 0.00139119, 0.000416598, 1.33333),\r\n    float4(0.00700976, 0.00049366, 0.000151938, 1.6875),\r\n    float4(0.00500364, 0.00020094, 5.28848e-005, 2.08333),\r\n    float4(0.00333804, 7.85443e-005, 1.2945e-005, 2.52083),\r\n    float4(0.000973794, 1.11862e-005, 9.43437e-007, 3)\r\n);\r\n#elif SSSS_QUALITY == 1\r\n#define SSSS_N_SAMPLES 17\r\nfloat4 kernel[] = float4[](\r\n    float4(0.536343, 0.624624, 0.748867, 0),\r\n    float4(0.00317394, 0.000134823, 3.77269e-005, -2),\r\n    float4(0.0100386, 0.000914679, 0.000275702, -1.53125),\r\n    float4(0.0144609, 0.00317269, 0.00106399, -1.125),\r\n    float4(0.0216301, 0.00794618, 0.00376991, -0.78125),\r\n    float4(0.0347317, 0.0151085, 0.00871983, -0.5),\r\n    float4(0.0571056, 0.0287432, 0.0172844, -0.28125),\r\n    float4(0.0582416, 0.0659959, 0.0411329, -0.125),\r\n    float4(0.0324462, 0.0656718, 0.0532821, -0.03125),\r\n    float4(0.0324462, 0.0656718, 0.0532821, 0.03125),\r\n    float4(0.0582416, 0.0659959, 0.0411329, 0.125),\r\n    float4(0.0571056, 0.0287432, 0.0172844, 0.28125),\r\n    float4(0.0347317, 0.0151085, 0.00871983, 0.5),\r\n    float4(0.0216301, 0.00794618, 0.00376991, 0.78125),\r\n    float4(0.0144609, 0.00317269, 0.00106399, 1.125),\r\n    float4(0.0100386, 0.000914679, 0.000275702, 1.53125),\r\n    float4(0.00317394, 0.000134823, 3.77269e-005, 2)\r\n);\r\n#elif SSSS_QUALITY == 0\r\n#define SSSS_N_SAMPLES 11\r\nfloat4 kernel[] = float4[](\r\n    float4(0.560479, 0.669086, 0.784728, 0),\r\n    float4(0.00471691, 0.000184771, 5.07566e-005, -2),\r\n    float4(0.0192831, 0.00282018, 0.00084214, -1.28),\r\n    float4(0.03639, 0.0130999, 0.00643685, -0.72),\r\n    float4(0.0821904, 0.0358608, 0.0209261, -0.32),\r\n    float4(0.0771802, 0.113491, 0.0793803, -0.08),\r\n    float4(0.0771802, 0.113491, 0.0793803, 0.08),\r\n    float4(0.0821904, 0.0358608, 0.0209261, 0.32),\r\n    float4(0.03639, 0.0130999, 0.00643685, 0.72),\r\n    float4(0.0192831, 0.00282018, 0.00084214, 1.28),\r\n    float4(0.00471691, 0.000184771, 5.07565e-005, 2)\r\n);\r\n#else\r\n#error Quality must be one of {0,1,2}\r\n#endif\r\n#endif\r\n\r\n\r\n// Translucency profile weights and variances\r\n// float3 weights[5];\r\n// float3 variances[5];\r\n\r\nfloat maxOffsetMm;\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Separable SSS Transmittance Function\r\n\r\nfloat3 SSSSTransmittance(\r\n   // This parameter allows to control the transmittance effect. Its range\r\n   // should be 0..1. Higher values translate to a stronger effect.\r\n  float translucency,\r\n  // This parameter should be the same as the 'SSSSBlurPS' one. See below\r\n  // for more details.\r\n  float sssWidth,\r\n  // Position in world space.\r\n  float3 worldPosition,\r\n  // Normal in world space.\r\n  float3 worldNormal,\r\n  // Light vector: lightWorldPosition - worldPosition.\r\n  float3 light,\r\n  // Linear 0..1 shadow map.\r\n  SSSSTexture2D shadowMap,\r\n  // Regular world to light space matrix.\r\n  float4x4 lightViewProjection,\r\n  // Far plane distance used in the light projection matrix.\r\n  float lightFarPlane,\r\n  // custom params:\r\n  float sssBias,\r\n  float sssGain\r\n) {\r\n  // Calculate the scale of the effect.\r\n  float scale = sssWidth * (1.0 - translucency); // sssWidth in  mm / world space unit\r\n\r\n  // First we shrink the position inwards the surface to avoid artifacts:\r\n  // (Note that this can be done once for all the lights)\r\n  // NOTE: sssBias = 0.005\r\n  float4 shrinkedPos = float4(worldPosition - sssBias * worldNormal, 1.0);\r\n\r\n  // Now we calculate the thickness from the light point of view:\r\n  float4 shadowPosition = SSSSMul(shrinkedPos, lightViewProjection); // NOPE, shadowMatrix also has model matrix!\r\n  shadowPosition.xyz = shadowPosition.xyz / shadowPosition.w;\r\n  shadowPosition.xyz = to_0_1(shadowPosition.xyz);\r\n  float d1 = SSSSSample(shadowMap, shadowPosition.xy).r; // 'd1' has a range of 0..1\r\n  float d2 = shadowPosition.z; // 'd2' has a range of 0..'lightFarPlane'\r\n  // thickness - distance between:\r\n  //   * pixel world position\r\n  //   * projected point from light point of view\r\n  float d = scale * abs(d1 - d2);\r\n  d *= lightFarPlane;\r\n\r\n  // Armed with the thickness, we can now calculate the color by means of the\r\n  // precalculated transmittance profile.\r\n  // (It can be precomputed into a texture, for maximum performance):\r\n  float dd = -d * d;\r\n\r\n  // UE4: Engine/Shaders/Private/SeparableSSS.ush\r\n  float3 profile =\r\n    float3(0.233, 0.455, 0.649) * exp(dd / 0.0064) +\r\n    float3(0.1,   0.336, 0.344) * exp(dd / 0.0484) +\r\n    float3(0.118, 0.198, 0.0  ) * exp(dd / 0.187)  +\r\n    float3(0.113, 0.007, 0.007) * exp(dd / 0.567)  +\r\n    float3(0.358, 0.004, 0.0  ) * exp(dd / 1.99)   +\r\n    float3(0.078, 0.0,   0.0  ) * exp(dd / 7.41);\r\n\r\n  // Using the profile, we finally approximate the transmitted lighting from\r\n  // the back of the object:\r\n  // NOTE: sssGain = 0.3\r\n  // we negate normal, cause we are interested in FORWARD scattering\r\n  return profile * SSSSSaturate(sssGain + dot(light, -worldNormal));\r\n}\r\n\r\n\r\n\r\n//-----------------------------------------------------------------------------\r\n// Separable SSS Reflectance Pixel Shader\r\n\r\n\r\nfloat4 SSSSBlurPS(\r\n  // The usual quad texture coordinates.\r\n  float2 texcoord,\r\n  /**\r\n   * This is a SRGB or HDR color input buffer, which should be the final\r\n   * color frame, resolved in case of using multisampling. The desired\r\n   * SSS strength should be stored in the alpha channel (1 for full\r\n   * strength, 0 for disabling SSS). If this is not possible, you an\r\n   * customize the source of this value using SSSS_STREGTH_SOURCE.\r\n   *\r\n   * When using non-SRGB buffers, you\r\n   * should convert to linear before processing, and back again to gamma\r\n   * space before storing the pixels (see Chapter 24 of GPU Gems 3 for\r\n   * more info)\r\n   *\r\n   * IMPORTANT: WORKING IN A NON-LINEAR SPACE WILL TOTALLY RUIN SSS!\r\n   */\r\n  SSSSTexture2D colorTex,\r\n  // The linear depth buffer of the scene, resolved in case of using\r\n  // multisampling. The resolve should be a simple average to avoid\r\n  // artifacts in the silhouette of objects.\r\n  SSSSTexture2D depthTex,\r\n  // This parameter specifies the global level of subsurface scattering\r\n  // or, in other words, the width of the filter. It's specified in\r\n  // mm / world space unit.\r\n  float sssWidth,\r\n  // Direction of the blur:\r\n  //   - First pass:   float2(1.0, 0.0)\r\n  //   - Second pass:  float2(0.0, 1.0)\r\n  float2 dir,\r\n  // replaced macros:\r\n  float sssFovy,\r\n  float sssStrength,\r\n  bool sssFollowSurface\r\n) {\r\n  // NOTE: UE4 calcualtes some of params on CPU, see:\r\n  // Engine/Source/Runtime/Renderer/Private/PostProcess/PostProcessSubsurface.cpp\r\n  // Engine/Shaders/Private/PostProcessSubsurface.usf\r\n  // Engine/Shaders/Private/SeparableSSS.ush\r\n\r\n  // Fetch color of current pixel:\r\n  float4 colorM = SSSSSamplePoint(colorTex, texcoord);\r\n\r\n  // Fetch linear depth of current pixel:\r\n  // NOTE: LINEAR DEPTH!\r\n  float depthM = SSSSS_sampleDepthLinear(depthTex, texcoord);\r\n\r\n  // Calculate the sssWidth scale (1.0 for a unit plane sitting on the\r\n  // projection window):\r\n  float distanceToProjectionWindow = 1.0 / tan(0.5 * radians(sssFovy));\r\n  float scale = distanceToProjectionWindow / depthM;\r\n\r\n\t// Calculate the final step to fetch the surrounding pixels:\r\n  float2 finalStep = scale * dir;\r\n  finalStep *= sssStrength; // Modulate it using the alpha channel.\r\n  finalStep *= 1.0 / (2.0 * sssWidth); // sssWidth in mm / world space unit, divided by 2 as uv coords are from [0 1]\r\n\r\n  // Accumulate the center sample:\r\n  float4 colorBlurred = colorM;\r\n  colorBlurred.rgb *= kernel[0].rgb;\r\n\r\n  // Accumulate the other samples:\r\n  SSSS_UNROLL\r\n  for (int i = 1; i < SSSS_N_SAMPLES; i++) {\r\n    // Fetch color and depth for current sample:\r\n    float2 offset = texcoord + kernel[i].a * finalStep;\r\n    float4 color = SSSSSample(colorTex, offset);\r\n\r\n    if (sssFollowSurface) {\r\n      // If the difference in depth is huge, we lerp color back to \"colorM\":\r\n      float depth = SSSSS_sampleDepthLinear(depthTex, offset);\r\n\r\n      // Original:\r\n      // float s = SSSSSaturate(\r\n        // abs(depthM - depth) / (distanceToProjectionWindow * (maxOffsetMm / sssWidth))\r\n      // );\r\n      // s = min(1.0, s * 1.5); // custom / user definable scaling\r\n      // UE4:\r\n      float s = saturate(12.0f / 400.0f * sssWidth * abs(depthM - depth));\r\n\r\n      color.rgb = SSSSLerp(color.rgb, colorM.rgb, s);\r\n    }\r\n\r\n    // Accumulate:\r\n    colorBlurred.rgb += kernel[i].rgb * color.rgb;\r\n  }\r\n\r\n  return colorBlurred;\r\n}\r\n\r\n\r\nvoid main() {\r\n  vec2 posTextureSpace = to_0_1(v_position.xy);\r\n\r\n  vec4 result = SSSSBlurPS(\r\n    posTextureSpace, // float2 texcoord,\r\n    u_sourceTex, // SSSSTexture2D colorTex,\r\n    u_linearDepthTex, // SSSSTexture2D depthTex,\r\n    u_sssWidth, // float sssWidth,\r\n    u_sssDirection, // float2 dir\r\n    u_sssFovy, u_sssStrength, u_sssFollowSurface != 0 // replaced macros\r\n  );\r\n\r\n  outColor1 = vec4(result.rgb, 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp sampler2D;\r\n\r\n// depth in perspective projection, will be converted to linear later\r\nuniform sampler2D u_depthPerspTex;\r\nuniform vec2 u_nearAndFar;\r\n\r\n\r\nin vec2 v_position;\r\n\r\n// NOTE: this will be in [zNear...zFar], not [0..1] !!!\r\nlayout(location = 0) out vec4 outColor1;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n\r\n\r\nvoid main() {\r\n  vec2 texcoord = to_0_1(v_position.xy);\r\n  float depth = texture(u_depthPerspTex, texcoord).r;\r\n  float linearDepth = linearizeDepth(depth, u_nearAndFar);\r\n  outColor1 = vec4(vec3(linearDepth), 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\n\r\n\r\nuniform mat4 u_directionalShadowMatrix_VP;\r\n\r\nlayout(location=0) in vec3 in_Position;\r\n\r\nflat out int v_hairInstanceId;\r\nout float v_vertexRootToTipFactor;\r\nout vec3 v_position;\r\nout vec3 v_normal;\r\nout vec3 v_tangent;\r\nout vec4 v_positionLightShadowSpace;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n// https://github.com/Scthe/TressFX-OpenGL/blob/master/src/shaders/gl-tfx/lib/TressFXStrands.glsl\r\n\r\n#define TRESSFX_FLOAT_EPSILON 1e-7\r\n\r\n\r\n///////// uniforms\r\n\r\nuniform mat4 u_mMat;\r\nuniform mat4 u_vpMat;\r\nuniform vec3 u_cameraPosition;\r\nuniform vec2 u_viewportSize;\r\nuniform vec3 u_centerOfGravity;\r\n// data buffers\r\nuniform sampler2D u_vertexPositionsBuffer;\r\nuniform sampler2D u_vertexTangentsBuffer;\r\n// tfx params\r\nuniform int u_numVerticesPerStrand;\r\nuniform float u_thinTip;\r\nuniform float u_fiberRadius;\r\nuniform uint u_followHairs;\r\nuniform float u_followHairSpreadRoot;\r\nuniform float u_followHairSpreadTip;\r\n\r\nconst float EXPAND_PIXELS_FACTOR = 0.71;\r\n\r\n\r\n///////// END: uniforms\r\n\r\n\r\nivec2 getVertexPositionCoords(uint offset) {\r\n  uvec2 texSize = uvec2(textureSize(u_vertexPositionsBuffer, 0));\r\n  return ivec2(offset % texSize.x, offset / texSize.x);\r\n}\r\n\r\nvec2 safeNormalize(vec2 vec) {\r\n  float len = length(vec);\r\n  return len >= TRESSFX_FLOAT_EPSILON ? normalize(vec) : vec2(0, 0);\r\n}\r\n\r\nvec3 safeNormalize(vec3 vec) {\r\n  float len = length(vec);\r\n  return len >= TRESSFX_FLOAT_EPSILON ? normalize(vec) : vec3(0, 0, 0);\r\n}\r\n\r\n/** Returns 1.0 for root vertex, 0.0 for last vertex in strand and values betweeen for others */\r\nfloat getVertexInStrandPercentage (uint index) {\r\n  uint vertexId = index % uint(u_numVerticesPerStrand); // [0-32]\r\n  return 1.0 - (float(vertexId) / float(u_numVerticesPerStrand)); // [0-1]\r\n}\r\n\r\n\r\nstruct TressFXVertex {\r\n  vec4 position; // projected\r\n  vec4 positionWorldSpace;\r\n  vec3 normal;\r\n  vec3 tangent;\r\n  float vertexRootToTipFactor; // 1 := root, 0: = tip\r\n};\r\n\r\nstruct TressFXParams {\r\n  uint vertexId;\r\n  uint instanceId;\r\n  uint strandId;\r\n\r\n  vec3 eye;\r\n  mat4 modelMat;\r\n  mat4 viewProjMat;\r\n  vec2 viewportSize;\r\n\r\n  float thinTip;\r\n  float fiberRadius;\r\n  float followHairSpreadRoot;\r\n  float followHairSpreadTip;\r\n};\r\n\r\nTressFXParams createTfxParams() {\r\n  TressFXParams params;\r\n  params.vertexId = uint(gl_VertexID);\r\n  params.instanceId = uint(gl_InstanceID);\r\n  params.strandId = uint(gl_VertexID / 2 / u_numVerticesPerStrand);\r\n\r\n  params.eye = u_cameraPosition;\r\n  params.modelMat = u_mMat;\r\n  params.viewProjMat = u_vpMat;\r\n  params.viewportSize = u_viewportSize;\r\n\r\n  params.thinTip = u_thinTip;\r\n  params.fiberRadius = u_fiberRadius;\r\n  params.followHairSpreadRoot = u_followHairSpreadRoot;\r\n  params.followHairSpreadTip = u_followHairSpreadTip;\r\n\r\n  return params;\r\n}\r\n\r\n\r\nvec3 randomizeStrandPos(uint instanceId, uint strandId, uint rngFac) {\r\n  vec3 seed = vec3(\r\n    float(instanceId),\r\n    float(strandId),\r\n    float(rngFac) + float(instanceId / 2u) + float(instanceId / 3u)\r\n  );\r\n  vec3 v = hash(seed);\r\n  return to_neg1_1(normalize(v));\r\n}\r\n\r\nvec3 getFollowHairDisplacement (\r\n  TressFXParams params, float vertex_position, vec3 tangent\r\n) {\r\n  if (params.instanceId == 0u) {\r\n    // not required, but why not? It should stick in the middle of follow-hair group\r\n    return vec3(0.0);\r\n  }\r\n\r\n  vec3 rootOffset = randomizeStrandPos(params.instanceId, params.strandId, 1u);\r\n  vec3 tipOffset = randomizeStrandPos(params.instanceId, params.strandId, 2u);\r\n  rootOffset *= params.followHairSpreadRoot;\r\n  tipOffset *= params.followHairSpreadTip;\r\n  return mix(tipOffset, rootOffset, vertex_position);\r\n\r\n  /*\r\n  // TODO make this around normal, so the hair does stay near skull\r\n  vec3 offset = mix(tipOffset, rootOffset, vertex_position);\r\n  vec3 normal   = normalize(offset - tangent * dot(offset, tangent));\r\n  vec3 bitangent = cross(normal, tangent);\r\n\r\n  float offsetMod = mix(params.followHairSpreadTip, params.followHairSpreadRoot, vertex_position);\r\n  return bitangent * offsetMod;\r\n  // return bitangent * params.followHairSpreadRoot;\r\n  // return rootOffset * params.followHairSpreadRoot;\r\n  */\r\n}\r\n\r\n\r\nTressFXVertex getExpandedTressFXVert(TressFXParams params) {\r\n  // Access the current line segment\r\n  // We will move vertices left or right by hair thickness:\r\n  //   - odd vertices are moved left,\r\n  //   - even are moved right.\r\n  // And by 'left' and 'right' we mean according to normal&tangent.\r\n  // And by normal we mean (hair_pos - camera_pos)\r\n  uint index = params.vertexId / 2u;  // vertexId is actually the indexed vertex id when indexed triangles are used\r\n\r\n  // Get updated positions and tangents from simulation result\r\n  ivec2 vertexSamplePos = getVertexPositionCoords(index);\r\n  vec3 v = texelFetch(u_vertexPositionsBuffer, vertexSamplePos, 0).xyz;\r\n  vec3 t = texelFetch(u_vertexTangentsBuffer, vertexSamplePos, 0).xyz;\r\n  v = (params.modelMat * vec4(v, 1.0)).xyz; // transform to world space\r\n  t = normalize(t); // not needed for cross, but useful for debugging\r\n\r\n  // Get hair strand thickness\r\n  float vertex_position = getVertexInStrandPercentage(index); // 1 := root, 0 := tip\r\n  float ratio = mix(params.thinTip, 1.0, vertex_position);\r\n\r\n  v += getFollowHairDisplacement(params, vertex_position, t);\r\n\r\n  // Calculate right and projected right vectors\r\n  vec3 towardsCamera = safeNormalize(v - params.eye);\r\n  vec3 right = safeNormalize(cross(t, towardsCamera));\r\n\r\n  // debug\r\n  // v = v + t * (params.thinTip * 0.1);\r\n  // v = v + towardsCamera * (params.thinTip * 0.1);\r\n  // v = v + right * (params.thinTip * 0.1);\r\n\r\n  // Calculate the negative and positive offset screenspace positions\r\n  vec4 hairEdgePositions[2]; // 0 is for odd vertexId, 1 is positive even vertexId\r\n  vec3 thicknessVector = right * ratio * params.fiberRadius;\r\n  hairEdgePositions[0] = vec4(v - thicknessVector, 1.0); // position 'left'\r\n  hairEdgePositions[1] = vec4(v + thicknessVector, 1.0); // position 'right'\r\n\r\n  // Write output data\r\n  TressFXVertex result;\r\n\tbool isOdd = (params.vertexId & 0x01u) > 0u;\r\n  result.positionWorldSpace = (isOdd ? hairEdgePositions[0] : hairEdgePositions[1]); // may not be 100% accurate with fixes below\r\n  result.position = params.viewProjMat * result.positionWorldSpace;\r\n  result.tangent = t;\r\n  result.vertexRootToTipFactor = vertex_position;\r\n  // result.normal = towardsCamera; // ?! might as well.\r\n  // result.normal = normalize(result.positionWorldSpace.xyz - v);\r\n  result.normal = normalize(result.positionWorldSpace.xyz - u_centerOfGravity);\r\n\r\n  // some additional fixing\r\n  {\r\n    vec2 proj_right = (params.viewProjMat * vec4(right, 0)).xy;\r\n    proj_right = safeNormalize(proj_right);\r\n\r\n    float fDirIndex = isOdd ? -1.0 : 1.0;\r\n    vec4 tmp = vec4(proj_right * EXPAND_PIXELS_FACTOR / params.viewportSize.y, 0.0f, 0.0f);\r\n    float w = isOdd ? hairEdgePositions[0].w : hairEdgePositions[1].w;\r\n    result.position += fDirIndex * tmp * w;\r\n  }\r\n\r\n  return result;\r\n}\r\n\r\n// END TressFXStrands.glsl\r\n\r\n\r\n\r\n\r\nvoid main() {\r\n  TressFXParams tfxParams = createTfxParams();\r\n  TressFXVertex tressfxVert = getExpandedTressFXVert(tfxParams);\r\n\r\n  gl_Position = tressfxVert.position;\r\n\r\n  v_hairInstanceId = gl_InstanceID;\r\n  v_vertexRootToTipFactor = tressfxVert.vertexRootToTipFactor;\r\n  v_positionLightShadowSpace = u_directionalShadowMatrix_VP * tressfxVert.positionWorldSpace;\r\n  v_position = tressfxVert.positionWorldSpace.xyz;\r\n  v_normal = tressfxVert.normal;\r\n  v_tangent = tressfxVert.tangent;\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n// precision highp sampler2D;\r\n\r\nuniform int u_displayMode;\r\nuniform vec3 u_cameraPosition;\r\nuniform vec2 u_viewportSize;\r\n// ao\r\nuniform sampler2D u_aoTex;\r\nuniform float u_aoStrength;\r\nuniform float u_aoExp;\r\n// Shadow\r\nuniform sampler2D u_directionalShadowDepthTex;\r\nuniform vec4 u_directionalShadowCasterPosition; // [position.xyz, bias (negative if pcss)]\r\nuniform int u_directionalShadowSampleRadius;\r\nuniform float u_maxShadowContribution;\r\n#define BIAS_FROM_UI (u_directionalShadowCasterPosition.w)\r\n#define USE_PCSS_SHADOWS (u_directionalShadowCasterPosition.w < 0.0f)\r\n// Lights\r\nuniform vec4 u_lightAmbient;\r\nuniform vec3 u_light0_Position;\r\nuniform vec4 u_light0_Color;\r\nuniform vec3 u_light1_Position;\r\nuniform vec4 u_light1_Color;\r\nuniform vec3 u_light2_Position;\r\nuniform vec4 u_light2_Color;\r\n// material\r\nuniform vec3 u_specularColor1;\r\nuniform vec3 u_specularColor2;\r\nuniform vec3 u_albedo;\r\nuniform float u_primaryShift;\r\nuniform float u_secondaryShift;\r\nuniform float u_specularPower1;\r\nuniform float u_specularPower2;\r\nuniform float u_specularStrength1;\r\nuniform float u_specularStrength2;\r\n\r\n\r\nflat in int v_hairInstanceId;\r\nin float v_vertexRootToTipFactor;\r\nin vec3 v_position;\r\nin vec3 v_normal;\r\nin vec3 v_tangent;\r\nin vec4 v_positionLightShadowSpace;\r\n\r\nlayout(location = 0) out vec4 outColor1;\r\nlayout(location = 1) out vec4 outColor2;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\nstruct Material {\r\n  vec3 positionWS;\r\n  vec3 normal;\r\n  vec3 toEye;\r\n  // pbr\r\n  vec3 albedo;\r\n  float roughness;\r\n  float specularMul; // needed for eyes. Normally You create separate mesh etc, but I'm too lazy\r\n  float isMetallic;\r\n  float ao;\r\n  // shadow\r\n  float shadow; // 0.0 - in shadow, 1.0 - in light\r\n  float hairShadow; // 0.0 - in shadow, 1.0 - in light. This is special Sintel texture!!!\r\n};\r\n\r\nstruct Light {\r\n  vec3 position;\r\n  vec3 color;\r\n  float intensity;\r\n};\r\n\r\nLight unpackLight(vec3 pos, vec4 color) {\r\n  Light light;\r\n  light.position = pos;\r\n  light.color = color.rgb;\r\n  light.intensity = color.a;\r\n  return light;\r\n}\r\n\r\n\r\n/// utils:\r\n\r\n/* Some custom AO handling - specific to this demo */\r\nfloat getCustom_AO(float ao, float aoStrength, float aoExp) {\r\n  ao = 1.0 - pow(1.0 - ao, aoExp);\r\n  return mix(ao, 1.0, 1.0 - aoStrength);\r\n}\r\n // for light struct\r\n/** returns inShadow(1.0) or notInShadow(0.0) */\r\n/*\r\nfloat calculateDirectionalShadow(vec4 lightPosInterp, vec3 normal, vec3 toShadowCaster) {\r\n  vec3 lightPosProj = lightPosInterp.xyz / lightPosInterp.w; // not build-in gl_Position. Useless for ORTHO, only PERSP.\r\n  lightPosProj = lightPosProj * 0.5 + 0.5; // from opengl [-1, 1] to depth-texture-like [0..1]\r\n\r\n  // depth from shadow map\r\n  float shadowMapDepth = texture(u_directionalShadowDepthTex, lightPosProj.xy).r;\r\n  // depth of current fragment (we multiplied by light-shadow matrix\r\n  // in vert. shader, did w-divide here)\r\n  float fragmentDepth = lightPosProj.z;\r\n\r\n  // GDC_Poster_NormalOffset.png\r\n  float bias = max(0.05 * (1.0 - dot(normal, toShadowCaster)), 0.005);\r\n\r\n  // There are following cases:\r\n  //  * fragmentDepth > shadowMapDepth\r\n  //      there exist some object that is closer to shadow source than object\r\n  //      Means object is IN SHADOW\r\n  //  * fragmentDepth == shadowMapDepth\r\n  //      this is the object that casts the shadow\r\n  //      Means NO SHADOW\r\n  //  * fragmentDepth < shadowMapDepth\r\n  //      would probably happen if object is not shadow-caster\r\n  //      Means NO SHADOW\r\n  return fragmentDepth - bias > shadowMapDepth  ? 1.0 : 0.0;\r\n}\r\n*/\r\n\r\nconst float IN_SHADOW = 1.0f;\r\nconst float NOT_IN_SHADOW = 0.0f;\r\n\r\n// settings\r\nconst float PCSS_PENUMBRA_WIDTH = 10.0;\r\nconst int PCSS_PENUMBRA_BASE = 1; // we want at least some blur\r\n\r\nfloat sampleShadowMap (int sampleRadius, vec3 lightPosProj, float bias) {\r\n  // depth of current fragment (we multiplied by light-shadow matrix\r\n  // in vert. shader, did w-divide here)\r\n  float fragmentDepth = lightPosProj.z;\r\n\r\n  float shadow = 0.0;\r\n  vec2 texelSize = 1.0 / vec2(textureSize(u_directionalShadowDepthTex, 0));\r\n  for (int x = -sampleRadius; x <= sampleRadius; ++x) {\r\n    for (int y = -sampleRadius; y <= sampleRadius; ++y) {\r\n      // depth from shadow map\r\n      float shadowMapDepth = texture(\r\n        u_directionalShadowDepthTex,\r\n        lightPosProj.xy + vec2(x, y) * texelSize\r\n      ).r;\r\n\r\n      // There are following cases:\r\n      //  * fragmentDepth > shadowMapDepth\r\n      //      there exist some object that is closer to shadow source than object\r\n      //      Means object is IN SHADOW\r\n      //  * fragmentDepth == shadowMapDepth\r\n      //      this is the object that casts the shadow\r\n      //      Means NO SHADOW\r\n      //  * fragmentDepth < shadowMapDepth\r\n      //      would probably happen if object is not shadow-caster\r\n      //      Means NO SHADOW\r\n      shadow += fragmentDepth - bias > shadowMapDepth  ? IN_SHADOW : NOT_IN_SHADOW;\r\n    }\r\n  }\r\n\r\n  float pcfTmp = float(sampleRadius * 2 + 1);\r\n  return shadow /= pcfTmp * pcfTmp;\r\n}\r\n\r\nfloat calculateDirectionalShadow(vec4 lightPosInterp, vec3 normal, vec3 toShadowCaster) {\r\n  // position of fragment as rendered from light POV\r\n  vec3 lightPosProj = lightPosInterp.xyz / lightPosInterp.w; // Useless for ORTHO, only PERSP.\r\n  lightPosProj = to_0_1(lightPosProj); // from opengl [-1, 1] to depth-texture-like [0..1]\r\n\r\n  // Special case if we went beyond the far plane of the frustum.\r\n  // Mark no shadow, cause it's better than dark region\r\n  // far away (or whatever relative light-camera postion is)\r\n  if (lightPosProj.z > 1.0) {\r\n    return NOT_IN_SHADOW;\r\n  }\r\n  // would cause 'invalid' sampling, mark as no shadow too.\r\n  if (outOfScreen(lightPosProj.xy)) {\r\n    return NOT_IN_SHADOW;\r\n  }\r\n\r\n  // GDC_Poster_NormalOffset.png\r\n  float bias = max(abs(BIAS_FROM_UI) * (1.0 - dot(normal, toShadowCaster)), 0.005);\r\n\r\n  if (USE_PCSS_SHADOWS) {\r\n    // PCSS\r\n    float fragmentDepth = lightPosProj.z;\r\n    float shadowMapDepth = texture(u_directionalShadowDepthTex, lightPosProj.xy).r; // sample center\r\n    float depthDiff = max(fragmentDepth - shadowMapDepth, 0.0);\r\n    int sampleRadius = PCSS_PENUMBRA_BASE + int(depthDiff / shadowMapDepth * PCSS_PENUMBRA_WIDTH);\r\n    return sampleShadowMap(sampleRadius, lightPosProj, bias);\r\n  } else {\r\n    // PCF\r\n    return sampleShadowMap(u_directionalShadowSampleRadius, lightPosProj, bias);\r\n  }\r\n}\r\n\r\n// http://developer.amd.com/wordpress/media/2012/10/Scheuermann_HairRendering.pdf\r\n// http://www.cemyuksel.com/courses/conferences/siggraph2010-hair/S2010_HairCourseNotes-Chapter4.pdf\r\n\r\nstruct KajiyaKayParams {\r\n  vec3 V; // viewDir\r\n  vec3 T; // tangentDir\r\n  vec3 N; // normalDir\r\n  vec3 L; // lightDirection\r\n\r\n  float shift; // specMap, [0..1], probably should be random\r\n  float primaryShift;\r\n  float secondaryShift;\r\n  float specularPower1;\r\n  float specularPower2;\r\n};\r\n\r\nvec3 shiftTangent(vec3 t, vec3 n, float shift) {\r\n  // vec3 shiftedT = (u_primaryShift OR u_secondaryShift + shift) * params.N\r\n  vec3 shiftedT = t + shift * n;\r\n  return normalize(shiftedT);\r\n}\r\n\r\nfloat strandSpecular(vec3 H, vec3 T, float specularPower) {\r\n  float dotTH = dot(T, H);\r\n  float sinTH = sqrt(1.0 - dotTH * dotTH); // from `sin^2 + cos^2 = 1`\r\n  float dirAtten = smoothstep(-1.0, 0.0, dotTH);\r\n  return dirAtten * pow(sinTH, specularPower);\r\n  // dbg:\r\n  // return dirAtten;\r\n  // return dotTH;\r\n  // return abs(T.x);\r\n  // return abs(T.y);\r\n  // return abs(T.z);\r\n  // return length(T) / 5.0;\r\n  // return pow(length(T) / 5.0, 2.0);\r\n}\r\n\r\nvec2 kajiyakay(KajiyaKayParams params) {\r\n  // using the binormal instead of Tangent since that goes root to tip\r\n  vec3 binormalDir = normalize(cross(params.T, params.N));\r\n\r\n  // shift the tangent via spec map\r\n  // TODO use tangent or binormalDir?\r\n  // vec3 tangent1 = shiftTangent(binormalDir, params.N, params.primaryShift + params.shift);\r\n  // vec3 tangent2 = shiftTangent(binormalDir, params.N, params.secondaryShift + params.shift);\r\n  vec3 tangent1 = shiftTangent(params.T, params.N, params.shift + params.primaryShift);\r\n  vec3 tangent2 = shiftTangent(params.T, params.N, params.shift + params.secondaryShift);\r\n  // vec3 tangent1 = params.T;\r\n  // vec3 tangent2 = params.T;\r\n\r\n  // 2 shifted specular terms, retuned as x,y components\r\n  vec3 H = normalize(params.V + params.L);\r\n  vec2 spec = vec2(0.0, 0.0);\r\n  spec.x = strandSpecular(H, tangent1, params.specularPower1);\r\n  spec.y = strandSpecular(H, tangent2, params.specularPower2);\r\n\r\n  return saturate(spec);\r\n}\r\n\r\n\r\n\r\nconst int DISPLAY_MODE_FINAL = 0;\r\nconst int DISPLAY_MODE_FLAT = 1;\r\nconst int DISPLAY_MODE_FOLLOW_GROUPS = 2;\r\nconst int DISPLAY_MODE_ROOT_TIP_PERCENTAGE = 3;\r\nconst int DISPLAY_MODE_SHADOW = 4;\r\n\r\n\r\nvec3 getColorFromInstance (int instanceId) {\r\n  switch (instanceId) {\r\n    case 1: return vec3(0.0, 1.0, 0.0);\r\n    case 2: return vec3(0.0, 0.0, 1.0);\r\n    case 3: return vec3(1.0, 1.0, 0.0);\r\n    case 4: return vec3(0.0, 1.0, 1.0);\r\n    case 5: return vec3(1.0, 0.0, 1.0);\r\n    case 6: return vec3(1.0, 1.0, 1.0);\r\n    case 7: return vec3(0.0, 0.0, 0.0);\r\n    case 8: return vec3(0.0, 0.5, 0.0);\r\n    case 9: return vec3(0.5, 0.5, 0.5);\r\n    case 10: return vec3(0.0, 0.0, 0.5);\r\n    case 11: return vec3(0.5, 0.5, 0.0);\r\n    case 12: return vec3(0.0, 0.5, 0.5);\r\n    case 13: return vec3(0.5, 0.0, 0.5);\r\n\r\n    default:\r\n    case 0: return vec3(1.0, 0.0, 0.0);\r\n  }\r\n}\r\n\r\nfloat calculateShadow () {\r\n  vec3 toCaster = normalize(u_directionalShadowCasterPosition.xyz - v_position);\r\n  vec3 normal = normalize(v_normal); // TODO use tangent per http://developer.amd.com/wordpress/media/2012/10/Scheuermann_HairRendering.pdf s7?\r\n  return 1.0 - calculateDirectionalShadow(\r\n    v_positionLightShadowSpace, normal, toCaster\r\n  );\r\n}\r\n\r\n\r\nKajiyaKayParams createKajiyakayParams() {\r\n  KajiyaKayParams params;\r\n  params.V = normalize(u_cameraPosition - v_position); // viewDir\r\n  params.T = normalize(v_tangent); // tangentDir\r\n  params.N = normalize(v_normal); // normalDir\r\n  // params.L // filled later\r\n\r\n  params.shift = 0.0; // TODO\r\n  params.primaryShift = u_primaryShift;\r\n  params.secondaryShift = u_secondaryShift;\r\n  params.specularPower1 = u_specularPower1;\r\n  params.specularPower2 = u_specularPower2;\r\n  return params;\r\n}\r\n\r\n\r\nvec3 doShading(Light lights[3]) {\r\n  vec3 ambient = u_lightAmbient.rgb * u_lightAmbient.a;\r\n  vec3 radianceSum = vec3(0.0);\r\n  KajiyaKayParams params = createKajiyakayParams();\r\n\r\n  for (uint i = 0u; i < 3u; i++) {\r\n    Light light = lights[i];\r\n    vec3 L = normalize(light.position - v_position); // wi in integral\r\n    // float NdotL = dotMax0(v_normal, L); // no, cause it's hair\r\n    float NdotL = dotMax0(v_tangent, L);\r\n    vec3 radiance = light.color * light.intensity; // incoming color from light\r\n\r\n    // specular\r\n    params.L = L;\r\n    vec2 specularHighlight = kajiyakay(params);\r\n    vec3 specular1 = specularHighlight.x * u_specularColor1 * u_specularStrength1;\r\n    vec3 specular2 = specularHighlight.y * u_specularColor2 * u_specularStrength2;\r\n\r\n    // combine\r\n    // NOTE: this is different then usual Kajiya-Kay, I like it more\r\n    vec3 fr = u_albedo * NdotL + specular1 + specular2;\r\n    radianceSum += fr * radiance;\r\n\r\n    // debug:\r\n    // radianceSum += u_albedo * NdotL * radiance;\r\n    // radianceSum += NdotL;\r\n    // radianceSum += specularHighlight.x;\r\n    // radianceSum += specularHighlight.y;\r\n    // radianceSum += specular1;\r\n    // radianceSum += specular2;\r\n    // radianceSum += specular1 + specular2;\r\n  }\r\n\r\n  // ambient occlusion\r\n  float ao = texture(u_aoTex, gl_FragCoord.xy / u_viewportSize).r;\r\n  ao = getCustom_AO(ao, u_aoStrength, u_aoExp);\r\n  radianceSum *= ao;\r\n  ambient *= ao;\r\n\r\n  float shadow = calculateShadow();\r\n  radianceSum = radianceSum * clamp(shadow, 1.0 - u_maxShadowContribution, 1.0);\r\n  return ambient + radianceSum;\r\n}\r\n\r\n\r\nvoid main() {\r\n  Light lights[3];\r\n  lights[0] = unpackLight(u_light0_Position, u_light0_Color);\r\n  lights[1] = unpackLight(u_light1_Position, u_light1_Color);\r\n  lights[2] = unpackLight(u_light2_Position, u_light2_Color);\r\n\r\n  vec3 result;\r\n\r\n  switch (u_displayMode) {\r\n    case DISPLAY_MODE_FOLLOW_GROUPS: {\r\n      result = getColorFromInstance(v_hairInstanceId);\r\n      break;\r\n    }\r\n\r\n    case DISPLAY_MODE_ROOT_TIP_PERCENTAGE: {\r\n      result = vec3(v_vertexRootToTipFactor);\r\n      // result = mix(vec3(0.0, 1.0, 1.0), vec3(0.0, 1.0, 0.0), v_vertexRootToTipFactor);\r\n      // result += getColorFromInstance(v_hairInstanceId);\r\n      break;\r\n    }\r\n\r\n    case DISPLAY_MODE_SHADOW: {\r\n      float shadow = calculateShadow();\r\n      result = vec3(shadow);\r\n      break;\r\n    }\r\n\r\n    case DISPLAY_MODE_FLAT: {\r\n      result = vec3(0.8);\r\n      break;\r\n    }\r\n\r\n    default:\r\n    case DISPLAY_MODE_FINAL: {\r\n      result = doShading(lights);\r\n      break;\r\n    }\r\n  }\r\n\r\n  outColor1 = vec4(result, 1.0);\r\n  outColor2 = vec4(to_0_1(normalize(v_normal)), 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp sampler2D;\r\n\r\n\r\nuniform sampler2D u_sceneDepthTex; // in perpective projection\r\nuniform sampler2D u_normalTex;\r\nuniform sampler2D u_noiseTex;\r\nuniform vec2 u_noiseScale;\r\nuniform mat4 u_invProjectionMat; // inverse projection matrix\r\nuniform mat4 u_viewMat;\r\nuniform mat4 u_projection;\r\nuniform int u_kernelSize;\r\nuniform float u_radius;\r\nuniform float u_bias;\r\nuniform vec3 u_kernel[256];\r\n\r\nin vec2 v_position;\r\n\r\nlayout(location = 0) out vec4 outColor1;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n\r\n\r\nvec3 positionVS_FromCoords(in vec2 texCoord) {\r\n  float depth = texture(u_sceneDepthTex, texCoord).r;\r\n  vec3 texSpace = vec3(texCoord, depth);\r\n  vec4 clipSpace = vec4(to_neg1_1(texSpace), 1);\r\n  vec4 viewPos = u_invProjectionMat * clipSpace;\r\n  return viewPos.xyz / viewPos.w;\r\n}\r\n\r\n\r\n// @see https://learnopengl.com/Advanced-Lighting/SSAO\r\nvoid main() {\r\n  vec2 posTextureSpace = to_0_1(v_position.xy);\r\n\r\n  vec3 fragPosVS = positionVS_FromCoords(posTextureSpace);\r\n\r\n  vec3 normalWS = texture(u_normalTex, posTextureSpace).rgb;\r\n  normalWS = normalize(to_neg1_1(normalWS));\r\n  vec3 normalVS = (u_viewMat * vec4(normalWS, 1.0)).xyz;\r\n  normalVS = normalize(normalVS);\r\n\r\n  vec3 randomVec = texture(u_noiseTex, posTextureSpace * u_noiseScale).xyz;\r\n  randomVec = normalize(randomVec);\r\n\r\n  // Gram-Schmidt process\r\n  // @see http://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process\r\n  vec3 tangent = normalize(randomVec - normalVS * dot(randomVec, normalVS));\r\n  vec3 bitangent = cross(normalVS, tangent);\r\n  mat3 TBN = mat3(tangent, bitangent, normalVS);\r\n\r\n  float occlusion = 0.0;\r\n  for(int i = 0; i < u_kernelSize; i++) {\r\n    float radius = u_radius; // TODO make depth-independent\r\n\r\n    // get sample position\r\n    vec3 sampleVS = TBN * u_kernel[i]; // From tangent to view-space\r\n    sampleVS = fragPosVS + sampleVS * radius;\r\n\r\n    vec4 offset = vec4(sampleVS, 1.0);\r\n    offset      = u_projection * offset;    // from view to clip-space\r\n    offset.xyz /= offset.w;\r\n    offset.xyz  = to_0_1(offset.xyz);\r\n\r\n    float sampleDepth = positionVS_FromCoords(offset.xy).z;\r\n    // occlusion += sampleDepth >= sampleVS.z + u_bias ? 1.0 : 0.0;\r\n    float rangeCheck = smoothstep(0.0, 1.0, radius / abs(fragPosVS.z - sampleDepth));\r\n    occlusion += (sampleDepth >= sampleVS.z + u_bias ? 1.0 : 0.0) * rangeCheck;\r\n  }\r\n\r\n  occlusion = occlusion / (float(u_kernelSize) - 1.0);\r\n  outColor1 = vec4(vec3(1.0 - occlusion), 1.0);\r\n}\r\n"},function(e,t){e.exports="#version 300 es\r\nprecision highp float;\r\nprecision highp int;\r\nprecision highp usampler2D;\r\n\r\n\r\nuniform sampler2D u_sourceTex;\r\nuniform sampler2D u_linearDepthTex;\r\nuniform float u_blurRadius;\r\nuniform float u_depthMaxDist;\r\nuniform vec2 u_direction;\r\n// The sigma value for the gaussian function: higher value means more blur\r\n// A good value for 9x9 is around 3 to 5\r\n// A good value for 7x7 is around 2.5 to 4\r\n// A good value for 5x5 is around 2 to 3.5\r\nuniform float u_gaussSigma;\r\n\r\n\r\nin vec2 v_position; // TexCoords\r\n\r\nlayout(location = 0) out vec4 outColor;\r\n\r\n\r\nconst float PI = 3.14159265359;\n\nvec2 fixOpenGLTextureCoords_AxisY(vec2 uv) {\n  return vec2(uv.x, 1.0 - uv.y);\n}\n\nfloat doGamma (float color, float gammaValue) {\n  return pow(color, 1.0 / gammaValue);\n}\nvec3 doGamma (vec3 color, float gammaValue) {\n  return pow(color, vec3(1.0 / gammaValue));\n}\nfloat sRGBtoLinear (float color, float gammaValue) {\n  // http://renderwonk.com/blog/index.php/archive/adventures-with-gamma-correct-rendering/\n  if (color > 0.04045) {\n    float n = color + 0.055;\n    return pow(n / 1.055, gammaValue);\n  }\n  return color / 12.92;\n}\nvec3 sRGBtoLinear (vec3 color, float gammaValue) {\n  return vec3(\n    sRGBtoLinear(color.r, gammaValue),\n    sRGBtoLinear(color.g, gammaValue),\n    sRGBtoLinear(color.b, gammaValue)\n  );\n}\n/*\n// OR: https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/GammaCorrectionCommon.ush\nhalf3 sRGBToLinear( half3 Color ) {\n\tColor = max(6.10352e-5, Color); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)\n\treturn Color > 0.04045 ? pow( Color * (1.0 / 1.055) + 0.0521327, 2.4 ) : Color * (1.0 / 12.92);\n}*/\n\n\nfloat toLuma_fromGamma (vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.299f, 0.587f, 0.114f);\n  return dot(toLumaCoef, rgbCol);\n}\n\nfloat toLuma_fromLinear(vec3 rgbCol) {\n  vec3 toLumaCoef = vec3(0.2126729f,  0.7151522f, 0.0721750f);\n  return dot(toLumaCoef, rgbCol);\n}\n\n\nfloat dotMax0 (vec3 n, vec3 toEye){\n  return max(0.0, dot(n, toEye));\n}\n\nbool outOfScreen (vec2 coord) {\n  return coord.x < 0.0 ||\n         coord.x > 1.0 ||\n         coord.y < 0.0 ||\n         coord.y > 1.0;\n}\n\n/** https://learnopengl.com/Advanced-OpenGL/Depth-testing */\nfloat linearizeDepth(float depth, vec2 nearAndFar) {\n  float near = nearAndFar.x;\n  float far = nearAndFar.y;\n  float z = depth * 2.0 - 1.0; // back to NDC\n  return (2.0 * near * far) / (far + near - z * (far - near));\n}\n\n\n// [0..1] -> [-1..1]\nfloat to_neg1_1 (float v) { return 2.0 * v - 1.0; }\nvec2  to_neg1_1 (vec2  v) { return 2.0 * v - 1.0; }\nvec3  to_neg1_1 (vec3  v) { return 2.0 * v - 1.0; }\nvec4  to_neg1_1 (vec4  v) { return 2.0 * v - 1.0; }\n\n// [-1..1] -> [0..1]\nfloat to_0_1 (float v) { return 0.5 * v + 0.5; }\nvec2 to_0_1  (vec2  v) { return 0.5 * v + 0.5; }\nvec3 to_0_1  (vec3  v) { return 0.5 * v + 0.5; }\nvec4 to_0_1  (vec4  v) { return 0.5 * v + 0.5; }\n\n// [-1..1] -> [0..1]\nfloat saturate (float v) { return clamp(v, 0.0, 1.0); }\nvec2  saturate (vec2  v) { return clamp(v, vec2(0.0, 0.0), vec2(1.0, 1.0)); }\nvec3  saturate (vec3  v) { return clamp(v, vec3(0.0, 0.0, 0.0), vec3(1.0, 1.0, 1.0)); }\nvec4  saturate (vec4  v) { return clamp(v, vec4(0.0, 0.0, 0.0, 0.0), vec4(1.0, 1.0, 1.0, 1.0)); }\n\nfloat max3(vec3 v){ return max(v.x, max(v.y, v.z)); }\nfloat max4(vec4 v){ return max(v.w, max3(v.xyz)); }\n\nfloat min3(vec3 v){ return min(v.x, min(v.y, v.z)); }\nfloat min4(vec4 v){ return min(v.w, min3(v.xyz)); }\n\n/** returns something random */\nvec3 hash(vec3 a) {\n  a = fract(a * vec3(.8, .8, .8));\n  a += dot(a, a.yxz + 19.19);\n  return fract((a.xxy + a.yxx) * a.zyx);\n}\n\n\n/**\n * Example usage:\n * uniform int u_optionFlags;\n * const int FLAG_USE_GAUSS = 1;\n * const int FLAG_USE_ROUGHNESS = 2;\n * ...\n * isFlag(u_optionFlags, FLAG_USE_ROUGHNESS) ? .. : ..;\n*/\n//\nbool isFlag(int flags, int flagValue) {\n  return (flags & flagValue) > 0;\n}\n\r\n\r\n\r\n/** @param offset - offset in pixels from center */\r\nvec2 getSamplePointCoord (vec2 offset) {\r\n  vec2 sourceSize = vec2(textureSize(u_sourceTex, 0));\r\n  return (gl_FragCoord.xy + offset) / sourceSize;\r\n}\r\n\r\n/*\r\nvec4 linearBlur() {\r\n  float m = 1.0f / u_blurRadius;\r\n\r\n  vec2 middleCoord = getSamplePointCoord(vec2(0.0, 0.0));\r\n  vec4 sum = texture(u_sourceTex, middleCoord);\r\n  float weightSum = 0.0;\r\n\r\n  for (float i = 1.0; i <= u_blurRadius; i++) { // from 1 as 0 would be center pixel\r\n    float weight =  1.0 - i * m; // linear\r\n    vec2 sideNegCoord = getSamplePointCoord(-i * u_direction);\r\n    vec2 sidePosCoord = getSamplePointCoord( i * u_direction);\r\n    sum += texture(u_sourceTex, sideNegCoord) * weight;\r\n    sum += texture(u_sourceTex, sidePosCoord) * weight;\r\n    weightSum += 2.0 * weight;\r\n  }\r\n\r\n  return sum / weightSum;\r\n}\r\n*/\r\n\r\n\r\nvec4 sampleWithDepthCompare (vec2 coord, float middleDepth, vec4 middleValue) {\r\n  float sampleDepth = texture(u_linearDepthTex, coord).r;\r\n  float dist = abs(sampleDepth - middleDepth);\r\n  if (dist < u_depthMaxDist) {\r\n    return texture(u_sourceTex, coord);\r\n  } else {\r\n    return middleValue;\r\n  }\r\n}\r\n\r\n/** http://callumhay.blogspot.com/2010/09/gaussian-blur-shader-glsl.html\r\n *  https://github.com/genekogan/Processing-Shader-Examples/blob/master/TextureShaders/data/blur.glsl\r\n */\r\nvec4 gaussianBlur() {\r\n  vec3 incrementalGaussian;\r\n  incrementalGaussian.x = 1.0 / (sqrt(2.0 * PI) * u_gaussSigma);\r\n  incrementalGaussian.y = exp(-0.5 / (u_gaussSigma * u_gaussSigma));\r\n  incrementalGaussian.z = incrementalGaussian.y * incrementalGaussian.y;\r\n\r\n  vec4 sum = vec4(0.0, 0.0, 0.0, 0.0);\r\n  float coefficientSum = 0.0;\r\n\r\n  vec2 middleCoord = getSamplePointCoord(vec2(0.0, 0.0));\r\n  float middleDepth = texture(u_linearDepthTex, middleCoord).r; // [near...far]\r\n  vec4 middleValue = texture(u_sourceTex, middleCoord);\r\n  sum += middleValue * incrementalGaussian.x;\r\n  coefficientSum += incrementalGaussian.x;\r\n  incrementalGaussian.xy *= incrementalGaussian.yz;\r\n\r\n  for (float i = 1.0; i <= u_blurRadius; i++) { // from 1 as 0 would be center pixel\r\n    vec2 sideNegCoord = getSamplePointCoord(-i * u_direction);\r\n    vec2 sidePosCoord = getSamplePointCoord( i * u_direction);\r\n    sum += sampleWithDepthCompare(sideNegCoord, middleDepth, middleValue) * incrementalGaussian.x;\r\n    sum += sampleWithDepthCompare(sidePosCoord, middleDepth, middleValue) * incrementalGaussian.x;\r\n    coefficientSum += 2.0 * incrementalGaussian.x;\r\n    incrementalGaussian.xy *= incrementalGaussian.yz;\r\n  }\r\n\r\n  return sum / coefficientSum;\r\n}\r\n\r\n\r\n\r\nvoid main() {\r\n  // outColor = linearBlur();\r\n  outColor = gaussianBlur();\r\n}\r\n"},function(e,t,n){"use strict";n.r(t);var r=n(1),o=n(0),a=n(2);var i=window.WebGL2RenderingContext;const s=(e,t)=>{const n=e.parentNode;n&&(n.innerHTML=function(e){return'<table style="background-color: #8CE; width: 100%; height: 100%;"><tr><td align="center"><div style="display: table-cell; vertical-align: middle;"><br/><br/><div style="">Status: '+e+"</div></div></td></tr></table>"}(t))},l=(e,t)=>{const n=e.getContext("webgl2",t);if(!(e=>e&&e instanceof WebGL2RenderingContext)(n))throw i?'It doesn\'t appear your computer can support WebGL 2.0.<br/><a href="http://get.webgl.org/troubleshooting/">Click here for more information.</a>':'This page requires a browser that supports WebGL 2.0.<br/><a href="http://get.webgl.org">Click here to upgrade your browser.</a>';return n};var c=n(4);const u=(e,t,n)=>{const r=Object(c.fromValues)(n[0],n[4],n[8],n[12]),o=Object(c.fromValues)(n[1],n[5],n[9],n[13]),a=Object(c.fromValues)(n[2],n[6],n[10],n[14]),i=Object(c.fromValues)(n[3],n[7],n[11],n[15]),s=Object(c.fromValues)(t[0],t[1],t[2],1);return e[0]=Object(c.dot)(s,r),e[1]=Object(c.dot)(s,o),e[2]=Object(c.dot)(s,a),e[3]=Object(c.dot)(s,i),e},d=(e,t,n)=>{const o=f(t,n);return Object(r.multiply)(Object(r.create)(),o,e)},f=(e,t)=>Object(r.multiply)(Object(r.create)(),t,e),h=(e,t,n)=>{void 0===n&&(n=Object.getOwnPropertyDescriptor(e,t));const r=n.value;return n.value=function(){const e=this;if(e.isOk)return r.apply(e,Array.from(arguments));throw`Tried to use invalid ${e.resourceType}`},n};class m{constructor(e,t){this.glId_=null,this.glId_=e,this.resourceType=t,this.uuid=m.nextUUid++}get glId(){return this.glId_}get isOk(){return null!==this.glId_}}m.nextUUid=0;const p=e=>{switch(e){case i.RGBA32I:case i.RGBA32UI:case i.RGBA16I:case i.RGBA16UI:case i.RGBA8I:case i.RGBA8UI:case i.RGB10_A2UI:case i.RG32I:case i.RG32UI:case i.RG16I:case i.RG16UI:case i.RG8I:case i.RG8UI:case i.R32I:case i.R32UI:case i.R16I:case i.R16UI:case i.R8I:case i.R8UI:case i.RGB32I:case i.RGB32UI:case i.RGB16I:case i.RGB16UI:case i.RGB8I:case i.RGB8UI:return!0;default:return!1}};Object(o.fromValues)(1,0,0),Object(o.fromValues)(-1,0,0),Object(o.fromValues)(0,1,0),Object(o.fromValues)(0,-1,0),Object(o.fromValues)(0,0,1),Object(o.fromValues)(0,0,-1),Object(o.fromValues)(0,-1,0),Object(o.fromValues)(0,-1,0),Object(o.fromValues)(0,0,1),Object(o.fromValues)(0,0,-1),Object(o.fromValues)(0,-1,0),Object(o.fromValues)(0,-1,0);var _,v,g=function(e,t,n,r){var o,a=arguments.length,i=a<3?t:null===r?r=Object.getOwnPropertyDescriptor(t,n):r;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)i=Reflect.decorate(e,t,n,r);else for(var s=e.length-1;s>=0;s--)(o=e[s])&&(i=(a<3?o(i):a>3?o(t,n,i):o(t,n))||i);return a>3&&i&&Object.defineProperty(t,n,i),i};(v=_||(_={}))[v.Texture2d=i.TEXTURE_2D]="Texture2d",v[v.TextureCubemap=i.TEXTURE_CUBE_MAP]="TextureCubemap",v[v.Texture3d=i.TEXTURE_3D]="Texture3d",v[v.Texture2dArray=i.TEXTURE_2D_ARRAY]="Texture2dArray";_.Texture2d,_.TextureCubemap,_.Texture3d,_.Texture2dArray;var S,x;(x=S||(S={}))[x.Positive_x=i.TEXTURE_CUBE_MAP_POSITIVE_X]="Positive_x",x[x.Negative_x=i.TEXTURE_CUBE_MAP_NEGATIVE_X]="Negative_x",x[x.Positive_y=i.TEXTURE_CUBE_MAP_POSITIVE_Y]="Positive_y",x[x.Negative_y=i.TEXTURE_CUBE_MAP_NEGATIVE_Y]="Negative_y",x[x.Positive_z=i.TEXTURE_CUBE_MAP_POSITIVE_Z]="Positive_z",x[x.Negative_z=i.TEXTURE_CUBE_MAP_NEGATIVE_Z]="Negative_z";S.Positive_x,S.Negative_x,S.Positive_y,S.Negative_y,S.Positive_z,S.Negative_z;const b=0,y=(e,t)=>{switch(t){case e.DEPTH_COMPONENT16:return{internalformat:e.DEPTH_COMPONENT16,format:e.DEPTH_COMPONENT,type:e.UNSIGNED_SHORT};case e.DEPTH24_STENCIL8:return{internalformat:e.DEPTH24_STENCIL8,format:e.DEPTH_STENCIL,type:e.UNSIGNED_INT_24_8};case e.DEPTH_COMPONENT32F:return{internalformat:e.DEPTH_COMPONENT32F,format:e.DEPTH_COMPONENT,type:e.FLOAT};case e.DEPTH_COMPONENT:case e.DEPTH_STENCIL:case e.UNSIGNED_INT_24_8:case e.UNSIGNED_SHORT:throw["Invalid texture sizedPixelFormat. You probably wanted to create depth buffer.","In that case, use one of [gl.DEPTH_COMPONENT16, gl.DEPTH24_STENCIL8]",`Provided '${t}', which is on the blacklist as invalid depth format`].join("");default:return null}};class w extends m{constructor(e,t,n,r,o,a,i){super(e.createTexture(),"Texture"),this.type=n,this.dimensions=r,this.mipmapLevels=o,this.sizedPixelFormat=a,this.opts=i,this.applyOptions(e,t,this.opts),this.allocate(e)}allocate(e){switch(this.checkAllocationSize(e),this.type){case _.Texture2d:return void this.allocateTeture2d(e,this.type);case _.Texture3d:case _.Texture2dArray:return void e.texStorage3D(this.type,this.mipmapLevels+1,this.sizedPixelFormat,this.width,this.height,this.depth);case _.TextureCubemap:return void this.allocateTeture2d(e,this.type);default:Co()}}allocateTeture2d(e,t){const n=y(e,this.sizedPixelFormat);n?e.texImage2D(t,0,n.internalformat,this.width,this.height,b,n.format,n.type,null):e.texStorage2D(t,this.mipmapLevels+1,this.sizedPixelFormat,this.width,this.height)}checkAllocationSize(e){const t=(e,t)=>{e.every(e=>e<=t)||console.warn(`Tried to allocate texture of size [${e.join(", ")}]px, while max for single dimension is ${t}px. This will not work correctly`)};switch(this.type){case _.Texture2d:case _.TextureCubemap:t([this.width,this.height],e.getParameter(e.MAX_TEXTURE_SIZE));break;case _.Texture3d:t([this.width,this.height,this.depth],e.getParameter(e.MAX_3D_TEXTURE_SIZE));break;case _.Texture2dArray:t([this.width,this.height],e.getParameter(e.MAX_TEXTURE_SIZE)),t([this.depth],e.getParameter(e.MAX_ARRAY_TEXTURE_LAYERS))}}checkIntegerWrite(e){const t=p(this.sizedPixelFormat),n=Eo(e).endsWith("_INTEGER");t&&!n&&console.warn("Texture.write: Tried to write non _INTEGER texture data into texture that uses internally integers")}write(e,t,n,r,o){if(this.isDepth)throw"Tried to write into depth texture. What?";this.checkIntegerWrite(o.unsizedPixelFormat),this.bindAsActive(e,t);const{start:a,dimensions:i}=r,{unsizedPixelFormat:s,perChannelType:l,data:c}=o;switch(this.type){case _.Texture2d:return void e.texSubImage2D(this.type,n,a[0],a[1],i[0],i[1],s,l,c);case _.Texture3d:case _.Texture2dArray:return void e.texSubImage3D(this.type,n,a[0],a[1],a[2],i[0],i[1],i[2],s,l,c);case _.TextureCubemap:return void e.texSubImage2D(o.cubemapSide,n,a[0],a[1],i[0],i[1],s,l,c);default:return void Co()}}get width(){return this.dimensions[0]}get height(){return this.dimensions[1]}get depth(){return this.dimensions[2]}get isDepth(){return[i.DEPTH_COMPONENT16,i.DEPTH24_STENCIL8].includes(this.sizedPixelFormat)}get isDepthStencil(){return[i.DEPTH24_STENCIL8].includes(this.sizedPixelFormat)}bindAsActive(e,t){t.bindSingle(e,this)}destroy(e){this.isOk&&(e.deleteTexture(this.glId),this.glId_=null)}generateMipmaps(e,t){this.bindAsActive(e,t),e.generateMipmap(this.type)}applyOptions(e,t,n){this.bindAsActive(e,t),e.texParameteri(this.type,e.TEXTURE_BASE_LEVEL,n.mipmapBaseLevel),e.texParameteri(this.type,e.TEXTURE_MAX_LEVEL,n.mipmapMaxLevel),e.texParameteri(this.type,e.TEXTURE_MIN_LOD,n.lodMin),e.texParameteri(this.type,e.TEXTURE_MAX_LOD,n.lodMax),e.texParameteri(this.type,e.TEXTURE_MIN_FILTER,n.filterMin),e.texParameteri(this.type,e.TEXTURE_MAG_FILTER,n.filterMag),e.texParameteri(this.type,e.TEXTURE_WRAP_R,n.wrap[0]),e.texParameteri(this.type,e.TEXTURE_WRAP_S,n.wrap[1]),e.texParameteri(this.type,e.TEXTURE_WRAP_T,n.wrap[2])}}var T,E,A,P,M,C;g([h],w.prototype,"write",null),g([h],w.prototype,"bindAsActive",null),g([h],w.prototype,"generateMipmaps",null),g([h],w.prototype,"applyOptions",null),(E=T||(T={}))[E.Nearest=i.NEAREST]="Nearest",E[E.Linear=i.LINEAR]="Linear",E[E.NearestMipmapNearest=i.NEAREST_MIPMAP_NEAREST]="NearestMipmapNearest",E[E.LinearMipmapNearest=i.LINEAR_MIPMAP_NEAREST]="LinearMipmapNearest",E[E.NearestMipmapLinear=i.NEAREST_MIPMAP_LINEAR]="NearestMipmapLinear",E[E.LinearMipmapLinear=i.LINEAR_MIPMAP_LINEAR]="LinearMipmapLinear",(P=A||(A={}))[P.Nearest=i.NEAREST]="Nearest",P[P.Linear=i.LINEAR]="Linear",(C=M||(M={}))[C.UseEdgePixel=i.CLAMP_TO_EDGE]="UseEdgePixel",C[C.MirroredRepeat=i.MIRRORED_REPEAT]="MirroredRepeat",C[C.Repeat=i.REPEAT]="Repeat";const O={mipmapBaseLevel:0,mipmapMaxLevel:1e3,filterMin:T.Linear,filterMag:A.Linear,lodMin:-1e3,lodMax:1e3,wrap:[M.UseEdgePixel,M.UseEdgePixel,M.UseEdgePixel]},R=e=>Object.assign({},O,e);var L=function(e,t){for(var n=-1,r=Array(e);++n<e;)r[n]=t(n);return r};var I=function(e){return e};var N=function(e){return"function"==typeof e?e:I};var D=function(e){var t=typeof e;return null!=e&&("object"==t||"function"==t)},F=n(3),k=F.a.Symbol,B=Object.prototype,V=B.hasOwnProperty,j=B.toString,z=k?k.toStringTag:void 0;var G=function(e){var t=V.call(e,z),n=e[z];try{e[z]=void 0;var r=!0}catch(e){}var o=j.call(e);return r&&(t?e[z]=n:delete e[z]),o},U=Object.prototype.toString;var H=function(e){return U.call(e)},W="[object Null]",Y="[object Undefined]",X=k?k.toStringTag:void 0;var q=function(e){return null==e?void 0===e?Y:W:X&&X in Object(e)?G(e):H(e)};var K=function(e){return null!=e&&"object"==typeof e},$="[object Symbol]";var Q=function(e){return"symbol"==typeof e||K(e)&&q(e)==$},Z=NaN,J=/^\s+|\s+$/g,ee=/^[-+]0x[0-9a-f]+$/i,te=/^0b[01]+$/i,ne=/^0o[0-7]+$/i,re=parseInt;var oe=function(e){if("number"==typeof e)return e;if(Q(e))return Z;if(D(e)){var t="function"==typeof e.valueOf?e.valueOf():e;e=D(t)?t+"":t}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(J,"");var n=te.test(e);return n||ne.test(e)?re(e.slice(2),n?2:8):ee.test(e)?Z:+e},ae=1/0,ie=1.7976931348623157e308;var se=function(e){return e?(e=oe(e))===ae||e===-ae?(e<0?-1:1)*ie:e==e?e:0:0===e?e:0};var le=function(e){var t=se(e),n=t%1;return t==t?n?t-n:t:0},ce=9007199254740991,ue=4294967295,de=Math.min;var fe=function(e,t){if((e=le(e))<1||e>ce)return[];var n=ue,r=de(e,ue);t=N(t),e-=ue;for(var o=L(r,t);++n<e;)t(n);return o};class he{constructor(e){this.bindings=[],this.maxTextures=e.getParameter(e.MAX_COMBINED_TEXTURE_IMAGE_UNITS),this.bindings=fe(this.maxTextures,()=>this.bindings.push(void 0))}getBindingIdx(e){return this.bindings.findIndex(t=>t===e)}bindSingle(e,t){this.assign(e,0,t)}isValidBindingIndex(e){return e>=0&&e<this.maxTextures}replaceTextures(e,t){if(t.length>=this.maxTextures)throw`Tried to bind ${t.length} textures, only ${this.maxTextures} are supported`;const n={},r=[];for(t.forEach(e=>{const t=this.getBindingIdx(e.glId);-1===t?r.push(e):n[e.uuid]=t});r.length>0;){const t=r.pop(),o=this.getNextUnusedBindingIdx(n);if(-1===o)throw"Could not find free texture binding index. This should be impossible";this.assign(e,o,t),n[t.uuid]=o}return n}getNextUnusedBindingIdx(e){const t=Object.values(e);for(let e=0;e<this.maxTextures;e++)if(!t.includes(e))return e;return-1}assign(e,t,n){if(!this.isValidBindingIndex(t))throw`Tried to assign to binding [${t}], max is ${this.maxTextures}`;if(!n.isOk)throw`Tried to bind not allocated texture (${Eo(n.type)})`;e.activeTexture(e.TEXTURE0+t),e.bindTexture(n.type,n.glId),this.bindings[t]=n.glId}}var me,pe,_e,ve,ge=function(e,t,n,r){var o,a=arguments.length,i=a<3?t:null===r?r=Object.getOwnPropertyDescriptor(t,n):r;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)i=Reflect.decorate(e,t,n,r);else for(var s=e.length-1;s>=0;s--)(o=e[s])&&(i=(a<3?o(i):a>3?o(t,n,i):o(t,n))||i);return a>3&&i&&Object.defineProperty(t,n,i),i};(pe=me||(me={}))[pe.VertexBuffer=i.ARRAY_BUFFER]="VertexBuffer",pe[pe.IndexBuffer=i.ELEMENT_ARRAY_BUFFER]="IndexBuffer",pe[pe.ReadFromTextureBuffer=i.PIXEL_PACK_BUFFER]="ReadFromTextureBuffer",pe[pe.WriteIntoTextureBuffer=i.PIXEL_UNPACK_BUFFER]="WriteIntoTextureBuffer",pe[pe.CopyReadBuffer=i.COPY_READ_BUFFER]="CopyReadBuffer",pe[pe.CopyWriteBuffer=i.COPY_WRITE_BUFFER]="CopyWriteBuffer",pe[pe.UniformBuffer=i.UNIFORM_BUFFER]="UniformBuffer",pe[pe.TransformFeedbackBuffer=i.TRANSFORM_FEEDBACK_BUFFER]="TransformFeedbackBuffer",(ve=_e||(_e={}))[ve.STREAM_DRAW=i.STREAM_DRAW]="STREAM_DRAW",ve[ve.STREAM_READ=i.STREAM_READ]="STREAM_READ",ve[ve.STREAM_COPY=i.STREAM_COPY]="STREAM_COPY",ve[ve.STATIC_DRAW=i.STATIC_DRAW]="STATIC_DRAW",ve[ve.STATIC_READ=i.STATIC_READ]="STATIC_READ",ve[ve.STATIC_COPY=i.STATIC_COPY]="STATIC_COPY",ve[ve.DYNAMIC_DRAW=i.DYNAMIC_DRAW]="DYNAMIC_DRAW",ve[ve.DYNAMIC_READ=i.DYNAMIC_READ]="DYNAMIC_READ",ve[ve.DYNAMIC_COPY=i.DYNAMIC_COPY]="DYNAMIC_COPY";const Se=e=>e.offset,xe=e=>e.size;class be extends m{constructor(e,t,n,r){super(e,"Buffer"),this.type=t,this.usage=n,this.bytes=r,this.rangeBytes=(()=>({offset:0,size:this.bytes}))}static fromData(e,t,n,r,o){o||(o={offset:0,size:r.length});const a=new be(e.createBuffer(),t,n,xe(o));return e.bindBuffer(t,a.glId),e.bufferData(t,r,a.usage,Se(o),xe(o)),a}static fromSize(e,t,n,r){const o=new be(e.createBuffer(),t,n,r);return e.bindBuffer(t,o.glId),e.bufferData(t,o.bytes,o.usage),o}bind(e){e.bindBuffer(this.type,this.glId)}destroy(e){this.isOk&&(e.deleteBuffer(this.glId),this.glId_=null)}}ge([h],be.prototype,"bind",null);var ye=function(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(!t(e[n],n,e))return!1;return!0};var we=function(e){return function(t,n,r){for(var o=-1,a=Object(t),i=r(t),s=i.length;s--;){var l=i[e?s:++o];if(!1===n(a[l],l,a))break}return t}}(),Te="[object Arguments]";var Ee=function(e){return K(e)&&q(e)==Te},Ae=Object.prototype,Pe=Ae.hasOwnProperty,Me=Ae.propertyIsEnumerable,Ce=Ee(function(){return arguments}())?Ee:function(e){return K(e)&&Pe.call(e,"callee")&&!Me.call(e,"callee")},Oe=Array.isArray,Re=n(6),Le=9007199254740991,Ie=/^(?:0|[1-9]\d*)$/;var Ne=function(e,t){var n=typeof e;return!!(t=null==t?Le:t)&&("number"==n||"symbol"!=n&&Ie.test(e))&&e>-1&&e%1==0&&e<t},De=9007199254740991;var Fe=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=De},ke={};ke["[object Float32Array]"]=ke["[object Float64Array]"]=ke["[object Int8Array]"]=ke["[object Int16Array]"]=ke["[object Int32Array]"]=ke["[object Uint8Array]"]=ke["[object Uint8ClampedArray]"]=ke["[object Uint16Array]"]=ke["[object Uint32Array]"]=!0,ke["[object Arguments]"]=ke["[object Array]"]=ke["[object ArrayBuffer]"]=ke["[object Boolean]"]=ke["[object DataView]"]=ke["[object Date]"]=ke["[object Error]"]=ke["[object Function]"]=ke["[object Map]"]=ke["[object Number]"]=ke["[object Object]"]=ke["[object RegExp]"]=ke["[object Set]"]=ke["[object String]"]=ke["[object WeakMap]"]=!1;var Be=function(e){return K(e)&&Fe(e.length)&&!!ke[q(e)]};var Ve=function(e){return function(t){return e(t)}},je=n(14),ze=je.a&&je.a.isTypedArray,Ge=ze?Ve(ze):Be,Ue=Object.prototype.hasOwnProperty;var He=function(e,t){var n=Oe(e),r=!n&&Ce(e),o=!n&&!r&&Object(Re.a)(e),a=!n&&!r&&!o&&Ge(e),i=n||r||o||a,s=i?L(e.length,String):[],l=s.length;for(var c in e)!t&&!Ue.call(e,c)||i&&("length"==c||o&&("offset"==c||"parent"==c)||a&&("buffer"==c||"byteLength"==c||"byteOffset"==c)||Ne(c,l))||s.push(c);return s},We=Object.prototype;var Ye=function(e){var t=e&&e.constructor;return e===("function"==typeof t&&t.prototype||We)};var Xe=function(e,t){return function(n){return e(t(n))}}(Object.keys,Object),qe=Object.prototype.hasOwnProperty;var Ke=function(e){if(!Ye(e))return Xe(e);var t=[];for(var n in Object(e))qe.call(e,n)&&"constructor"!=n&&t.push(n);return t},$e="[object AsyncFunction]",Qe="[object Function]",Ze="[object GeneratorFunction]",Je="[object Proxy]";var et=function(e){if(!D(e))return!1;var t=q(e);return t==Qe||t==Ze||t==$e||t==Je};var tt=function(e){return null!=e&&Fe(e.length)&&!et(e)};var nt=function(e){return tt(e)?He(e):Ke(e)};var rt=function(e,t){return function(n,r){if(null==n)return n;if(!tt(n))return e(n,r);for(var o=n.length,a=t?o:-1,i=Object(n);(t?a--:++a<o)&&!1!==r(i[a],a,i););return n}}(function(e,t){return e&&we(e,t,nt)});var ot=function(e,t){var n=!0;return rt(e,function(e,r,o){return n=!!t(e,r,o)}),n};var at=function(){this.__data__=[],this.size=0};var it=function(e,t){return e===t||e!=e&&t!=t};var st=function(e,t){for(var n=e.length;n--;)if(it(e[n][0],t))return n;return-1},lt=Array.prototype.splice;var ct=function(e){var t=this.__data__,n=st(t,e);return!(n<0||(n==t.length-1?t.pop():lt.call(t,n,1),--this.size,0))};var ut=function(e){var t=this.__data__,n=st(t,e);return n<0?void 0:t[n][1]};var dt=function(e){return st(this.__data__,e)>-1};var ft=function(e,t){var n=this.__data__,r=st(n,e);return r<0?(++this.size,n.push([e,t])):n[r][1]=t,this};function ht(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}ht.prototype.clear=at,ht.prototype.delete=ct,ht.prototype.get=ut,ht.prototype.has=dt,ht.prototype.set=ft;var mt=ht;var pt=function(){this.__data__=new mt,this.size=0};var _t=function(e){var t=this.__data__,n=t.delete(e);return this.size=t.size,n};var vt=function(e){return this.__data__.get(e)};var gt,St=function(e){return this.__data__.has(e)},xt=F.a["__core-js_shared__"],bt=(gt=/[^.]+$/.exec(xt&&xt.keys&&xt.keys.IE_PROTO||""))?"Symbol(src)_1."+gt:"";var yt=function(e){return!!bt&&bt in e},wt=Function.prototype.toString;var Tt=function(e){if(null!=e){try{return wt.call(e)}catch(e){}try{return e+""}catch(e){}}return""},Et=/^\[object .+?Constructor\]$/,At=Function.prototype,Pt=Object.prototype,Mt=At.toString,Ct=Pt.hasOwnProperty,Ot=RegExp("^"+Mt.call(Ct).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");var Rt=function(e){return!(!D(e)||yt(e))&&(et(e)?Ot:Et).test(Tt(e))};var Lt=function(e,t){return null==e?void 0:e[t]};var It=function(e,t){var n=Lt(e,t);return Rt(n)?n:void 0},Nt=It(F.a,"Map"),Dt=It(Object,"create");var Ft=function(){this.__data__=Dt?Dt(null):{},this.size=0};var kt=function(e){var t=this.has(e)&&delete this.__data__[e];return this.size-=t?1:0,t},Bt="__lodash_hash_undefined__",Vt=Object.prototype.hasOwnProperty;var jt=function(e){var t=this.__data__;if(Dt){var n=t[e];return n===Bt?void 0:n}return Vt.call(t,e)?t[e]:void 0},zt=Object.prototype.hasOwnProperty;var Gt=function(e){var t=this.__data__;return Dt?void 0!==t[e]:zt.call(t,e)},Ut="__lodash_hash_undefined__";var Ht=function(e,t){var n=this.__data__;return this.size+=this.has(e)?0:1,n[e]=Dt&&void 0===t?Ut:t,this};function Wt(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}Wt.prototype.clear=Ft,Wt.prototype.delete=kt,Wt.prototype.get=jt,Wt.prototype.has=Gt,Wt.prototype.set=Ht;var Yt=Wt;var Xt=function(){this.size=0,this.__data__={hash:new Yt,map:new(Nt||mt),string:new Yt}};var qt=function(e){var t=typeof e;return"string"==t||"number"==t||"symbol"==t||"boolean"==t?"__proto__"!==e:null===e};var Kt=function(e,t){var n=e.__data__;return qt(t)?n["string"==typeof t?"string":"hash"]:n.map};var $t=function(e){var t=Kt(this,e).delete(e);return this.size-=t?1:0,t};var Qt=function(e){return Kt(this,e).get(e)};var Zt=function(e){return Kt(this,e).has(e)};var Jt=function(e,t){var n=Kt(this,e),r=n.size;return n.set(e,t),this.size+=n.size==r?0:1,this};function en(e){var t=-1,n=null==e?0:e.length;for(this.clear();++t<n;){var r=e[t];this.set(r[0],r[1])}}en.prototype.clear=Xt,en.prototype.delete=$t,en.prototype.get=Qt,en.prototype.has=Zt,en.prototype.set=Jt;var tn=en,nn=200;var rn=function(e,t){var n=this.__data__;if(n instanceof mt){var r=n.__data__;if(!Nt||r.length<nn-1)return r.push([e,t]),this.size=++n.size,this;n=this.__data__=new tn(r)}return n.set(e,t),this.size=n.size,this};function on(e){var t=this.__data__=new mt(e);this.size=t.size}on.prototype.clear=pt,on.prototype.delete=_t,on.prototype.get=vt,on.prototype.has=St,on.prototype.set=rn;var an=on,sn="__lodash_hash_undefined__";var ln=function(e){return this.__data__.set(e,sn),this};var cn=function(e){return this.__data__.has(e)};function un(e){var t=-1,n=null==e?0:e.length;for(this.__data__=new tn;++t<n;)this.add(e[t])}un.prototype.add=un.prototype.push=ln,un.prototype.has=cn;var dn=un;var fn=function(e,t){for(var n=-1,r=null==e?0:e.length;++n<r;)if(t(e[n],n,e))return!0;return!1};var hn=function(e,t){return e.has(t)},mn=1,pn=2;var _n=function(e,t,n,r,o,a){var i=n&mn,s=e.length,l=t.length;if(s!=l&&!(i&&l>s))return!1;var c=a.get(e);if(c&&a.get(t))return c==t;var u=-1,d=!0,f=n&pn?new dn:void 0;for(a.set(e,t),a.set(t,e);++u<s;){var h=e[u],m=t[u];if(r)var p=i?r(m,h,u,t,e,a):r(h,m,u,e,t,a);if(void 0!==p){if(p)continue;d=!1;break}if(f){if(!fn(t,function(e,t){if(!hn(f,t)&&(h===e||o(h,e,n,r,a)))return f.push(t)})){d=!1;break}}else if(h!==m&&!o(h,m,n,r,a)){d=!1;break}}return a.delete(e),a.delete(t),d},vn=F.a.Uint8Array;var gn=function(e){var t=-1,n=Array(e.size);return e.forEach(function(e,r){n[++t]=[r,e]}),n};var Sn=function(e){var t=-1,n=Array(e.size);return e.forEach(function(e){n[++t]=e}),n},xn=1,bn=2,yn="[object Boolean]",wn="[object Date]",Tn="[object Error]",En="[object Map]",An="[object Number]",Pn="[object RegExp]",Mn="[object Set]",Cn="[object String]",On="[object Symbol]",Rn="[object ArrayBuffer]",Ln="[object DataView]",In=k?k.prototype:void 0,Nn=In?In.valueOf:void 0;var Dn=function(e,t,n,r,o,a,i){switch(n){case Ln:if(e.byteLength!=t.byteLength||e.byteOffset!=t.byteOffset)return!1;e=e.buffer,t=t.buffer;case Rn:return!(e.byteLength!=t.byteLength||!a(new vn(e),new vn(t)));case yn:case wn:case An:return it(+e,+t);case Tn:return e.name==t.name&&e.message==t.message;case Pn:case Cn:return e==t+"";case En:var s=gn;case Mn:var l=r&xn;if(s||(s=Sn),e.size!=t.size&&!l)return!1;var c=i.get(e);if(c)return c==t;r|=bn,i.set(e,t);var u=_n(s(e),s(t),r,o,a,i);return i.delete(e),u;case On:if(Nn)return Nn.call(e)==Nn.call(t)}return!1};var Fn=function(e,t){for(var n=-1,r=t.length,o=e.length;++n<r;)e[o+n]=t[n];return e};var kn=function(e,t,n){var r=t(e);return Oe(e)?r:Fn(r,n(e))};var Bn=function(e,t){for(var n=-1,r=null==e?0:e.length,o=0,a=[];++n<r;){var i=e[n];t(i,n,e)&&(a[o++]=i)}return a};var Vn=function(){return[]},jn=Object.prototype.propertyIsEnumerable,zn=Object.getOwnPropertySymbols,Gn=zn?function(e){return null==e?[]:(e=Object(e),Bn(zn(e),function(t){return jn.call(e,t)}))}:Vn;var Un=function(e){return kn(e,nt,Gn)},Hn=1,Wn=Object.prototype.hasOwnProperty;var Yn=function(e,t,n,r,o,a){var i=n&Hn,s=Un(e),l=s.length;if(l!=Un(t).length&&!i)return!1;for(var c=l;c--;){var u=s[c];if(!(i?u in t:Wn.call(t,u)))return!1}var d=a.get(e);if(d&&a.get(t))return d==t;var f=!0;a.set(e,t),a.set(t,e);for(var h=i;++c<l;){var m=e[u=s[c]],p=t[u];if(r)var _=i?r(p,m,u,t,e,a):r(m,p,u,e,t,a);if(!(void 0===_?m===p||o(m,p,n,r,a):_)){f=!1;break}h||(h="constructor"==u)}if(f&&!h){var v=e.constructor,g=t.constructor;v!=g&&"constructor"in e&&"constructor"in t&&!("function"==typeof v&&v instanceof v&&"function"==typeof g&&g instanceof g)&&(f=!1)}return a.delete(e),a.delete(t),f},Xn=It(F.a,"DataView"),qn=It(F.a,"Promise"),Kn=It(F.a,"Set"),$n=It(F.a,"WeakMap"),Qn=Tt(Xn),Zn=Tt(Nt),Jn=Tt(qn),er=Tt(Kn),tr=Tt($n),nr=q;(Xn&&"[object DataView]"!=nr(new Xn(new ArrayBuffer(1)))||Nt&&"[object Map]"!=nr(new Nt)||qn&&"[object Promise]"!=nr(qn.resolve())||Kn&&"[object Set]"!=nr(new Kn)||$n&&"[object WeakMap]"!=nr(new $n))&&(nr=function(e){var t=q(e),n="[object Object]"==t?e.constructor:void 0,r=n?Tt(n):"";if(r)switch(r){case Qn:return"[object DataView]";case Zn:return"[object Map]";case Jn:return"[object Promise]";case er:return"[object Set]";case tr:return"[object WeakMap]"}return t});var rr=nr,or=1,ar="[object Arguments]",ir="[object Array]",sr="[object Object]",lr=Object.prototype.hasOwnProperty;var cr=function(e,t,n,r,o,a){var i=Oe(e),s=Oe(t),l=i?ir:rr(e),c=s?ir:rr(t),u=(l=l==ar?sr:l)==sr,d=(c=c==ar?sr:c)==sr,f=l==c;if(f&&Object(Re.a)(e)){if(!Object(Re.a)(t))return!1;i=!0,u=!1}if(f&&!u)return a||(a=new an),i||Ge(e)?_n(e,t,n,r,o,a):Dn(e,t,l,n,r,o,a);if(!(n&or)){var h=u&&lr.call(e,"__wrapped__"),m=d&&lr.call(t,"__wrapped__");if(h||m){var p=h?e.value():e,_=m?t.value():t;return a||(a=new an),o(p,_,n,r,a)}}return!!f&&(a||(a=new an),Yn(e,t,n,r,o,a))};var ur=function e(t,n,r,o,a){return t===n||(null==t||null==n||!K(t)&&!K(n)?t!=t&&n!=n:cr(t,n,r,o,e,a))},dr=1,fr=2;var hr=function(e,t,n,r){var o=n.length,a=o,i=!r;if(null==e)return!a;for(e=Object(e);o--;){var s=n[o];if(i&&s[2]?s[1]!==e[s[0]]:!(s[0]in e))return!1}for(;++o<a;){var l=(s=n[o])[0],c=e[l],u=s[1];if(i&&s[2]){if(void 0===c&&!(l in e))return!1}else{var d=new an;if(r)var f=r(c,u,l,e,t,d);if(!(void 0===f?ur(u,c,dr|fr,r,d):f))return!1}}return!0};var mr=function(e){return e==e&&!D(e)};var pr=function(e){for(var t=nt(e),n=t.length;n--;){var r=t[n],o=e[r];t[n]=[r,o,mr(o)]}return t};var _r=function(e,t){return function(n){return null!=n&&n[e]===t&&(void 0!==t||e in Object(n))}};var vr=function(e){var t=pr(e);return 1==t.length&&t[0][2]?_r(t[0][0],t[0][1]):function(n){return n===e||hr(n,e,t)}},gr=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,Sr=/^\w*$/;var xr=function(e,t){if(Oe(e))return!1;var n=typeof e;return!("number"!=n&&"symbol"!=n&&"boolean"!=n&&null!=e&&!Q(e))||Sr.test(e)||!gr.test(e)||null!=t&&e in Object(t)},br="Expected a function";function yr(e,t){if("function"!=typeof e||null!=t&&"function"!=typeof t)throw new TypeError(br);var n=function(){var r=arguments,o=t?t.apply(this,r):r[0],a=n.cache;if(a.has(o))return a.get(o);var i=e.apply(this,r);return n.cache=a.set(o,i)||a,i};return n.cache=new(yr.Cache||tn),n}yr.Cache=tn;var wr=yr,Tr=500;var Er=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,Ar=/\\(\\)?/g,Pr=function(e){var t=wr(e,function(e){return n.size===Tr&&n.clear(),e}),n=t.cache;return t}(function(e){var t=[];return 46===e.charCodeAt(0)&&t.push(""),e.replace(Er,function(e,n,r,o){t.push(r?o.replace(Ar,"$1"):n||e)}),t});var Mr=function(e,t){for(var n=-1,r=null==e?0:e.length,o=Array(r);++n<r;)o[n]=t(e[n],n,e);return o},Cr=1/0,Or=k?k.prototype:void 0,Rr=Or?Or.toString:void 0;var Lr=function e(t){if("string"==typeof t)return t;if(Oe(t))return Mr(t,e)+"";if(Q(t))return Rr?Rr.call(t):"";var n=t+"";return"0"==n&&1/t==-Cr?"-0":n};var Ir=function(e){return null==e?"":Lr(e)};var Nr=function(e,t){return Oe(e)?e:xr(e,t)?[e]:Pr(Ir(e))},Dr=1/0;var Fr=function(e){if("string"==typeof e||Q(e))return e;var t=e+"";return"0"==t&&1/e==-Dr?"-0":t};var kr=function(e,t){for(var n=0,r=(t=Nr(t,e)).length;null!=e&&n<r;)e=e[Fr(t[n++])];return n&&n==r?e:void 0};var Br=function(e,t,n){var r=null==e?void 0:kr(e,t);return void 0===r?n:r};var Vr=function(e,t){return null!=e&&t in Object(e)};var jr=function(e,t,n){for(var r=-1,o=(t=Nr(t,e)).length,a=!1;++r<o;){var i=Fr(t[r]);if(!(a=null!=e&&n(e,i)))break;e=e[i]}return a||++r!=o?a:!!(o=null==e?0:e.length)&&Fe(o)&&Ne(i,o)&&(Oe(e)||Ce(e))};var zr=function(e,t){return null!=e&&jr(e,t,Vr)},Gr=1,Ur=2;var Hr=function(e,t){return xr(e)&&mr(t)?_r(Fr(e),t):function(n){var r=Br(n,e);return void 0===r&&r===t?zr(n,e):ur(t,r,Gr|Ur)}};var Wr=function(e){return function(t){return null==t?void 0:t[e]}};var Yr=function(e){return function(t){return kr(t,e)}};var Xr=function(e){return xr(e)?Wr(Fr(e)):Yr(e)};var qr=function(e){return"function"==typeof e?e:null==e?I:"object"==typeof e?Oe(e)?Hr(e[0],e[1]):vr(e):Xr(e)};var Kr=function(e,t,n){if(!D(n))return!1;var r=typeof t;return!!("number"==r?tt(n)&&Ne(t,n.length):"string"==r&&t in n)&&it(n[t],e)};var $r,Qr,Zr=function(e,t,n){var r=Oe(e)?ye:ot;return n&&Kr(e,t,n)&&(t=void 0),r(e,qr(t,3))},Jr=function(e,t,n,r){var o,a=arguments.length,i=a<3?t:null===r?r=Object.getOwnPropertyDescriptor(t,n):r;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)i=Reflect.decorate(e,t,n,r);else for(var s=e.length-1;s>=0;s--)(o=e[s])&&(i=(a<3?o(i):a>3?o(t,n,i):o(t,n))||i);return a>3&&i&&Object.defineProperty(t,n,i),i};(Qr=$r||($r={}))[Qr.All=i.FRAMEBUFFER]="All",Qr[Qr.Read=i.READ_FRAMEBUFFER]="Read",Qr[Qr.Draw=i.DRAW_FRAMEBUFFER]="Draw";const eo=e=>{return[i.DEPTH_ATTACHMENT,i.DEPTH_STENCIL_ATTACHMENT].includes(e.attachmentId)},to=e=>{if(0===e.length)throw"Tried to create Fbo with 0 attachments";if(!(e=>{const t=e[0].width,n=e[0].height;return Zr(e,e=>e.width===t&&e.height===n)})(e)){throw`Tried to create Fbo with attachments of different size: ${e.map(e=>`(${e.width}x${e.height})`).join(", ")}`}const t=e.filter(e=>e.isDepth),n=e.filter(e=>!e.isDepth);if(t.length>1)throw`Tried to create Fbo with ${t.length} depth/stencil attachments. Use at most 1`;const r=[];if(t[0]){const e=t[0];r.push({glId:e.glId,attachmentId:e.isDepthStencil?i.DEPTH_STENCIL_ATTACHMENT:i.DEPTH_ATTACHMENT})}return n.forEach((e,t)=>{r.push({glId:e.glId,attachmentId:i.COLOR_ATTACHMENT0+t})}),r};class no extends m{constructor(e,t){super(e.createFramebuffer(),"Fbo"),this.attachments=to(t),this.dimensions=Object(a.fromValues)(t[0].width,t[0].height),e.bindFramebuffer(e.DRAW_FRAMEBUFFER,this.glId),this.attachments.forEach(t=>e.framebufferTexture2D(e.DRAW_FRAMEBUFFER,t.attachmentId,e.TEXTURE_2D,t.glId,0)),this.bindAsDrawTarget(e);const n=e.checkFramebufferStatus(e.DRAW_FRAMEBUFFER);if(n!==e.FRAMEBUFFER_COMPLETE)throw this.destroy(e),`Fbo create error, checkFramebufferStatus: ${Eo(n)}(${n.toString(16)})`}get width(){return this.dimensions[0]}get height(){return this.dimensions[1]}bind(e,t,n=!1){e.bindFramebuffer(t,this.glId),n&&this.bindAsDrawTarget(e)}bindAsDrawTarget(e){if(!this.isOk)throw"Tried to use invalid Fbo";{const t=this.colorAttachments.map(e=>e.attachmentId);e.drawBuffers(0===t.length?[e.NONE]:t)}}get colorAttachments(){return this.attachments.filter(e=>!eo(e))}destroy(e){this.isOk&&(e.deleteFramebuffer(this.glId),this.glId_=null)}}Jr([h],no.prototype,"bind",null);var ro,oo,ao=function(e,t,n,r){var o,a=arguments.length,i=a<3?t:null===r?r=Object.getOwnPropertyDescriptor(t,n):r;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)i=Reflect.decorate(e,t,n,r);else for(var s=e.length-1;s>=0;s--)(o=e[s])&&(i=(a<3?o(i):a>3?o(t,n,i):o(t,n))||i);return a>3&&i&&Object.defineProperty(t,n,i),i};(oo=ro||(ro={}))[oo.VertexShader=i.VERTEX_SHADER]="VertexShader",oo[oo.FragmentShader=i.FRAGMENT_SHADER]="FragmentShader";const io=(e,t,n)=>{const r=e.createShader(t);if(e.shaderSource(r,n),e.compileShader(r),e.getShaderParameter(r,e.COMPILE_STATUS))return r;return console.error(`${ro[t]} compile error:`),((e,t)=>{const n=/\d+:(\d+):(.*)$/,r=e.split("\n");return t.split("\n").map(e=>{const t=n.exec(e);if(t&&3===t.length){const e=parseInt(t[1],10)-1;return`> ${r[e].trim()}\n  L${e}: ${t[2].trim()}`}return e})})(n,e.getShaderInfoLog(r)).forEach(e=>{(e=e.trim()).length>0&&console.log(`%c${e}`,"color: #FA5858")}),void e.deleteShader(r)},so=(e,t)=>{const n=e.getProgramParameter(t.glId,e.ACTIVE_ATTRIBUTES),r={};for(let o=0;o<n;o++){const n=e.getActiveAttrib(t.glId,o);r[n.name]={size:n.size,name:n.name,type:n.type,location:e.getAttribLocation(t.glId,n.name)}}return r},lo=(e,t)=>{const n=e.getProgramParameter(t.glId,e.ACTIVE_UNIFORMS),r={};for(let o=0;o<n;o++){const n=e.getActiveUniform(t.glId,o),a=n.name.replace("[0]","");r[n.name]={size:n.size,name:n.name,type:n.type,location:e.getUniformLocation(t.glId,a)}}return r};class co extends m{constructor(e,t,n){super(e.createProgram(),"Shader"),this.attrs={},this.uniforms={};const r=io(e,ro.VertexShader,t),o=io(e,ro.FragmentShader,n);r&&o?(e.attachShader(this.glId,r),e.attachShader(this.glId,o),e.linkProgram(this.glId),e.deleteShader(r),e.deleteShader(o),e.getProgramParameter(this.glId,e.LINK_STATUS)?(this.attrs=so(e,this),this.uniforms=lo(e,this)):this.destroy(e)):this.destroy(e)}use(e){e.useProgram(this.glId)}getAttr(e){return this.attrs[e]}getUniform(e){return this.uniforms[e]}destroy(e){e.deleteProgram(this.glId),this.glId_=null}}ao([h],co.prototype,"use",null),ao([h],co.prototype,"getAttr",null),ao([h],co.prototype,"getUniform",null);var uo,fo,ho=function(e,t,n,r){var o,a=arguments.length,i=a<3?t:null===r?r=Object.getOwnPropertyDescriptor(t,n):r;if("object"==typeof Reflect&&"function"==typeof Reflect.decorate)i=Reflect.decorate(e,t,n,r);else for(var s=e.length-1;s>=0;s--)(o=e[s])&&(i=(a<3?o(i):a>3?o(t,n,i):o(t,n))||i);return a>3&&i&&Object.defineProperty(t,n,i),i};(fo=uo||(uo={}))[fo.FLOAT=i.FLOAT]="FLOAT",fo[fo.FLOAT_VEC2=i.FLOAT_VEC2]="FLOAT_VEC2",fo[fo.FLOAT_VEC3=i.FLOAT_VEC3]="FLOAT_VEC3",fo[fo.FLOAT_VEC4=i.FLOAT_VEC4]="FLOAT_VEC4";const mo=(e,t,n)=>{const{name:r,rawData:o,offset:a,stride:i,type:s}=n,[l,c]=((e,t)=>{switch(t){case uo.FLOAT:return[e.FLOAT,1];case uo.FLOAT_VEC2:return[e.FLOAT,2];case uo.FLOAT_VEC3:return[e.FLOAT,3];case uo.FLOAT_VEC4:return[e.FLOAT,4];default:throw`Unsupported vertex attribute type: ${t}`}})(e,n.type),u=be.fromData(e,me.VertexBuffer,_e.STATIC_DRAW,o);return u.bind(e),e.vertexAttribPointer(t,c,l,!1,i,a),e.enableVertexAttribArray(t),{name:r,glBuffer:u,location:t,type:s,stride:i,offset:a}};class po extends m{constructor(e,t){super(e.createVertexArray(),"Vao"),this.attrs=[],this.initAttribute=(e=>(t,n)=>{const r=mo(e,n,t);r?this.attrs.push(r):console.error(`Vertex attribute ${t.name} not found. `+"This attribute may simply be not used, so it is not critical. Vao may not work as expected")}),e.bindVertexArray(this.glId),t.forEach(this.initAttribute(e)),e.bindVertexArray(null),t.length!==this.attrs.length&&this.destroy(e)}bind(e){e.bindVertexArray(this.glId)}destroy(e){this.isOk&&(this.attrs.forEach(t=>t.glBuffer.destroy(e)),e.deleteVertexArray(this.glId),this.glId_=null)}}ho([h],po.prototype,"bind",null);const _o=e=>(t,n,r)=>{t[e](n,r)},vo=e=>(t,n,r)=>{t[e](n,!1,r)},go=(e,t,n)=>{const r=e.getUniform(t);if(!r){if(n)throw(e=>`Uniform '${e}' was not found, all uniforms `+"for this call of setUniforms have forced validation ON")(t);return null}return r},So=(e,t,n,r=!1)=>{const{gl:o,textureBindingState:a}=e,i=[];Object.keys(n).forEach(e=>{const a=n[e];if(null==a)throw`Uniform '${e}' cannot be set to invalid value '${a}'`;if(a instanceof w)i.push({name:e,texture:a});else{const n=go(t,e,r);if(n){const t=((e,t)=>{switch(t){case e.FLOAT:return _o("uniform1f");case e.FLOAT_VEC2:return _o("uniform2fv");case e.FLOAT_VEC3:return _o("uniform3fv");case e.FLOAT_VEC4:return _o("uniform4fv");case e.INT:return _o("uniform1i");case e.INT_VEC2:return _o("uniform2iv");case e.INT_VEC3:return _o("uniform3iv");case e.INT_VEC4:return _o("uniform4iv");case e.UNSIGNED_INT:return _o("uniform1ui");case e.UNSIGNED_INT_VEC2:return _o("uniform2uiv");case e.UNSIGNED_INT_VEC3:return _o("uniform3uiv");case e.UNSIGNED_INT_VEC4:return _o("uniform4uiv");case e.FLOAT_MAT2:return vo("uniformMatrix2fv");case e.FLOAT_MAT3:return vo("uniformMatrix3fv");case e.FLOAT_MAT4:return vo("uniformMatrix4fv")}return null})(o,n.type);if(t)t(o,n.location,a);else if(r)throw((e,t)=>`Uniform '${e}' has not recognised type ${t}(${Eo(t)}), `+"all uniforms for this call of setUniforms have forced validation ON")(e,n.type)}}});const s=a.replaceTextures(o,i.map(e=>e.texture));i.forEach(e=>{const{name:n,texture:i}=e,l=go(t,n,r);if(!l)return;if(!((e,t)=>{return[e.SAMPLER_2D,e.INT_SAMPLER_2D,e.UNSIGNED_INT_SAMPLER_2D,e.SAMPLER_2D_SHADOW,e.SAMPLER_CUBE,e.UNSIGNED_INT_SAMPLER_CUBE].includes(t)})(o,l.type))throw`Uniform '${n}' of type ${Eo(l.type)} cannot be assigned texture`;const c=s[i.uuid];if(!a.isValidBindingIndex(c))throw`Error binding texture for shader. Returned invalid binding index ${c},`+` only ${a.maxTextures} are supported`;o.uniform1i(l.location,c)})},xo=Object(o.fromValues)(0,1,0),bo=e=>e*Math.PI/180,yo=(e,t,n=!1)=>{n&&(e=bo(e),t=bo(t));const r=Object(o.create)();return r[0]=Math.cos(e)*Math.sin(t),r[1]=Math.cos(t),r[2]=Math.sin(e)*Math.sin(t),r},wo=(e,t,n)=>Math.min(Math.max(e,t),n),To=(e,t,n)=>e*(1-(n=wo(n,0,1)))+t*n,Eo=e=>{return Object.keys(i).filter(t=>i[t]===e).join(" ")},Ao=e=>{if("string"==typeof e){const t="#"===e[0]?e.substr(1):e;e=parseInt(t,16)}const t=e>>16&255,n=e>>8&255,r=255&e;return Object(o.fromValues)(t/255,n/255,r/255)},Po=(e,t)=>{const n=Object(o.subtract)(Object(o.create)(),e,t);return Object(o.normalize)(n,n)},Mo=(e,t)=>{const n=Object(o.add)(Object(o.create)(),e,t);return Object(o.normalize)(n,n)};function Co(e){throw new Error("Didn't expect to get here")}const Oo=(e,t,n,r)=>new Promise((a,i)=>{const s=new Image;s.addEventListener("load",()=>{const n={start:Object(o.fromValues)(0,0,0),dimensions:r.dimensions},i={unsizedPixelFormat:e.RGB_INTEGER,perChannelType:e.UNSIGNED_BYTE,data:s};r.write(e,t,0,n,i),a(r)}),s.addEventListener("error",i),s.src=n}),Ro=(e,t=!1)=>{if(!e||3!==e.length)throw`arrayToVec3 expects array of 3 values, got ${e?e.length:"null"}`;return t&&(e=e.map(e=>e/255)),Object(o.fromValues)(e[0],e[1],e[2])};var Lo;!function(e){e[e.Linear=0]="Linear",e[e.Reinhard=1]="Reinhard",e[e.Uncharted2=2]="Uncharted2",e[e.Photographic=3]="Photographic",e[e.ACES_UE4=4]="ACES_UE4"}(Lo||(Lo={}));const Io=["Linear","Reinhard","Uncharted2","Photographic","ACES_UE4"];class No{execute(e){const{cfg:t,device:n,frameRes:r}=e,{gl:o}=n,a=r.tonemappingShader;a.use(o);const i=r.tonemappingFbo;r.tonemappingFbo.bind(o,$r.Draw,!0),o.viewport(0,0,i.dimensions[0],i.dimensions[1]);const s=t.postfx.colorGrading;So(n,a,Object.assign({u_source:r.forwardColorTex,u_gamma:t.postfx.gamma,u_ditherStrength:t.postfx.ditherStrength},this.prepareColorGradingParams("",s.global),this.prepareColorGradingParams("Shadows",s.shadows),this.prepareColorGradingParams("Midtones",s.midtones),this.prepareColorGradingParams("Highlights",s.highlights),{u_colorCorrectionShadowsMax:s.shadows.shadowsMax,u_colorCorrectionHighlightsMin:s.highlights.highlightsMin,u_exposure:t.postfx.exposure,u_whitePoint:t.postfx.whitePoint,u_tonemappingMode:t.postfx.tonemappingOp,u_acesC:t.postfx.acesC,u_acesS:t.postfx.acesS}),!0),n.renderFullscreenQuad(!0)}prepareColorGradingParams(e,t){const n=e=>Object(c.fromValues)(e.color[0],e.color[1],e.color[2],e.value);return{[`u_colorSaturation${e}`]:n(t.saturation),[`u_colorContrast${e}`]:n(t.contrast),[`u_colorGamma${e}`]:n(t.gamma),[`u_colorGain${e}`]:n(t.gain),[`u_colorOffset${e}`]:n(t.offset)}}}const Do=(e,t)=>({color:e,value:t}),Fo=5;class ko{constructor(){this.githubRepoLink="//github.com/Scthe/WebFX",this.clearColor=Ao("#5d5d5d"),this.clearDepth=1,this.clearStencil=0,this.resizeUpdateFreq=1e3,this.showDebugPositions=!1,this.useMSAA=!0,this.displayMode=0,this.stencilConsts={skin:1,hair:2},this.camera={position:Object(o.fromValues)(0,2.5,5),rotation:Object(a.fromValues)(0,0),settings:{fovDgr:75,zNear:.1,zFar:100}},this.shadows={shadowmapSize:2048,usePCSS:!1,blurRadius:4,bias:.005,blurRadiusTfx:1,biasHairTfx:.05,hairTfxRadiusMultipler:1.1,strength:.7,directionalLight:{posPhi:105,posTheta:45,posRadius:Fo,target:Object(o.fromValues)(0,2,0),projection:{left:-Fo,right:Fo,top:Fo,bottom:-Fo,near:.1,far:20}},showDebugView:!1},this.lightAmbient={color:Ao("#a0a0a0"),energy:.02},this.light0={posPhi:125,posTheta:45,posRadius:10,color:Ro([214,197,208],!0),energy:1},this.light1={posPhi:45,posTheta:82,posRadius:10,color:Ro([214,166,166],!0),energy:.8},this.light2={posPhi:-105,posTheta:55,posRadius:10,color:Ro([133,171,169],!0),energy:.55},this.lightSSS={depthmapSize:1024,posPhi:-93,posTheta:55,posRadius:Fo,blurWidth:25,blurStrength:.35,blurFollowSurface:!1},this.ssao={textureSizeMul:.5,kernelSize:24,radius:.5,bias:.025,blurRadius:7,blurGaussSigma:3,blurMaxDepthDistance:.06,aoStrength:.3,aoExp:3},this.postfx={gamma:2.2,ditherStrength:1.5,tonemappingOp:Lo.ACES_UE4,exposure:1,whitePoint:1,acesC:.8,acesS:1,useFxaa:!0,subpixel:.75,edgeThreshold:.125,edgeThresholdMin:.0625,colorGrading:{global:{saturation:Do(Object(o.fromValues)(1,1,1),1),contrast:Do(Object(o.fromValues)(1,1,1),1),gamma:Do(Object(o.fromValues)(1,1,1),1),gain:Do(Object(o.fromValues)(1,1,1),1),offset:Do(Object(o.fromValues)(0,0,0),0)},shadows:{saturation:Do(Object(o.fromValues)(1,1,1),1),contrast:Do(Object(o.fromValues)(1,1,1),1),gamma:Do(Object(o.fromValues)(1,1,1),1),gain:Do(Object(o.fromValues)(1,1,1),1),offset:Do(Object(o.fromValues)(0,0,0),0),shadowsMax:.09},midtones:{saturation:Do(Object(o.fromValues)(1,1,1),1),contrast:Do(Object(o.fromValues)(1,1,1),1),gamma:Do(Object(o.fromValues)(1,1,1),1),gain:Do(Object(o.fromValues)(1,1,1),1),offset:Do(Object(o.fromValues)(0,0,0),0)},highlights:{saturation:Do(Object(o.fromValues)(1,1,1),1),contrast:Do(Object(o.fromValues)(1,1,1),1),gamma:Do(Object(o.fromValues)(1,1,1),1),gain:Do(Object(o.fromValues)(1,1,1),1),offset:Do(Object(o.fromValues)(0,0,0),0),highlightsMin:.5}}},this.sintel={modelScale:.1,centerOfGravity:Object(o.fromValues)(0,3,0)}}sphericalToCartesian(e){const t=yo(e.posPhi,e.posTheta,!0);return Object(o.scale)(t,t,e.posRadius)}}var Bo=Math.ceil,Vo=Math.max;var jo=function(e,t,n,r){for(var o=-1,a=Vo(Bo((t-e)/(n||1)),0),i=Array(a);a--;)i[r?a:++o]=e,e+=n;return i};var zo=function(e){return function(t,n,r){return r&&"number"!=typeof r&&Kr(t,n,r)&&(n=r=void 0),t=se(t),void 0===n?(n=t,t=0):n=se(n),r=void 0===r?t<n?1:-1:se(r),jo(t,n,r,e)}}(),Go=k?k.isConcatSpreadable:void 0;var Uo=function(e){return Oe(e)||Ce(e)||!!(Go&&e&&e[Go])};var Ho=function e(t,n,r,o,a){var i=-1,s=t.length;for(r||(r=Uo),a||(a=[]);++i<s;){var l=t[i];n>0&&r(l)?n>1?e(l,n-1,r,o,a):Fn(a,l):o||(a[a.length]=l)}return a};var Wo=function(e){return null!=e&&e.length?Ho(e,1):[]};var Yo=function(e,t){var n=-1,r=tt(e)?Array(e.length):[];return rt(e,function(e,o,a){r[++n]=t(e,o,a)}),r};var Xo=function(e,t){return(Oe(e)?Mr:Yo)(e,qr(t,3))};var qo=function(e,t){return Ho(Xo(e,t),1)};const Ko=(e,t)=>{if(!e)throw t},$o=(e,t,n)=>Object(o.fromValues)(e,t,n),Qo=(e,t,n)=>{const r=(e=>t=>t%e)(e),o=[];for(let a=0;a<e;a++)o.push({a:t+a,b:t+r(a+1),c:n});return o},Zo=(e,t)=>{const n=2/(t+1),r=qo(zo(t),t=>{const r=(t+1)*n,o=(r-1)/1;return((e,t)=>{const n=[];for(let r=0;r<t;r++){const o=r/t*(2*Math.PI),a=Math.sin(o),i=Math.cos(o);n.push($o(e*a,0,e*i))}return n})(1*Math.sqrt(1-o*o),e).map((e=>t=>$o(t[0],t[1]+e,t[2]))(r-1))}),o=Wo(r),a=qo(zo(t-1),t=>((e,t,n)=>{const r=[],o=t=>t%e;for(let a=0;a<e;a++)r.push({a:t+a,b:t+o(a+1),c:n+a}),r.push({a:n+o(a+1),b:n+a,c:t+o(a+1)});return r})(e,e*t,e*(t+1)));return o.push($o(0,1,0)),a.push(...Qo(e,(t-1)*e,o.length-1)),o.push($o(0,-1,0)),a.push(...Qo(e,0,o.length-1)),{vertices:o,indices:[...a]}},Jo=e=>{const{radius:t,rings:n,segments:r}=(e=>{const t=e;return Object.keys(t).forEach(e=>{t[e]=Math.abs(t[e])}),t})(e);Ko(r>=3,`Sphere segments should be 3 or more, was ${r}`),Ko(n>=2,`Sphere rings should be 2 or more, was ${n}`);const a=Zo(r,n);return a.vertices.forEach(e=>{Object(o.scale)(e,e,t)}),a};var ea=function(e,t,n,r){for(var o=e.length,a=n+(r?1:-1);r?a--:++a<o;)if(t(e[a],a,e))return a;return-1};var ta=function(e){return e!=e};var na=function(e,t,n){for(var r=n-1,o=e.length;++r<o;)if(e[r]===t)return r;return-1};var ra=function(e,t,n){return t==t?na(e,t,n):ea(e,ta,n)};var oa=function(e,t){return!(null==e||!e.length)&&ra(e,t,0)>-1};var aa=function(e,t,n){for(var r=-1,o=null==e?0:e.length;++r<o;)if(n(t,e[r]))return!0;return!1},ia=Math.min;var sa=function(e,t,n){for(var r=n?aa:oa,o=e[0].length,a=e.length,i=a,s=Array(a),l=1/0,c=[];i--;){var u=e[i];i&&t&&(u=Mr(u,Ve(t))),l=ia(u.length,l),s[i]=!n&&(t||o>=120&&u.length>=120)?new dn(i&&u):void 0}u=e[0];var d=-1,f=s[0];e:for(;++d<o&&c.length<l;){var h=u[d],m=t?t(h):h;if(h=n||0!==h?h:0,!(f?hn(f,m):r(c,m,n))){for(i=a;--i;){var p=s[i];if(!(p?hn(p,m):r(e[i],m,n)))continue e}f&&f.push(m),c.push(h)}}return c};var la=function(e,t,n){switch(n.length){case 0:return e.call(t);case 1:return e.call(t,n[0]);case 2:return e.call(t,n[0],n[1]);case 3:return e.call(t,n[0],n[1],n[2])}return e.apply(t,n)},ca=Math.max;var ua=function(e,t,n){return t=ca(void 0===t?e.length-1:t,0),function(){for(var r=arguments,o=-1,a=ca(r.length-t,0),i=Array(a);++o<a;)i[o]=r[t+o];o=-1;for(var s=Array(t+1);++o<t;)s[o]=r[o];return s[t]=n(i),la(e,this,s)}};var da=function(e){return function(){return e}},fa=function(){try{var e=It(Object,"defineProperty");return e({},"",{}),e}catch(e){}}(),ha=fa?function(e,t){return fa(e,"toString",{configurable:!0,enumerable:!1,value:da(t),writable:!0})}:I,ma=800,pa=16,_a=Date.now;var va=function(e){var t=0,n=0;return function(){var r=_a(),o=pa-(r-n);if(n=r,o>0){if(++t>=ma)return arguments[0]}else t=0;return e.apply(void 0,arguments)}}(ha);var ga=function(e){return K(e)&&tt(e)};var Sa,xa=function(e){return ga(e)?e:[]},ba=function(e,t){return va(ua(e,t,I),e+"")}(function(e){var t=Mr(e,xa);return t.length&&t[0]===e[0]?sa(t):[]});!function(e){e[e.Camera=0]="Camera",e[e.FpsController=1]="FpsController",e[e.Material=2]="Material",e[e.Mesh=3]="Mesh",e[e.Tfx=4]="Tfx",e[e.Name=5]="Name",e[e.Transform=6]="Transform"}(Sa||(Sa={}));class ya{get type(){return this.constructor.TYPE}}ya.TYPE="[ERROR] Please override me!";class wa{constructor(){this.nextEntityId=0;const e={};Object.keys(Sa).forEach(t=>e[t]=[]),this.components=e}createEnity(){return this.nextEntityId++}addComponent(e,t){this.getComponents(t.type)[e]=t}getComponent(e,t){const n=t.TYPE;return this.getComponents(n)[e]}getAllIds(e){const t=e.includes.map(e=>{const t=this.getComponents(e);return Object.entries(t).reduce((e,t)=>{const[n,r]=t;return r&&e.push(n),e},[])});return ba(...t)}forEachEntity(e,...t){const n=this.getComponents(t[0].TYPE),r=[null,null,null,null,null];Object.entries(n).forEach(n=>{const o=n[0],a=n[1];r[0]=o,r[1]=a;let i=!0;for(let e=1;e<t.length;e++){const n=t[e],a=this.getComponent(o,n);r[e+1]=a,i=i&&!!a}i&&e.apply(null,r)})}removeAll(e,t){Object.keys(Sa).forEach(n=>{const r=n,o=this.getComponents(r);Object.entries(o).forEach(n=>{const[r,a]=n;e.includes(r)&&a&&(a.destroy(t),delete o[r])})})}getByName(e){const t=this.getComponents(Sa.Name);let n=void 0;return Object.entries(t).forEach(t=>{const[r,o]=t;o.name===e&&(n=parseInt(r,10))}),n}getComponents(e){return this.components[e]}}class Ta extends ya{constructor(e){super(),this.settings=e,this.perspectiveMatrix=Object(r.create)()}updateProjectionMatrix(e,t){const{fovDgr:n,zNear:o,zFar:a}=this.settings,i=e/t;Object(r.perspective)(this.perspectiveMatrix,bo(n),i,o,a)}destroy(e){}}Ta.TYPE=Sa.Camera;const Ea={CAMERA_FORWARD:"W",CAMERA_BACK:"S",CAMERA_LEFT:"A",CAMERA_RIGHT:"D",CAMERA_UP:" ",CAMERA_DOWN:"Z"},Aa=Math.PI/2,Pa=0,Ma=1;class Ca extends ya{constructor(){super(...arguments),this.rotateSensitivity=.002,this.moveSensitivity=.005,this.wheelSensitivity=.5,this.viewMatrix_=Object(r.create)(),this.angles_=Object(a.fromValues)(0,0),this.position_=Object(o.fromValues)(0,0,0),this.onMouseDrag=(e=>{this.angles[Ma]+=e[0]*this.rotateSensitivity,this.angles[Pa]+=e[1]*this.rotateSensitivity;const t=.95*Aa;this.angles[Pa]=wo(this.angles[Pa],-t,t)}),this.onMouseWheel=(e=>{const t=Math.sign(e)*this.wheelSensitivity;this.applyMove(Object(o.fromValues)(0,0,t))}),this.update=((e,t)=>{const n=this.moveSensitivity*e,r=this.calculateMovementDirectionFromKeys(t,n);this.applyMove(r)})}get position(){return this.position_}get angles(){return this.angles_}calculateMovementDirectionFromKeys(e,t){const n=t=>e.isPressed(t.charCodeAt(0));let r=Object(o.fromValues)(0,0,0);return n(Ea.CAMERA_FORWARD)&&(r[2]-=t),n(Ea.CAMERA_BACK)&&(r[2]+=t),n(Ea.CAMERA_LEFT)&&(r[0]-=t),n(Ea.CAMERA_RIGHT)&&(r[0]+=t),n(Ea.CAMERA_UP)&&(r[1]+=t),n(Ea.CAMERA_DOWN)&&(r[1]-=t),r}applyMove(e){if(0!==e[0]||0!==e[1]||0!==e[2]){const t=Object(r.transpose)(Object(r.create)(),this.getRotationMat()),n=Object(c.create)(),a=u(n,e,t);Object(o.add)(this.position,this.position,a)}}getRotationMat(){const e=this.angles,t=Object(r.create)();return Object(r.rotateX)(t,t,e[Pa]),Object(r.rotateY)(t,t,e[Ma]),t}get viewMatrix(){const e=this.getRotationMat(),t=this.position;return Object(r.translate)(this.viewMatrix_,e,[-t[0],-t[1],-t[2]])}destroy(e){}}Ca.TYPE=Sa.FpsController;class Oa extends ya{constructor(e,t,n=null){super(),this.albedoTex=e,this.specularTex=t,this.hairShadowTex=n,this.isMetallic=!1,this.specular=.7,this.specularMul=1,this.sssTransluency=.5,this.sssWidth=60,this.sssBias=.022,this.sssGain=0,this.sssStrength=1}destroy(e){}}Oa.TYPE=Sa.Material;class Ra extends ya{constructor(e,t){super(),this.vao=e,this.indices=t}destroy(e){this.vao.destroy(e),this.indices.indexBuffer.destroy(e)}}Ra.TYPE=Sa.Mesh;class La{constructor(){this.albedo=Ro([31,26,24],!0),this.aoStrength=1,this.aoExp=3.1,this.specularColor1=Ro([87,43,24],!0),this.specularPower1=160,this.specularStrength1=.27,this.primaryShift=.005,this.specularColor2=Ro([138,129,111],!0),this.specularPower2=400,this.specularStrength2=.07,this.secondaryShift=-.06}}class Ia extends ya{constructor(e,t,n,r,o){super(),this.numHairStrands=e,this.numVerticesPerStrand=t,this.positionsTexture=n,this.tangentsTexture=r,this.indices=o,this.fiberRadius=.01,this.thinTip=.9,this.followHairs=10,this.followHairSpreadRoot=.14,this.followHairSpreadTip=.09,this.displayMode=0,this.material=new La}destroy(e){this.positionsTexture.destroy(e)}get totalVertices(){return this.numHairStrands*this.numVerticesPerStrand}}Ia.MAX_FOLLOW_HAIRS_PER_GUIDE=15,Ia.TYPE=Sa.Tfx;var Na=n(15);const Da=()=>({position:Object(o.fromValues)(0,0,0),rotation:Object(Na.create)(),scale:Object(o.fromValues)(1,1,1)}),Fa=Da();Object.freeze(Fa);Fa.position,Fa.rotation,Fa.scale;const ka=e=>{const{position:t,rotation:n,scale:o}=e;return((e,t,n)=>{let o=Object(r.create)();if(4===t.length)Object(r.fromRotationTranslation)(o,t,e);else{const n=Object(r.create)();Object(r.fromTranslation)(n,e),Object(r.multiply)(o,n,t)}const a=Object(r.fromScaling)(Object(r.create)(),n);return Object(r.multiply)(Object(r.create)(),o,a)})(t,n,o)};class Ba extends ya{constructor(e=Da()){super(),this.tfx=e,this.modelMatrix=Object(r.create)(),this.updateModelMatrix()}get position(){return this.tfx.position}get rotation(){return this.tfx.rotation}get scale(){return this.tfx.scale}updateModelMatrix(){const e=ka(this.tfx);Object(r.copy)(this.modelMatrix,e)}destroy(e){}}Ba.TYPE=Sa.Transform;const Va=(e,t,n)=>{const{vertices:r,indices:o}=t,a=new Float32Array(3*r.length);r.forEach((e,t)=>{a[3*t+0]=e[0],a[3*t+1]=e[1],a[3*t+2]=e[2]});const i=new po(e,[{name:n,stride:0,offset:0,type:uo.FLOAT_VEC3,rawData:a}]),s=new Uint16Array(3*o.length);o.forEach((e,t)=>{s[3*t+0]=e.a,s[3*t+1]=e.b,s[3*t+2]=e.c});const l=be.fromData(e,me.IndexBuffer,_e.STATIC_DRAW,s);return new Ra(i,{indexGlType:e.UNSIGNED_SHORT,indexBuffer:l,triangleCnt:o.length})};var ja,za,Ga,Ua,Ha,Wa,Ya=function(e,t){return ur(e,t)};(za=ja||(ja={}))[za.AlwaysFail=i.NEVER]="AlwaysFail",za[za.AlwaysPass=i.ALWAYS]="AlwaysPass",za[za.IfEqual=i.EQUAL]="IfEqual",za[za.IfNotEqual=i.NOTEQUAL]="IfNotEqual",za[za.IfMore=i.GREATER]="IfMore",za[za.IfMoreOrEqual=i.GEQUAL]="IfMoreOrEqual",za[za.IfLess=i.LESS]="IfLess",za[za.IfLessOrEqual=i.LEQUAL]="IfLessOrEqual";class Xa{constructor(){this.test=ja.IfLess,this.write=!0}}(Ua=Ga||(Ga={}))[Ua.AlwaysPass=i.ALWAYS]="AlwaysPass",Ua[Ua.AlwaysFail=i.NEVER]="AlwaysFail",Ua[Ua.IfRefIsLessThenCurrent=i.LESS]="IfRefIsLessThenCurrent",Ua[Ua.IfRefIsLessOrEqualCurrent=i.LEQUAL]="IfRefIsLessOrEqualCurrent",Ua[Ua.IfRefIsMoreThenCurrent=i.GREATER]="IfRefIsMoreThenCurrent",Ua[Ua.IfRefIsMoreOrEqualCurrent=i.GEQUAL]="IfRefIsMoreOrEqualCurrent",Ua[Ua.IfRefIsEqualCurrent=i.EQUAL]="IfRefIsEqualCurrent",Ua[Ua.IfRefIsNotEqualCurrent=i.NOTEQUAL]="IfRefIsNotEqualCurrent",(Wa=Ha||(Ha={}))[Wa.Keep=i.KEEP]="Keep",Wa[Wa.Zero=i.ZERO]="Zero",Wa[Wa.Replace=i.REPLACE]="Replace",Wa[Wa.Increment=i.INCR]="Increment",Wa[Wa.IncrementWrap=i.INCR_WRAP]="IncrementWrap",Wa[Wa.Decrement=i.DECR]="Decrement",Wa[Wa.DecrementWrap=i.DECR_WRAP]="DecrementWrap",Wa[Wa.Invert=i.INVERT]="Invert";class qa{constructor(){this.test=Ga.AlwaysPass,this.opStencilFail=Ha.Keep,this.opstencilPassDepthFail=Ha.Keep,this.opPass=Ha.Keep}}class Ka{constructor(){this.referenceValue=0,this.compareMask=4294967295,this.writeBytes=4294967295,this.front=new qa,this.back=new qa}}const $a=(e,t,n)=>{n?e.enable(t):e.disable(t)},Qa=e=>{return e.opStencilFail===Ha.Keep&&e.opstencilPassDepthFail===Ha.Keep&&e.opPass===Ha.Keep&&e.test===Ga.AlwaysPass},Za=(e,t,n,r=!1)=>{if(((e,t,n,r)=>{(r||!Ya(t,n))&&($a(e,e.DEPTH_TEST,t.test!==ja.AlwaysPass||t.write),e.depthFunc(t.test),e.depthMask(t.write))})(e,t.depth,n?n.depth:void 0,r),((e,t,n,r)=>{if(!r&&Ya(t,n))return;const o=t.front,a=t.back,i=t.referenceValue,s=t.compareMask;$a(e,e.STENCIL_TEST,!Qa(o)||!Qa(a)),o.test===a.test?e.stencilFunc(o.test,i,s):(e.stencilFuncSeparate(e.FRONT,o.test,i,s),e.stencilFuncSeparate(e.BACK,a.test,i,s)),e.stencilMask(t.writeBytes),((e,t)=>e.opStencilFail===t.opStencilFail&&e.opstencilPassDepthFail===t.opstencilPassDepthFail&&e.opPass===t.opPass)(o,a)?e.stencilOp(o.opStencilFail,o.opstencilPassDepthFail,o.opPass):(e.stencilOpSeparate(e.FRONT,o.opStencilFail,o.opstencilPassDepthFail,o.opPass),e.stencilOpSeparate(e.BACK,a.opStencilFail,a.opstencilPassDepthFail,a.opPass))})(e,t.stencil,n?n.stencil:void 0,r),(r||t.dithering!==n.dithering)&&$a(e,e.DITHER,t.dithering),(r||t.culling!==n.culling)&&(t.culling===ri.None?$a(e,e.CULL_FACE,!1):($a(e,e.CULL_FACE,!0),e.cullFace(t.culling))),r||n.colorWrite[0]!==t.colorWrite[0]||n.colorWrite[1]!==t.colorWrite[1]||n.colorWrite[2]!==t.colorWrite[2]||n.colorWrite[3]!==t.colorWrite[3]){const n=t.colorWrite;e.colorMask(n[0],n[1],n[2],n[3])}};var Ja,ei,ti,ni,ri,oi;(ei=Ja||(Ja={}))[ei.Zero=i.ZERO]="Zero",ei[ei.One=i.ONE]="One",ei[ei.SourceColor=i.SRC_COLOR]="SourceColor",ei[ei.OneMinusSourceColor=i.ONE_MINUS_SRC_COLOR]="OneMinusSourceColor",ei[ei.DestinationColor=i.DST_COLOR]="DestinationColor",ei[ei.OneMinusDestinationColor=i.ONE_MINUS_DST_COLOR]="OneMinusDestinationColor",ei[ei.ConstantColor=i.CONSTANT_COLOR]="ConstantColor",ei[ei.OneMinusConstantColor=i.ONE_MINUS_CONSTANT_COLOR]="OneMinusConstantColor",ei[ei.SourceAlpha=i.SRC_ALPHA]="SourceAlpha",ei[ei.OneMinusSourceAlpha=i.ONE_MINUS_SRC_ALPHA]="OneMinusSourceAlpha",ei[ei.DestinationAlpha=i.DST_ALPHA]="DestinationAlpha",ei[ei.OneMinusDestinationAlpha=i.ONE_MINUS_DST_ALPHA]="OneMinusDestinationAlpha",ei[ei.ConstantAlpha=i.CONSTANT_ALPHA]="ConstantAlpha",ei[ei.OneMinusConstantAlpha=i.ONE_MINUS_CONSTANT_ALPHA]="OneMinusConstantAlpha",(ni=ti||(ti={}))[ni.AlwaysReplace=i.NONE]="AlwaysReplace",ni[ni.Min=i.MIN]="Min",ni[ni.Max=i.MAX]="Max",ni[ni.Addition=i.FUNC_ADD]="Addition",ni[ni.Subtraction=i.FUNC_SUBTRACT]="Subtraction",ni[ni.ReverseSubtraction=i.FUNC_REVERSE_SUBTRACT]="ReverseSubtraction";(oi=ri||(ri={}))[oi.None=i.NONE]="None",oi[oi.CullFront=i.FRONT]="CullFront",oi[oi.CullBack=i.BACK]="CullBack";class ai{constructor(){this.depth=new Xa,this.stencil=new Ka,this.dithering=!1,this.culling=ri.CullBack,this.colorWrite=[!0,!0,!0,!0]}}class ii{constructor(e){this.gl=e,this.drawParams=new ai,this.renderMesh=(e=>{const t=this.gl,{vao:n,indices:{indexGlType:r,indexBuffer:o,triangleCnt:a}}=e;n.bind(t),o.bind(t),t.drawElements(t.TRIANGLES,3*a,r,0)}),this.renderTressFx=((e,t,n)=>{const r=this.gl;So(this,t,{u_mMat:n.modelMat,u_vpMat:n.viewProjectionMat,u_cameraPosition:n.cameraPosition,u_centerOfGravity:n.cfg.sintel.centerOfGravity,u_viewportSize:Object(a.fromValues)(n.viewport.width,n.viewport.height),u_numVerticesPerStrand:e.numVerticesPerStrand,u_vertexPositionsBuffer:e.positionsTexture,u_vertexTangentsBuffer:e.tangentsTexture,u_fiberRadius:e.fiberRadius*n.radiusMultiplier,u_thinTip:1-e.thinTip,u_followHairSpreadRoot:e.followHairSpreadRoot,u_followHairSpreadTip:e.followHairSpreadTip},!0);const{indexGlType:o,indexBuffer:i,triangleCnt:s}=e.indices,l=3*s;i.bind(r),r.drawElementsInstanced(r.TRIANGLES,l,o,0,e.followHairs)}),this.backbufferFboId=e.getParameter(e.FRAMEBUFFER_BINDING),Za(e,this.drawParams,null,!0),this._surfaceSize={width:0,height:0},this.debugSphereMesh=this.createDebugSphere(e),this.textureBindingState=new he(e)}createDebugSphere(e){const t=Jo({radius:1,segments:12,rings:12});return Va(e,t,"position")}setState(e){const t=this.gl;Za(t,e,this.drawParams),this.drawParams=e}setBackbufferAsRenderTarget(){const e=this.gl;e.bindFramebuffer(e.FRAMEBUFFER,this.backbufferFboId),e.drawBuffers([e.BACK])}renderFullscreenQuad(e=!1){const t=this.gl;if(e){const e=new ai;e.depth.test=ja.AlwaysPass,this.setState(e)}t.drawArrays(t.TRIANGLES,0,3)}renderDebugSphere(){this.renderMesh(this.debugSphereMesh)}set surfaceSize(e){this._surfaceSize.width=e.width,this._surfaceSize.height=e.height}get surfaceSize(){return this._surfaceSize}}var si=function(){return F.a.Date.now()},li="Expected a function",ci=Math.max,ui=Math.min;var di=function(e,t,n){var r,o,a,i,s,l,c=0,u=!1,d=!1,f=!0;if("function"!=typeof e)throw new TypeError(li);function h(t){var n=r,a=o;return r=o=void 0,c=t,i=e.apply(a,n)}function m(e){var n=e-l;return void 0===l||n>=t||n<0||d&&e-c>=a}function p(){var e=si();if(m(e))return _(e);s=setTimeout(p,function(e){var n=t-(e-l);return d?ui(n,a-(e-c)):n}(e))}function _(e){return s=void 0,f&&r?h(e):(r=o=void 0,i)}function v(){var e=si(),n=m(e);if(r=arguments,o=this,l=e,n){if(void 0===s)return function(e){return c=e,s=setTimeout(p,t),u?h(e):i}(l);if(d)return s=setTimeout(p,t),h(l)}return void 0===s&&(s=setTimeout(p,t)),i}return t=oe(t)||0,D(n)&&(u=!!n.leading,a=(d="maxWait"in n)?ci(oe(n.maxWait)||0,t):a,f="trailing"in n?!!n.trailing:f),v.cancel=function(){void 0!==s&&clearTimeout(s),c=0,r=l=o=s=void 0},v.flush=function(){return void 0===s?i:_(si())},v};class fi{constructor(e,t){this.gl=e,this.debouncedHandleResize=null,this.handlers=[],this.onResize=(()=>{const e=this.getScreenSize();this.nextScreen.width===e.width&&this.nextScreen.height===e.height||(this.nextScreen.width=e.width,this.nextScreen.height=e.height,this.debouncedHandleResize())}),this.handleResize=(()=>{const{width:e,height:t}=this.nextScreen;console.log(`Detected viewport (${e}x${t})`);const n=this.gl;n.canvas.width=e,n.canvas.height=t,this.handlers.forEach(e=>e(this.nextScreen))}),this.nextScreen=this.getScreenSize(),this.debouncedHandleResize=di(this.handleResize,t),window.addEventListener("resize",this.onResize,!1)}addHandler(e){this.handlers.push(e)}getScreenSize(){const e=this.gl,t=window.devicePixelRatio;return{width:Math.floor(e.canvas.clientWidth*t),height:Math.floor(e.canvas.clientHeight*t)}}forceRecalc(){this.handleResize()}}const hi=0;class mi{constructor(){this.pressedKeys=new Array(128),this.onKeyDown=(e=>{this.pressedKeys[e.keyCode]=!0}),this.onKeyUp=(e=>{this.pressedKeys[e.keyCode]=!1}),this.isPressed=(e=>this.pressedKeys[e]),window.addEventListener("keydown",this.onKeyDown,!1),window.addEventListener("keyup",this.onKeyUp,!1)}dispose(){window.removeEventListener("keydown",this.onKeyDown,!1),window.removeEventListener("keyup",this.onKeyUp,!1)}}class pi{constructor(e,t){this.element=e,this.fpsController=t,this.isDragging=!1,this.onMouseMove=(e=>{if(!this.isDragging)return;const t=this.getMovement(e);this.fpsController.onMouseDrag(t)}),this.onMouseDown=(e=>{e.button===hi&&(this.isDragging=!0)}),this.onMouseUp=(e=>{e.button===hi&&(this.isDragging=!1)}),this.getMovement=(e=>Object(a.fromValues)(e.movementX||e.mozMovementX||e.webkitMovementX||0,e.movementY||e.mozMovementY||e.webkitMovementY||0)),this.onMouseWheel=(e=>{this.fpsController.onMouseWheel(e.deltaY)}),this.element.addEventListener("mousedown",this.onMouseDown,!1),this.element.addEventListener("mousemove",this.onMouseMove,!1),this.element.addEventListener("mouseup",this.onMouseUp,!1),this.element.addEventListener("mouseleave",this.onMouseUp,!1),this.element.addEventListener("wheel",this.onMouseWheel,!1),this.keyboardState=new mi}dispose(){this.element.removeEventListener("mousedown",this.onMouseDown,!1),this.element.removeEventListener("mousemove",this.onMouseMove,!1),this.element.removeEventListener("mouseup",this.onMouseUp,!1),this.element.removeEventListener("mouseleave",this.onMouseUp,!1),this.element.removeEventListener("wheel",this.onMouseWheel,!1),this.keyboardState.dispose()}update(e){this.fpsController.update(e,this.keyboardState)}}class _i{constructor(){this.frameTimings={deltaTimeMs:0,absoluteTimeMs:0,aboluteFrameId:0}}update(e){const{absoluteTimeMs:t}=this.frameTimings;this.frameTimings.deltaTimeMs=e-t,this.frameTimings.absoluteTimeMs=e,++this.frameTimings.aboluteFrameId}}const vi=n(185);class gi{constructor(){this.statsUI=new vi,this.statsUI.showPanel(1),this.statsUI.showPanel(0),document.body.appendChild(this.statsUI.dom)}frameBegin(){this.statsUI.begin()}frameEnd(){this.statsUI.end()}}function Si(e,t){var n=e.__state.conversionName.toString(),r=Math.round(e.r),o=Math.round(e.g),a=Math.round(e.b),i=e.a,s=Math.round(e.h),l=e.s.toFixed(1),c=e.v.toFixed(1);if(t||"THREE_CHAR_HEX"===n||"SIX_CHAR_HEX"===n){for(var u=e.hex.toString(16);u.length<6;)u="0"+u;return"#"+u}return"CSS_RGB"===n?"rgb("+r+","+o+","+a+")":"CSS_RGBA"===n?"rgba("+r+","+o+","+a+","+i+")":"HEX"===n?"0x"+e.hex.toString(16):"RGB_ARRAY"===n?"["+r+","+o+","+a+"]":"RGBA_ARRAY"===n?"["+r+","+o+","+a+","+i+"]":"RGB_OBJ"===n?"{r:"+r+",g:"+o+",b:"+a+"}":"RGBA_OBJ"===n?"{r:"+r+",g:"+o+",b:"+a+",a:"+i+"}":"HSV_OBJ"===n?"{h:"+s+",s:"+l+",v:"+c+"}":"HSVA_OBJ"===n?"{h:"+s+",s:"+l+",v:"+c+",a:"+i+"}":"unknown format"}var xi=Array.prototype.forEach,bi=Array.prototype.slice,yi={BREAK:{},extend:function(e){return this.each(bi.call(arguments,1),function(t){(this.isObject(t)?Object.keys(t):[]).forEach(function(n){this.isUndefined(t[n])||(e[n]=t[n])}.bind(this))},this),e},defaults:function(e){return this.each(bi.call(arguments,1),function(t){(this.isObject(t)?Object.keys(t):[]).forEach(function(n){this.isUndefined(e[n])&&(e[n]=t[n])}.bind(this))},this),e},compose:function(){var e=bi.call(arguments);return function(){for(var t=bi.call(arguments),n=e.length-1;n>=0;n--)t=[e[n].apply(this,t)];return t[0]}},each:function(e,t,n){if(e)if(xi&&e.forEach&&e.forEach===xi)e.forEach(t,n);else if(e.length===e.length+0){var r,o=void 0;for(o=0,r=e.length;o<r;o++)if(o in e&&t.call(n,e[o],o)===this.BREAK)return}else for(var a in e)if(t.call(n,e[a],a)===this.BREAK)return},defer:function(e){setTimeout(e,0)},debounce:function(e,t,n){var r=void 0;return function(){var o=this,a=arguments;var i=n||!r;clearTimeout(r),r=setTimeout(function(){r=null,n||e.apply(o,a)},t),i&&e.apply(o,a)}},toArray:function(e){return e.toArray?e.toArray():bi.call(e)},isUndefined:function(e){return void 0===e},isNull:function(e){return null===e},isNaN:function(e){function t(t){return e.apply(this,arguments)}return t.toString=function(){return e.toString()},t}(function(e){return isNaN(e)}),isArray:Array.isArray||function(e){return e.constructor===Array},isObject:function(e){return e===Object(e)},isNumber:function(e){return e===e+0},isString:function(e){return e===e+""},isBoolean:function(e){return!1===e||!0===e},isFunction:function(e){return"[object Function]"===Object.prototype.toString.call(e)}},wi=[{litmus:yi.isString,conversions:{THREE_CHAR_HEX:{read:function(e){var t=e.match(/^#([A-F0-9])([A-F0-9])([A-F0-9])$/i);return null!==t&&{space:"HEX",hex:parseInt("0x"+t[1].toString()+t[1].toString()+t[2].toString()+t[2].toString()+t[3].toString()+t[3].toString(),0)}},write:Si},SIX_CHAR_HEX:{read:function(e){var t=e.match(/^#([A-F0-9]{6})$/i);return null!==t&&{space:"HEX",hex:parseInt("0x"+t[1].toString(),0)}},write:Si},CSS_RGB:{read:function(e){var t=e.match(/^rgb\(\s*(.+)\s*,\s*(.+)\s*,\s*(.+)\s*\)/);return null!==t&&{space:"RGB",r:parseFloat(t[1]),g:parseFloat(t[2]),b:parseFloat(t[3])}},write:Si},CSS_RGBA:{read:function(e){var t=e.match(/^rgba\(\s*(.+)\s*,\s*(.+)\s*,\s*(.+)\s*,\s*(.+)\s*\)/);return null!==t&&{space:"RGB",r:parseFloat(t[1]),g:parseFloat(t[2]),b:parseFloat(t[3]),a:parseFloat(t[4])}},write:Si}}},{litmus:yi.isNumber,conversions:{HEX:{read:function(e){return{space:"HEX",hex:e,conversionName:"HEX"}},write:function(e){return e.hex}}}},{litmus:yi.isArray,conversions:{RGB_ARRAY:{read:function(e){return 3===e.length&&{space:"RGB",r:e[0],g:e[1],b:e[2]}},write:function(e){return[e.r,e.g,e.b]}},RGBA_ARRAY:{read:function(e){return 4===e.length&&{space:"RGB",r:e[0],g:e[1],b:e[2],a:e[3]}},write:function(e){return[e.r,e.g,e.b,e.a]}}}},{litmus:yi.isObject,conversions:{RGBA_OBJ:{read:function(e){return!!(yi.isNumber(e.r)&&yi.isNumber(e.g)&&yi.isNumber(e.b)&&yi.isNumber(e.a))&&{space:"RGB",r:e.r,g:e.g,b:e.b,a:e.a}},write:function(e){return{r:e.r,g:e.g,b:e.b,a:e.a}}},RGB_OBJ:{read:function(e){return!!(yi.isNumber(e.r)&&yi.isNumber(e.g)&&yi.isNumber(e.b))&&{space:"RGB",r:e.r,g:e.g,b:e.b}},write:function(e){return{r:e.r,g:e.g,b:e.b}}},HSVA_OBJ:{read:function(e){return!!(yi.isNumber(e.h)&&yi.isNumber(e.s)&&yi.isNumber(e.v)&&yi.isNumber(e.a))&&{space:"HSV",h:e.h,s:e.s,v:e.v,a:e.a}},write:function(e){return{h:e.h,s:e.s,v:e.v,a:e.a}}},HSV_OBJ:{read:function(e){return!!(yi.isNumber(e.h)&&yi.isNumber(e.s)&&yi.isNumber(e.v))&&{space:"HSV",h:e.h,s:e.s,v:e.v}},write:function(e){return{h:e.h,s:e.s,v:e.v}}}}}],Ti=void 0,Ei=void 0,Ai=function(){Ei=!1;var e=arguments.length>1?yi.toArray(arguments):arguments[0];return yi.each(wi,function(t){if(t.litmus(e))return yi.each(t.conversions,function(t,n){if(Ti=t.read(e),!1===Ei&&!1!==Ti)return Ei=Ti,Ti.conversionName=n,Ti.conversion=t,yi.BREAK}),yi.BREAK}),Ei},Pi=void 0,Mi={hsv_to_rgb:function(e,t,n){var r=Math.floor(e/60)%6,o=e/60-Math.floor(e/60),a=n*(1-t),i=n*(1-o*t),s=n*(1-(1-o)*t),l=[[n,s,a],[i,n,a],[a,n,s],[a,i,n],[s,a,n],[n,a,i]][r];return{r:255*l[0],g:255*l[1],b:255*l[2]}},rgb_to_hsv:function(e,t,n){var r=Math.min(e,t,n),o=Math.max(e,t,n),a=o-r,i=void 0;return 0===o?{h:NaN,s:0,v:0}:(i=e===o?(t-n)/a:t===o?2+(n-e)/a:4+(e-t)/a,(i/=6)<0&&(i+=1),{h:360*i,s:a/o,v:o/255})},rgb_to_hex:function(e,t,n){var r=this.hex_with_component(0,2,e);return r=this.hex_with_component(r,1,t),r=this.hex_with_component(r,0,n)},component_from_hex:function(e,t){return e>>8*t&255},hex_with_component:function(e,t,n){return n<<(Pi=8*t)|e&~(255<<Pi)}},Ci="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},Oi=function(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")},Ri=function(){function e(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}return function(t,n,r){return n&&e(t.prototype,n),r&&e(t,r),t}}(),Li=function e(t,n,r){null===t&&(t=Function.prototype);var o=Object.getOwnPropertyDescriptor(t,n);if(void 0===o){var a=Object.getPrototypeOf(t);return null===a?void 0:e(a,n,r)}if("value"in o)return o.value;var i=o.get;return void 0!==i?i.call(r):void 0},Ii=function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function, not "+typeof t);e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,enumerable:!1,writable:!0,configurable:!0}}),t&&(Object.setPrototypeOf?Object.setPrototypeOf(e,t):e.__proto__=t)},Ni=function(e,t){if(!e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return!t||"object"!=typeof t&&"function"!=typeof t?e:t},Di=function(){function e(){if(Oi(this,e),this.__state=Ai.apply(this,arguments),!1===this.__state)throw new Error("Failed to interpret color arguments");this.__state.a=this.__state.a||1}return Ri(e,[{key:"toString",value:function(){return Si(this)}},{key:"toHexString",value:function(){return Si(this,!0)}},{key:"toOriginal",value:function(){return this.__state.conversion.write(this)}}]),e}();function Fi(e,t,n){Object.defineProperty(e,t,{get:function(){return"RGB"===this.__state.space?this.__state[t]:(Di.recalculateRGB(this,t,n),this.__state[t])},set:function(e){"RGB"!==this.__state.space&&(Di.recalculateRGB(this,t,n),this.__state.space="RGB"),this.__state[t]=e}})}function ki(e,t){Object.defineProperty(e,t,{get:function(){return"HSV"===this.__state.space?this.__state[t]:(Di.recalculateHSV(this),this.__state[t])},set:function(e){"HSV"!==this.__state.space&&(Di.recalculateHSV(this),this.__state.space="HSV"),this.__state[t]=e}})}Di.recalculateRGB=function(e,t,n){if("HEX"===e.__state.space)e.__state[t]=Mi.component_from_hex(e.__state.hex,n);else{if("HSV"!==e.__state.space)throw new Error("Corrupted color state");yi.extend(e.__state,Mi.hsv_to_rgb(e.__state.h,e.__state.s,e.__state.v))}},Di.recalculateHSV=function(e){var t=Mi.rgb_to_hsv(e.r,e.g,e.b);yi.extend(e.__state,{s:t.s,v:t.v}),yi.isNaN(t.h)?yi.isUndefined(e.__state.h)&&(e.__state.h=0):e.__state.h=t.h},Di.COMPONENTS=["r","g","b","h","s","v","hex","a"],Fi(Di.prototype,"r",2),Fi(Di.prototype,"g",1),Fi(Di.prototype,"b",0),ki(Di.prototype,"h"),ki(Di.prototype,"s"),ki(Di.prototype,"v"),Object.defineProperty(Di.prototype,"a",{get:function(){return this.__state.a},set:function(e){this.__state.a=e}}),Object.defineProperty(Di.prototype,"hex",{get:function(){return"HEX"!==!this.__state.space&&(this.__state.hex=Mi.rgb_to_hex(this.r,this.g,this.b)),this.__state.hex},set:function(e){this.__state.space="HEX",this.__state.hex=e}});var Bi=function(){function e(t,n){Oi(this,e),this.initialValue=t[n],this.domElement=document.createElement("div"),this.object=t,this.property=n,this.__onChange=void 0,this.__onFinishChange=void 0}return Ri(e,[{key:"onChange",value:function(e){return this.__onChange=e,this}},{key:"onFinishChange",value:function(e){return this.__onFinishChange=e,this}},{key:"setValue",value:function(e){return this.object[this.property]=e,this.__onChange&&this.__onChange.call(this,e),this.updateDisplay(),this}},{key:"getValue",value:function(){return this.object[this.property]}},{key:"updateDisplay",value:function(){return this}},{key:"isModified",value:function(){return this.initialValue!==this.getValue()}}]),e}(),Vi={};yi.each({HTMLEvents:["change"],MouseEvents:["click","mousemove","mousedown","mouseup","mouseover"],KeyboardEvents:["keydown"]},function(e,t){yi.each(e,function(e){Vi[e]=t})});var ji=/(\d+(\.\d+)?)px/;function zi(e){if("0"===e||yi.isUndefined(e))return 0;var t=e.match(ji);return yi.isNull(t)?0:parseFloat(t[1])}var Gi={makeSelectable:function(e,t){void 0!==e&&void 0!==e.style&&(e.onselectstart=t?function(){return!1}:function(){},e.style.MozUserSelect=t?"auto":"none",e.style.KhtmlUserSelect=t?"auto":"none",e.unselectable=t?"on":"off")},makeFullscreen:function(e,t,n){var r=n,o=t;yi.isUndefined(o)&&(o=!0),yi.isUndefined(r)&&(r=!0),e.style.position="absolute",o&&(e.style.left=0,e.style.right=0),r&&(e.style.top=0,e.style.bottom=0)},fakeEvent:function(e,t,n,r){var o=n||{},a=Vi[t];if(!a)throw new Error("Event type "+t+" not supported.");var i=document.createEvent(a);switch(a){case"MouseEvents":var s=o.x||o.clientX||0,l=o.y||o.clientY||0;i.initMouseEvent(t,o.bubbles||!1,o.cancelable||!0,window,o.clickCount||1,0,0,s,l,!1,!1,!1,!1,0,null);break;case"KeyboardEvents":var c=i.initKeyboardEvent||i.initKeyEvent;yi.defaults(o,{cancelable:!0,ctrlKey:!1,altKey:!1,shiftKey:!1,metaKey:!1,keyCode:void 0,charCode:void 0}),c(t,o.bubbles||!1,o.cancelable,window,o.ctrlKey,o.altKey,o.shiftKey,o.metaKey,o.keyCode,o.charCode);break;default:i.initEvent(t,o.bubbles||!1,o.cancelable||!0)}yi.defaults(i,r),e.dispatchEvent(i)},bind:function(e,t,n,r){var o=r||!1;return e.addEventListener?e.addEventListener(t,n,o):e.attachEvent&&e.attachEvent("on"+t,n),Gi},unbind:function(e,t,n,r){var o=r||!1;return e.removeEventListener?e.removeEventListener(t,n,o):e.detachEvent&&e.detachEvent("on"+t,n),Gi},addClass:function(e,t){if(void 0===e.className)e.className=t;else if(e.className!==t){var n=e.className.split(/ +/);-1===n.indexOf(t)&&(n.push(t),e.className=n.join(" ").replace(/^\s+/,"").replace(/\s+$/,""))}return Gi},removeClass:function(e,t){if(t)if(e.className===t)e.removeAttribute("class");else{var n=e.className.split(/ +/),r=n.indexOf(t);-1!==r&&(n.splice(r,1),e.className=n.join(" "))}else e.className=void 0;return Gi},hasClass:function(e,t){return new RegExp("(?:^|\\s+)"+t+"(?:\\s+|$)").test(e.className)||!1},getWidth:function(e){var t=getComputedStyle(e);return zi(t["border-left-width"])+zi(t["border-right-width"])+zi(t["padding-left"])+zi(t["padding-right"])+zi(t.width)},getHeight:function(e){var t=getComputedStyle(e);return zi(t["border-top-width"])+zi(t["border-bottom-width"])+zi(t["padding-top"])+zi(t["padding-bottom"])+zi(t.height)},getOffset:function(e){var t=e,n={left:0,top:0};if(t.offsetParent)do{n.left+=t.offsetLeft,n.top+=t.offsetTop,t=t.offsetParent}while(t);return n},isActive:function(e){return e===document.activeElement&&(e.type||e.href)}},Ui=function(e){function t(e,n){Oi(this,t);var r=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n)),o=r;return r.__prev=r.getValue(),r.__checkbox=document.createElement("input"),r.__checkbox.setAttribute("type","checkbox"),Gi.bind(r.__checkbox,"change",function(){o.setValue(!o.__prev)},!1),r.domElement.appendChild(r.__checkbox),r.updateDisplay(),r}return Ii(t,Bi),Ri(t,[{key:"setValue",value:function(e){var n=Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"setValue",this).call(this,e);return this.__onFinishChange&&this.__onFinishChange.call(this,this.getValue()),this.__prev=this.getValue(),n}},{key:"updateDisplay",value:function(){return!0===this.getValue()?(this.__checkbox.setAttribute("checked","checked"),this.__checkbox.checked=!0,this.__prev=!0):(this.__checkbox.checked=!1,this.__prev=!1),Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"updateDisplay",this).call(this)}}]),t}(),Hi=function(e){function t(e,n,r){Oi(this,t);var o=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n)),a=r,i=o;if(o.__select=document.createElement("select"),yi.isArray(a)){var s={};yi.each(a,function(e){s[e]=e}),a=s}return yi.each(a,function(e,t){var n=document.createElement("option");n.innerHTML=t,n.setAttribute("value",e),i.__select.appendChild(n)}),o.updateDisplay(),Gi.bind(o.__select,"change",function(){var e=this.options[this.selectedIndex].value;i.setValue(e)}),o.domElement.appendChild(o.__select),o}return Ii(t,Bi),Ri(t,[{key:"setValue",value:function(e){var n=Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"setValue",this).call(this,e);return this.__onFinishChange&&this.__onFinishChange.call(this,this.getValue()),n}},{key:"updateDisplay",value:function(){return Gi.isActive(this.__select)?this:(this.__select.value=this.getValue(),Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"updateDisplay",this).call(this))}}]),t}(),Wi=function(e){function t(e,n){Oi(this,t);var r=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n)),o=r;function a(){o.setValue(o.__input.value)}return r.__input=document.createElement("input"),r.__input.setAttribute("type","text"),Gi.bind(r.__input,"keyup",a),Gi.bind(r.__input,"change",a),Gi.bind(r.__input,"blur",function(){o.__onFinishChange&&o.__onFinishChange.call(o,o.getValue())}),Gi.bind(r.__input,"keydown",function(e){13===e.keyCode&&this.blur()}),r.updateDisplay(),r.domElement.appendChild(r.__input),r}return Ii(t,Bi),Ri(t,[{key:"updateDisplay",value:function(){return Gi.isActive(this.__input)||(this.__input.value=this.getValue()),Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"updateDisplay",this).call(this)}}]),t}();function Yi(e){var t=e.toString();return t.indexOf(".")>-1?t.length-t.indexOf(".")-1:0}var Xi=function(e){function t(e,n,r){Oi(this,t);var o=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n)),a=r||{};return o.__min=a.min,o.__max=a.max,o.__step=a.step,yi.isUndefined(o.__step)?0===o.initialValue?o.__impliedStep=1:o.__impliedStep=Math.pow(10,Math.floor(Math.log(Math.abs(o.initialValue))/Math.LN10))/10:o.__impliedStep=o.__step,o.__precision=Yi(o.__impliedStep),o}return Ii(t,Bi),Ri(t,[{key:"setValue",value:function(e){var n=e;return void 0!==this.__min&&n<this.__min?n=this.__min:void 0!==this.__max&&n>this.__max&&(n=this.__max),void 0!==this.__step&&n%this.__step!=0&&(n=Math.round(n/this.__step)*this.__step),Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"setValue",this).call(this,n)}},{key:"min",value:function(e){return this.__min=e,this}},{key:"max",value:function(e){return this.__max=e,this}},{key:"step",value:function(e){return this.__step=e,this.__impliedStep=e,this.__precision=Yi(e),this}}]),t}();var qi=function(e){function t(e,n,r){Oi(this,t);var o=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n,r));o.__truncationSuspended=!1;var a=o,i=void 0;function s(){a.__onFinishChange&&a.__onFinishChange.call(a,a.getValue())}function l(e){var t=i-e.clientY;a.setValue(a.getValue()+t*a.__impliedStep),i=e.clientY}function c(){Gi.unbind(window,"mousemove",l),Gi.unbind(window,"mouseup",c),s()}return o.__input=document.createElement("input"),o.__input.setAttribute("type","text"),Gi.bind(o.__input,"change",function(){var e=parseFloat(a.__input.value);yi.isNaN(e)||a.setValue(e)}),Gi.bind(o.__input,"blur",function(){s()}),Gi.bind(o.__input,"mousedown",function(e){Gi.bind(window,"mousemove",l),Gi.bind(window,"mouseup",c),i=e.clientY}),Gi.bind(o.__input,"keydown",function(e){13===e.keyCode&&(a.__truncationSuspended=!0,this.blur(),a.__truncationSuspended=!1,s())}),o.updateDisplay(),o.domElement.appendChild(o.__input),o}return Ii(t,Xi),Ri(t,[{key:"updateDisplay",value:function(){var e,n,r;return this.__input.value=this.__truncationSuspended?this.getValue():(e=this.getValue(),n=this.__precision,r=Math.pow(10,n),Math.round(e*r)/r),Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"updateDisplay",this).call(this)}}]),t}();function Ki(e,t,n,r,o){return r+(e-t)/(n-t)*(o-r)}var $i=function(e){function t(e,n,r,o,a){Oi(this,t);var i=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n,{min:r,max:o,step:a})),s=i;function l(e){e.preventDefault();var t=s.__background.getBoundingClientRect();return s.setValue(Ki(e.clientX,t.left,t.right,s.__min,s.__max)),!1}function c(){Gi.unbind(window,"mousemove",l),Gi.unbind(window,"mouseup",c),s.__onFinishChange&&s.__onFinishChange.call(s,s.getValue())}function u(e){var t=e.touches[0].clientX,n=s.__background.getBoundingClientRect();s.setValue(Ki(t,n.left,n.right,s.__min,s.__max))}function d(){Gi.unbind(window,"touchmove",u),Gi.unbind(window,"touchend",d),s.__onFinishChange&&s.__onFinishChange.call(s,s.getValue())}return i.__background=document.createElement("div"),i.__foreground=document.createElement("div"),Gi.bind(i.__background,"mousedown",function(e){document.activeElement.blur(),Gi.bind(window,"mousemove",l),Gi.bind(window,"mouseup",c),l(e)}),Gi.bind(i.__background,"touchstart",function(e){if(1!==e.touches.length)return;Gi.bind(window,"touchmove",u),Gi.bind(window,"touchend",d),u(e)}),Gi.addClass(i.__background,"slider"),Gi.addClass(i.__foreground,"slider-fg"),i.updateDisplay(),i.__background.appendChild(i.__foreground),i.domElement.appendChild(i.__background),i}return Ii(t,Xi),Ri(t,[{key:"updateDisplay",value:function(){var e=(this.getValue()-this.__min)/(this.__max-this.__min);return this.__foreground.style.width=100*e+"%",Li(t.prototype.__proto__||Object.getPrototypeOf(t.prototype),"updateDisplay",this).call(this)}}]),t}(),Qi=function(e){function t(e,n,r){Oi(this,t);var o=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n)),a=o;return o.__button=document.createElement("div"),o.__button.innerHTML=void 0===r?"Fire":r,Gi.bind(o.__button,"click",function(e){return e.preventDefault(),a.fire(),!1}),Gi.addClass(o.__button,"button"),o.domElement.appendChild(o.__button),o}return Ii(t,Bi),Ri(t,[{key:"fire",value:function(){this.__onChange&&this.__onChange.call(this),this.getValue().call(this.object),this.__onFinishChange&&this.__onFinishChange.call(this,this.getValue())}}]),t}(),Zi=function(e){function t(e,n){Oi(this,t);var r=Ni(this,(t.__proto__||Object.getPrototypeOf(t)).call(this,e,n));r.__color=new Di(r.getValue()),r.__temp=new Di(0);var o=r;r.domElement=document.createElement("div"),Gi.makeSelectable(r.domElement,!1),r.__selector=document.createElement("div"),r.__selector.className="selector",r.__saturation_field=document.createElement("div"),r.__saturation_field.className="saturation-field",r.__field_knob=document.createElement("div"),r.__field_knob.className="field-knob",r.__field_knob_border="2px solid ",r.__hue_knob=document.createElement("div"),r.__hue_knob.className="hue-knob",r.__hue_field=document.createElement("div"),r.__hue_field.className="hue-field",r.__input=document.createElement("input"),r.__input.type="text",r.__input_textShadow="0 1px 1px ",Gi.bind(r.__input,"keydown",function(e){13===e.keyCode&&d.call(this)}),Gi.bind(r.__input,"blur",d),Gi.bind(r.__selector,"mousedown",function(){Gi.addClass(this,"drag").bind(window,"mouseup",function(){Gi.removeClass(o.__selector,"drag")})}),Gi.bind(r.__selector,"touchstart",function(){Gi.addClass(this,"drag").bind(window,"touchend",function(){Gi.removeClass(o.__selector,"drag")})});var a,i=document.createElement("div");function s(e){h(e),Gi.bind(window,"mousemove",h),Gi.bind(window,"touchmove",h),Gi.bind(window,"mouseup",c),Gi.bind(window,"touchend",c)}function l(e){m(e),Gi.bind(window,"mousemove",m),Gi.bind(window,"touchmove",m),Gi.bind(window,"mouseup",u),Gi.bind(window,"touchend",u)}function c(){Gi.unbind(window,"mousemove",h),Gi.unbind(window,"touchmove",h),Gi.unbind(window,"mouseup",c),Gi.unbind(window,"touchend",c),f()}function u(){Gi.unbind(window,"mousemove",m),Gi.unbind(window,"touchmove",m),Gi.unbind(window,"mouseup",u),Gi.unbind(window,"touchend",u),f()}function d(){var e=Ai(this.value);!1!==e?(o.__color.__state=e,o.setValue(o.__color.toOriginal())):this.value=o.__color.toString()}function f(){o.__onFinishChange&&o.__onFinishChange.call(o,o.__color.toOriginal())}function h(e){-1===e.type.indexOf("touch")&&e.preventDefault();var t=o.__saturation_field.getBoundingClientRect(),n=e.touches&&e.touches[0]||e,r=n.clientX,a=n.clientY,i=(r-t.left)/(t.right-t.left),s=1-(a-t.top)/(t.bottom-t.top);return s>1?s=1:s<0&&(s=0),i>1?i=1:i<0&&(i=0),o.__color.v=s,o.__color.s=i,o.setValue(o.__color.toOriginal()),!1}function m(e){-1===e.type.indexOf("touch")&&e.preventDefault();var t=o.__hue_field.getBoundingClientRect(),n=1-((e.touches&&e.touches[0]||e).clientY-t.top)/(t.bottom-t.top);return n>1?n=1:n<0&&(n=0),o.__color.h=360*n,o.setValue(o.__color.toOriginal()),!1}return yi.extend(r.__selector.style,{width:"122px",height:"102px",padding:"3px",backgroundColor:"#222",boxShadow:"0px 1px 3px rgba(0,0,0,0.3)"}),yi.extend(r.__field_knob.style,{position:"absolute",width:"12px",height:"12px",border:r.__field_knob_border+(r.__color.v<.5?"#fff":"#000"),boxShadow:"0px 1px 3px rgba(0,0,0,0.5)",borderRadius:"12px",zIndex:1}),yi.extend(r.__hue_knob.style,{position:"absolute",width:"15px",height:"2px",borderRight:"4px solid #fff",zIndex:1}),yi.extend(r.__saturation_field.style,{width:"100px",height:"100px",border:"1px solid #555",marginRight:"3px",display:"inline-block",cursor:"pointer"}),yi.extend(i.style,{width:"100%",height:"100%",background:"none"}),es(i,"top","rgba(0,0,0,0)","#000"),yi.extend(r.__hue_field.style,{width:"15px",height:"100px",border:"1px solid #555",cursor:"ns-resize",position:"absolute",top:"3px",right:"3px"}),(a=r.__hue_field).style.background="",a.style.cssText+="background: -moz-linear-gradient(top,  #ff0000 0%, #ff00ff 17%, #0000ff 34%, #00ffff 50%, #00ff00 67%, #ffff00 84%, #ff0000 100%);",a.style.cssText+="background: -webkit-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);",a.style.cssText+="background: -o-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);",a.style.cssText+="background: -ms-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);",a.style.cssText+="background: linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);",yi.extend(r.__input.style,{outline:"none",textAlign:"center",color:"#fff",border:0,fontWeight:"bold",textShadow:r.__input_textShadow+"rgba(0,0,0,0.7)"}),Gi.bind(r.__saturation_field,"mousedown",s),Gi.bind(r.__saturation_field,"touchstart",s),Gi.bind(r.__field_knob,"mousedown",s),Gi.bind(r.__field_knob,"touchstart",s),Gi.bind(r.__hue_field,"mousedown",l),Gi.bind(r.__hue_field,"touchstart",l),r.__saturation_field.appendChild(i),r.__selector.appendChild(r.__field_knob),r.__selector.appendChild(r.__saturation_field),r.__selector.appendChild(r.__hue_field),r.__hue_field.appendChild(r.__hue_knob),r.domElement.appendChild(r.__input),r.domElement.appendChild(r.__selector),r.updateDisplay(),r}return Ii(t,Bi),Ri(t,[{key:"updateDisplay",value:function(){var e=Ai(this.getValue());if(!1!==e){var t=!1;yi.each(Di.COMPONENTS,function(n){if(!yi.isUndefined(e[n])&&!yi.isUndefined(this.__color.__state[n])&&e[n]!==this.__color.__state[n])return t=!0,{}},this),t&&yi.extend(this.__color.__state,e)}yi.extend(this.__temp.__state,this.__color.__state),this.__temp.a=1;var n=this.__color.v<.5||this.__color.s>.5?255:0,r=255-n;yi.extend(this.__field_knob.style,{marginLeft:100*this.__color.s-7+"px",marginTop:100*(1-this.__color.v)-7+"px",backgroundColor:this.__temp.toHexString(),border:this.__field_knob_border+"rgb("+n+","+n+","+n+")"}),this.__hue_knob.style.marginTop=100*(1-this.__color.h/360)+"px",this.__temp.s=1,this.__temp.v=1,es(this.__saturation_field,"left","#fff",this.__temp.toHexString()),this.__input.value=this.__color.toString(),yi.extend(this.__input.style,{backgroundColor:this.__color.toHexString(),color:"rgb("+n+","+n+","+n+")",textShadow:this.__input_textShadow+"rgba("+r+","+r+","+r+",.7)"})}}]),t}(),Ji=["-moz-","-o-","-webkit-","-ms-",""];function es(e,t,n,r){e.style.background="",yi.each(Ji,function(o){e.style.cssText+="background: "+o+"linear-gradient("+t+", "+n+" 0%, "+r+" 100%); "})}var ts=function(e,t){var n=t||document,r=document.createElement("style");r.type="text/css",r.innerHTML=e;var o=n.getElementsByTagName("head")[0];try{o.appendChild(r)}catch(e){}},ns=function(e,t){var n=e[t];return yi.isArray(arguments[2])||yi.isObject(arguments[2])?new Hi(e,t,arguments[2]):yi.isNumber(n)?yi.isNumber(arguments[2])&&yi.isNumber(arguments[3])?yi.isNumber(arguments[4])?new $i(e,t,arguments[2],arguments[3],arguments[4]):new $i(e,t,arguments[2],arguments[3]):yi.isNumber(arguments[4])?new qi(e,t,{min:arguments[2],max:arguments[3],step:arguments[4]}):new qi(e,t,{min:arguments[2],max:arguments[3]}):yi.isString(n)?new Wi(e,t):yi.isFunction(n)?new Qi(e,t,""):yi.isBoolean(n)?new Ui(e,t):null};var rs=window.requestAnimationFrame||window.webkitRequestAnimationFrame||window.mozRequestAnimationFrame||window.oRequestAnimationFrame||window.msRequestAnimationFrame||function(e){setTimeout(e,1e3/60)},os=function(){function e(){Oi(this,e),this.backgroundElement=document.createElement("div"),yi.extend(this.backgroundElement.style,{backgroundColor:"rgba(0,0,0,0.8)",top:0,left:0,display:"none",zIndex:"1000",opacity:0,WebkitTransition:"opacity 0.2s linear",transition:"opacity 0.2s linear"}),Gi.makeFullscreen(this.backgroundElement),this.backgroundElement.style.position="fixed",this.domElement=document.createElement("div"),yi.extend(this.domElement.style,{position:"fixed",display:"none",zIndex:"1001",opacity:0,WebkitTransition:"-webkit-transform 0.2s ease-out, opacity 0.2s linear",transition:"transform 0.2s ease-out, opacity 0.2s linear"}),document.body.appendChild(this.backgroundElement),document.body.appendChild(this.domElement);var t=this;Gi.bind(this.backgroundElement,"click",function(){t.hide()})}return Ri(e,[{key:"show",value:function(){var e=this;this.backgroundElement.style.display="block",this.domElement.style.display="block",this.domElement.style.opacity=0,this.domElement.style.webkitTransform="scale(1.1)",this.layout(),yi.defer(function(){e.backgroundElement.style.opacity=1,e.domElement.style.opacity=1,e.domElement.style.webkitTransform="scale(1)"})}},{key:"hide",value:function(){var e=this,t=function t(){e.domElement.style.display="none",e.backgroundElement.style.display="none",Gi.unbind(e.domElement,"webkitTransitionEnd",t),Gi.unbind(e.domElement,"transitionend",t),Gi.unbind(e.domElement,"oTransitionEnd",t)};Gi.bind(this.domElement,"webkitTransitionEnd",t),Gi.bind(this.domElement,"transitionend",t),Gi.bind(this.domElement,"oTransitionEnd",t),this.backgroundElement.style.opacity=0,this.domElement.style.opacity=0,this.domElement.style.webkitTransform="scale(1.1)"}},{key:"layout",value:function(){this.domElement.style.left=window.innerWidth/2-Gi.getWidth(this.domElement)/2+"px",this.domElement.style.top=window.innerHeight/2-Gi.getHeight(this.domElement)/2+"px"}}]),e}();ts(function(e){if(e&&"undefined"!=typeof window){var t=document.createElement("style");return t.setAttribute("type","text/css"),t.innerHTML=e,document.head.appendChild(t),e}}(".dg ul{list-style:none;margin:0;padding:0;width:100%;clear:both}.dg.ac{position:fixed;top:0;left:0;right:0;height:0;z-index:0}.dg:not(.ac) .main{overflow:hidden}.dg.main{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear}.dg.main.taller-than-window{overflow-y:auto}.dg.main.taller-than-window .close-button{opacity:1;margin-top:-1px;border-top:1px solid #2c2c2c}.dg.main ul.closed .close-button{opacity:1 !important}.dg.main:hover .close-button,.dg.main .close-button.drag{opacity:1}.dg.main .close-button{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear;border:0;line-height:19px;height:20px;cursor:pointer;text-align:center;background-color:#000}.dg.main .close-button.close-top{position:relative}.dg.main .close-button.close-bottom{position:absolute}.dg.main .close-button:hover{background-color:#111}.dg.a{float:right;margin-right:15px;overflow-y:visible}.dg.a.has-save>ul.close-top{margin-top:0}.dg.a.has-save>ul.close-bottom{margin-top:27px}.dg.a.has-save>ul.closed{margin-top:0}.dg.a .save-row{top:0;z-index:1002}.dg.a .save-row.close-top{position:relative}.dg.a .save-row.close-bottom{position:fixed}.dg li{-webkit-transition:height .1s ease-out;-o-transition:height .1s ease-out;-moz-transition:height .1s ease-out;transition:height .1s ease-out;-webkit-transition:overflow .1s linear;-o-transition:overflow .1s linear;-moz-transition:overflow .1s linear;transition:overflow .1s linear}.dg li:not(.folder){cursor:auto;height:27px;line-height:27px;padding:0 4px 0 5px}.dg li.folder{padding:0;border-left:4px solid rgba(0,0,0,0)}.dg li.title{cursor:pointer;margin-left:-4px}.dg .closed li:not(.title),.dg .closed ul li,.dg .closed ul li>*{height:0;overflow:hidden;border:0}.dg .cr{clear:both;padding-left:3px;height:27px;overflow:hidden}.dg .property-name{cursor:default;float:left;clear:left;width:40%;overflow:hidden;text-overflow:ellipsis}.dg .c{float:left;width:60%;position:relative}.dg .c input[type=text]{border:0;margin-top:4px;padding:3px;width:100%;float:right}.dg .has-slider input[type=text]{width:30%;margin-left:0}.dg .slider{float:left;width:66%;margin-left:-5px;margin-right:0;height:19px;margin-top:4px}.dg .slider-fg{height:100%}.dg .c input[type=checkbox]{margin-top:7px}.dg .c select{margin-top:5px}.dg .cr.function,.dg .cr.function .property-name,.dg .cr.function *,.dg .cr.boolean,.dg .cr.boolean *{cursor:pointer}.dg .cr.color{overflow:visible}.dg .selector{display:none;position:absolute;margin-left:-9px;margin-top:23px;z-index:10}.dg .c:hover .selector,.dg .selector.drag{display:block}.dg li.save-row{padding:0}.dg li.save-row .button{display:inline-block;padding:0px 6px}.dg.dialogue{background-color:#222;width:460px;padding:15px;font-size:13px;line-height:15px}#dg-new-constructor{padding:10px;color:#222;font-family:Monaco, monospace;font-size:10px;border:0;resize:none;box-shadow:inset 1px 1px 1px #888;word-wrap:break-word;margin:12px 0;display:block;width:440px;overflow-y:scroll;height:100px;position:relative}#dg-local-explain{display:none;font-size:11px;line-height:17px;border-radius:3px;background-color:#333;padding:8px;margin-top:10px}#dg-local-explain code{font-size:10px}#dat-gui-save-locally{display:none}.dg{color:#eee;font:11px 'Lucida Grande', sans-serif;text-shadow:0 -1px 0 #111}.dg.main::-webkit-scrollbar{width:5px;background:#1a1a1a}.dg.main::-webkit-scrollbar-corner{height:0;display:none}.dg.main::-webkit-scrollbar-thumb{border-radius:5px;background:#676767}.dg li:not(.folder){background:#1a1a1a;border-bottom:1px solid #2c2c2c}.dg li.save-row{line-height:25px;background:#dad5cb;border:0}.dg li.save-row select{margin-left:5px;width:108px}.dg li.save-row .button{margin-left:5px;margin-top:1px;border-radius:2px;font-size:9px;line-height:7px;padding:4px 4px 5px 4px;background:#c5bdad;color:#fff;text-shadow:0 1px 0 #b0a58f;box-shadow:0 -1px 0 #b0a58f;cursor:pointer}.dg li.save-row .button.gears{background:#c5bdad url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAANCAYAAAB/9ZQ7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAQJJREFUeNpiYKAU/P//PwGIC/ApCABiBSAW+I8AClAcgKxQ4T9hoMAEUrxx2QSGN6+egDX+/vWT4e7N82AMYoPAx/evwWoYoSYbACX2s7KxCxzcsezDh3evFoDEBYTEEqycggWAzA9AuUSQQgeYPa9fPv6/YWm/Acx5IPb7ty/fw+QZblw67vDs8R0YHyQhgObx+yAJkBqmG5dPPDh1aPOGR/eugW0G4vlIoTIfyFcA+QekhhHJhPdQxbiAIguMBTQZrPD7108M6roWYDFQiIAAv6Aow/1bFwXgis+f2LUAynwoIaNcz8XNx3Dl7MEJUDGQpx9gtQ8YCueB+D26OECAAQDadt7e46D42QAAAABJRU5ErkJggg==) 2px 1px no-repeat;height:7px;width:8px}.dg li.save-row .button:hover{background-color:#bab19e;box-shadow:0 -1px 0 #b0a58f}.dg li.folder{border-bottom:0}.dg li.title{padding-left:16px;background:#000 url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlI+hKgFxoCgAOw==) 6px 10px no-repeat;cursor:pointer;border-bottom:1px solid rgba(255,255,255,0.2)}.dg .closed li.title{background-image:url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlGIWqMCbWAEAOw==)}.dg .cr.boolean{border-left:3px solid #806787}.dg .cr.color{border-left:3px solid}.dg .cr.function{border-left:3px solid #e61d5f}.dg .cr.number{border-left:3px solid #2FA1D6}.dg .cr.number input[type=text]{color:#2FA1D6}.dg .cr.string{border-left:3px solid #1ed36f}.dg .cr.string input[type=text]{color:#1ed36f}.dg .cr.function:hover,.dg .cr.boolean:hover{background:#111}.dg .c input[type=text]{background:#303030;outline:none}.dg .c input[type=text]:hover{background:#3c3c3c}.dg .c input[type=text]:focus{background:#494949;color:#fff}.dg .c .slider{background:#303030;cursor:ew-resize}.dg .c .slider-fg{background:#2FA1D6;max-width:100%}.dg .c .slider:hover{background:#3c3c3c}.dg .c .slider:hover .slider-fg{background:#44abda}\n"));var as="Default",is=function(){try{return!!window.localStorage}catch(e){return!1}}(),ss=void 0,ls=!0,cs=void 0,us=!1,ds=[],fs=function e(t){var n=this,r=t||{};this.domElement=document.createElement("div"),this.__ul=document.createElement("ul"),this.domElement.appendChild(this.__ul),Gi.addClass(this.domElement,"dg"),this.__folders={},this.__controllers=[],this.__rememberedObjects=[],this.__rememberedObjectIndecesToControllers=[],this.__listening=[],r=yi.defaults(r,{closeOnTop:!1,autoPlace:!0,width:e.DEFAULT_WIDTH}),r=yi.defaults(r,{resizable:r.autoPlace,hideable:r.autoPlace}),yi.isUndefined(r.load)?r.load={preset:as}:r.preset&&(r.load.preset=r.preset),yi.isUndefined(r.parent)&&r.hideable&&ds.push(this),r.resizable=yi.isUndefined(r.parent)&&r.resizable,r.autoPlace&&yi.isUndefined(r.scrollable)&&(r.scrollable=!0);var o,a=is&&"true"===localStorage.getItem(gs(this,"isLocal")),i=void 0,s=void 0;if(Object.defineProperties(this,{parent:{get:function(){return r.parent}},scrollable:{get:function(){return r.scrollable}},autoPlace:{get:function(){return r.autoPlace}},closeOnTop:{get:function(){return r.closeOnTop}},preset:{get:function(){return n.parent?n.getRoot().preset:r.load.preset},set:function(e){n.parent?n.getRoot().preset=e:r.load.preset=e,function(e){for(var t=0;t<e.__preset_select.length;t++)e.__preset_select[t].value===e.preset&&(e.__preset_select.selectedIndex=t)}(this),n.revert()}},width:{get:function(){return r.width},set:function(e){r.width=e,ys(n,e)}},name:{get:function(){return r.name},set:function(e){r.name=e,s&&(s.innerHTML=r.name)}},closed:{get:function(){return r.closed},set:function(t){r.closed=t,r.closed?Gi.addClass(n.__ul,e.CLASS_CLOSED):Gi.removeClass(n.__ul,e.CLASS_CLOSED),this.onResize(),n.__closeButton&&(n.__closeButton.innerHTML=t?e.TEXT_OPEN:e.TEXT_CLOSED)}},load:{get:function(){return r.load}},useLocalStorage:{get:function(){return a},set:function(e){is&&(a=e,e?Gi.bind(window,"unload",i):Gi.unbind(window,"unload",i),localStorage.setItem(gs(n,"isLocal"),e))}}}),yi.isUndefined(r.parent)){if(this.closed=r.closed||!1,Gi.addClass(this.domElement,e.CLASS_MAIN),Gi.makeSelectable(this.domElement,!1),is&&a){n.useLocalStorage=!0;var l=localStorage.getItem(gs(this,"gui"));l&&(r.load=JSON.parse(l))}this.__closeButton=document.createElement("div"),this.__closeButton.innerHTML=e.TEXT_CLOSED,Gi.addClass(this.__closeButton,e.CLASS_CLOSE_BUTTON),r.closeOnTop?(Gi.addClass(this.__closeButton,e.CLASS_CLOSE_TOP),this.domElement.insertBefore(this.__closeButton,this.domElement.childNodes[0])):(Gi.addClass(this.__closeButton,e.CLASS_CLOSE_BOTTOM),this.domElement.appendChild(this.__closeButton)),Gi.bind(this.__closeButton,"click",function(){n.closed=!n.closed})}else{void 0===r.closed&&(r.closed=!0);var c=document.createTextNode(r.name);Gi.addClass(c,"controller-name"),s=hs(n,c);Gi.addClass(this.__ul,e.CLASS_CLOSED),Gi.addClass(s,"title"),Gi.bind(s,"click",function(e){return e.preventDefault(),n.closed=!n.closed,!1}),r.closed||(this.closed=!1)}r.autoPlace&&(yi.isUndefined(r.parent)&&(ls&&(cs=document.createElement("div"),Gi.addClass(cs,"dg"),Gi.addClass(cs,e.CLASS_AUTO_PLACE_CONTAINER),document.body.appendChild(cs),ls=!1),cs.appendChild(this.domElement),Gi.addClass(this.domElement,e.CLASS_AUTO_PLACE)),this.parent||ys(n,r.width)),this.__resizeHandler=function(){n.onResizeDebounced()},Gi.bind(window,"resize",this.__resizeHandler),Gi.bind(this.__ul,"webkitTransitionEnd",this.__resizeHandler),Gi.bind(this.__ul,"transitionend",this.__resizeHandler),Gi.bind(this.__ul,"oTransitionEnd",this.__resizeHandler),this.onResize(),r.resizable&&bs(this),i=function(){is&&"true"===localStorage.getItem(gs(n,"isLocal"))&&localStorage.setItem(gs(n,"gui"),JSON.stringify(n.getSaveObject()))},this.saveToLocalStorageIfPossible=i,r.parent||((o=n.getRoot()).width+=1,yi.defer(function(){o.width-=1}))};function hs(e,t,n){var r=document.createElement("li");return t&&r.appendChild(t),n?e.__ul.insertBefore(r,n):e.__ul.appendChild(r),e.onResize(),r}function ms(e){Gi.unbind(window,"resize",e.__resizeHandler),e.saveToLocalStorageIfPossible&&Gi.unbind(window,"unload",e.saveToLocalStorageIfPossible)}function ps(e,t){var n=e.__preset_select[e.__preset_select.selectedIndex];n.innerHTML=t?n.value+"*":n.value}function _s(e,t){var n=e.getRoot(),r=n.__rememberedObjects.indexOf(t.object);if(-1!==r){var o=n.__rememberedObjectIndecesToControllers[r];if(void 0===o&&(o={},n.__rememberedObjectIndecesToControllers[r]=o),o[t.property]=t,n.load&&n.load.remembered){var a=n.load.remembered,i=void 0;if(a[e.preset])i=a[e.preset];else{if(!a[as])return;i=a[as]}if(i[r]&&void 0!==i[r][t.property]){var s=i[r][t.property];t.initialValue=s,t.setValue(s)}}}}function vs(e,t,n,r){if(void 0===t[n])throw new Error('Object "'+t+'" has no property "'+n+'"');var o=void 0;if(r.color)o=new Zi(t,n);else{var a=[t,n].concat(r.factoryArgs);o=ns.apply(e,a)}r.before instanceof Bi&&(r.before=r.before.__li),_s(e,o),Gi.addClass(o.domElement,"c");var i=document.createElement("span");Gi.addClass(i,"property-name"),i.innerHTML=o.property;var s=document.createElement("div");s.appendChild(i),s.appendChild(o.domElement);var l=hs(e,s,r.before);return Gi.addClass(l,fs.CLASS_CONTROLLER_ROW),o instanceof Zi?Gi.addClass(l,"color"):Gi.addClass(l,Ci(o.getValue())),function(e,t,n){if(n.__li=t,n.__gui=e,yi.extend(n,{options:function(t){if(arguments.length>1){var r=n.__li.nextElementSibling;return n.remove(),vs(e,n.object,n.property,{before:r,factoryArgs:[yi.toArray(arguments)]})}if(yi.isArray(t)||yi.isObject(t)){var o=n.__li.nextElementSibling;return n.remove(),vs(e,n.object,n.property,{before:o,factoryArgs:[t]})}},name:function(e){return n.__li.firstElementChild.firstElementChild.innerHTML=e,n},listen:function(){return n.__gui.listen(n),n},remove:function(){return n.__gui.remove(n),n}}),n instanceof $i){var r=new qi(n.object,n.property,{min:n.__min,max:n.__max,step:n.__step});yi.each(["updateDisplay","onChange","onFinishChange","step","min","max"],function(e){var t=n[e],o=r[e];n[e]=r[e]=function(){var e=Array.prototype.slice.call(arguments);return o.apply(r,e),t.apply(n,e)}}),Gi.addClass(t,"has-slider"),n.domElement.insertBefore(r.domElement,n.domElement.firstElementChild)}else if(n instanceof qi){var o=function(t){if(yi.isNumber(n.__min)&&yi.isNumber(n.__max)){var r=n.__li.firstElementChild.firstElementChild.innerHTML,o=n.__gui.__listening.indexOf(n)>-1;n.remove();var a=vs(e,n.object,n.property,{before:n.__li.nextElementSibling,factoryArgs:[n.__min,n.__max,n.__step]});return a.name(r),o&&a.listen(),a}return t};n.min=yi.compose(o,n.min),n.max=yi.compose(o,n.max)}else n instanceof Ui?(Gi.bind(t,"click",function(){Gi.fakeEvent(n.__checkbox,"click")}),Gi.bind(n.__checkbox,"click",function(e){e.stopPropagation()})):n instanceof Qi?(Gi.bind(t,"click",function(){Gi.fakeEvent(n.__button,"click")}),Gi.bind(t,"mouseover",function(){Gi.addClass(n.__button,"hover")}),Gi.bind(t,"mouseout",function(){Gi.removeClass(n.__button,"hover")})):n instanceof Zi&&(Gi.addClass(t,"color"),n.updateDisplay=yi.compose(function(e){return t.style.borderLeftColor=n.__color.toString(),e},n.updateDisplay),n.updateDisplay());n.setValue=yi.compose(function(t){return e.getRoot().__preset_select&&n.isModified()&&ps(e.getRoot(),!0),t},n.setValue)}(e,l,o),e.__controllers.push(o),o}function gs(e,t){return document.location.href+"."+t}function Ss(e,t,n){var r=document.createElement("option");r.innerHTML=t,r.value=t,e.__preset_select.appendChild(r),n&&(e.__preset_select.selectedIndex=e.__preset_select.length-1)}function xs(e,t){t.style.display=e.useLocalStorage?"block":"none"}function bs(e){var t=void 0;function n(n){return n.preventDefault(),e.width+=t-n.clientX,e.onResize(),t=n.clientX,!1}function r(){Gi.removeClass(e.__closeButton,fs.CLASS_DRAG),Gi.unbind(window,"mousemove",n),Gi.unbind(window,"mouseup",r)}function o(o){return o.preventDefault(),t=o.clientX,Gi.addClass(e.__closeButton,fs.CLASS_DRAG),Gi.bind(window,"mousemove",n),Gi.bind(window,"mouseup",r),!1}e.__resize_handle=document.createElement("div"),yi.extend(e.__resize_handle.style,{width:"6px",marginLeft:"-3px",height:"200px",cursor:"ew-resize",position:"absolute"}),Gi.bind(e.__resize_handle,"mousedown",o),Gi.bind(e.__closeButton,"mousedown",o),e.domElement.insertBefore(e.__resize_handle,e.domElement.firstElementChild)}function ys(e,t){e.domElement.style.width=t+"px",e.__save_row&&e.autoPlace&&(e.__save_row.style.width=t+"px"),e.__closeButton&&(e.__closeButton.style.width=t+"px")}function ws(e,t){var n={};return yi.each(e.__rememberedObjects,function(r,o){var a={},i=e.__rememberedObjectIndecesToControllers[o];yi.each(i,function(e,n){a[n]=t?e.initialValue:e.getValue()}),n[o]=a}),n}fs.toggleHide=function(){us=!us,yi.each(ds,function(e){e.domElement.style.display=us?"none":""})},fs.CLASS_AUTO_PLACE="a",fs.CLASS_AUTO_PLACE_CONTAINER="ac",fs.CLASS_MAIN="main",fs.CLASS_CONTROLLER_ROW="cr",fs.CLASS_TOO_TALL="taller-than-window",fs.CLASS_CLOSED="closed",fs.CLASS_CLOSE_BUTTON="close-button",fs.CLASS_CLOSE_TOP="close-top",fs.CLASS_CLOSE_BOTTOM="close-bottom",fs.CLASS_DRAG="drag",fs.DEFAULT_WIDTH=245,fs.TEXT_CLOSED="Close Controls",fs.TEXT_OPEN="Open Controls",fs._keydownHandler=function(e){"text"===document.activeElement.type||72!==e.which&&72!==e.keyCode||fs.toggleHide()},Gi.bind(window,"keydown",fs._keydownHandler,!1),yi.extend(fs.prototype,{add:function(e,t){return vs(this,e,t,{factoryArgs:Array.prototype.slice.call(arguments,2)})},addColor:function(e,t){return vs(this,e,t,{color:!0})},remove:function(e){this.__ul.removeChild(e.__li),this.__controllers.splice(this.__controllers.indexOf(e),1);var t=this;yi.defer(function(){t.onResize()})},destroy:function(){if(this.parent)throw new Error("Only the root GUI should be removed with .destroy(). For subfolders, use gui.removeFolder(folder) instead.");this.autoPlace&&cs.removeChild(this.domElement);var e=this;yi.each(this.__folders,function(t){e.removeFolder(t)}),Gi.unbind(window,"keydown",fs._keydownHandler,!1),ms(this)},addFolder:function(e){if(void 0!==this.__folders[e])throw new Error('You already have a folder in this GUI by the name "'+e+'"');var t={name:e,parent:this};t.autoPlace=this.autoPlace,this.load&&this.load.folders&&this.load.folders[e]&&(t.closed=this.load.folders[e].closed,t.load=this.load.folders[e]);var n=new fs(t);this.__folders[e]=n;var r=hs(this,n.domElement);return Gi.addClass(r,"folder"),n},removeFolder:function(e){this.__ul.removeChild(e.domElement.parentElement),delete this.__folders[e.name],this.load&&this.load.folders&&this.load.folders[e.name]&&delete this.load.folders[e.name],ms(e);var t=this;yi.each(e.__folders,function(t){e.removeFolder(t)}),yi.defer(function(){t.onResize()})},open:function(){this.closed=!1},close:function(){this.closed=!0},hide:function(){this.domElement.style.display="none"},show:function(){this.domElement.style.display=""},onResize:function(){var e=this.getRoot();if(e.scrollable){var t=Gi.getOffset(e.__ul).top,n=0;yi.each(e.__ul.childNodes,function(t){e.autoPlace&&t===e.__save_row||(n+=Gi.getHeight(t))}),window.innerHeight-t-20<n?(Gi.addClass(e.domElement,fs.CLASS_TOO_TALL),e.__ul.style.height=window.innerHeight-t-20+"px"):(Gi.removeClass(e.domElement,fs.CLASS_TOO_TALL),e.__ul.style.height="auto")}e.__resize_handle&&yi.defer(function(){e.__resize_handle.style.height=e.__ul.offsetHeight+"px"}),e.__closeButton&&(e.__closeButton.style.width=e.width+"px")},onResizeDebounced:yi.debounce(function(){this.onResize()},50),remember:function(){if(yi.isUndefined(ss)&&((ss=new os).domElement.innerHTML='<div id="dg-save" class="dg dialogue">\n\n  Here\'s the new load parameter for your <code>GUI</code>\'s constructor:\n\n  <textarea id="dg-new-constructor"></textarea>\n\n  <div id="dg-save-locally">\n\n    <input id="dg-local-storage" type="checkbox"/> Automatically save\n    values to <code>localStorage</code> on exit.\n\n    <div id="dg-local-explain">The values saved to <code>localStorage</code> will\n      override those passed to <code>dat.GUI</code>\'s constructor. This makes it\n      easier to work incrementally, but <code>localStorage</code> is fragile,\n      and your friends may not see the same values you do.\n\n    </div>\n\n  </div>\n\n</div>'),this.parent)throw new Error("You can only call remember on a top level GUI.");var e=this;yi.each(Array.prototype.slice.call(arguments),function(t){0===e.__rememberedObjects.length&&function(e){var t=e.__save_row=document.createElement("li");Gi.addClass(e.domElement,"has-save"),e.__ul.insertBefore(t,e.__ul.firstChild),Gi.addClass(t,"save-row");var n=document.createElement("span");n.innerHTML="&nbsp;",Gi.addClass(n,"button gears");var r=document.createElement("span");r.innerHTML="Save",Gi.addClass(r,"button"),Gi.addClass(r,"save");var o=document.createElement("span");o.innerHTML="New",Gi.addClass(o,"button"),Gi.addClass(o,"save-as");var a=document.createElement("span");a.innerHTML="Revert",Gi.addClass(a,"button"),Gi.addClass(a,"revert");var i=e.__preset_select=document.createElement("select");e.load&&e.load.remembered?yi.each(e.load.remembered,function(t,n){Ss(e,n,n===e.preset)}):Ss(e,as,!1);if(Gi.bind(i,"change",function(){for(var t=0;t<e.__preset_select.length;t++)e.__preset_select[t].innerHTML=e.__preset_select[t].value;e.preset=this.value}),t.appendChild(i),t.appendChild(n),t.appendChild(r),t.appendChild(o),t.appendChild(a),is){var s=document.getElementById("dg-local-explain"),l=document.getElementById("dg-local-storage"),c=document.getElementById("dg-save-locally");c.style.display="block","true"===localStorage.getItem(gs(e,"isLocal"))&&l.setAttribute("checked","checked"),xs(e,s),Gi.bind(l,"change",function(){e.useLocalStorage=!e.useLocalStorage,xs(e,s)})}var u=document.getElementById("dg-new-constructor");Gi.bind(u,"keydown",function(e){!e.metaKey||67!==e.which&&67!==e.keyCode||ss.hide()}),Gi.bind(n,"click",function(){u.innerHTML=JSON.stringify(e.getSaveObject(),void 0,2),ss.show(),u.focus(),u.select()}),Gi.bind(r,"click",function(){e.save()}),Gi.bind(o,"click",function(){var t=prompt("Enter a new preset name.");t&&e.saveAs(t)}),Gi.bind(a,"click",function(){e.revert()})}(e),-1===e.__rememberedObjects.indexOf(t)&&e.__rememberedObjects.push(t)}),this.autoPlace&&ys(this,this.width)},getRoot:function(){for(var e=this;e.parent;)e=e.parent;return e},getSaveObject:function(){var e=this.load;return e.closed=this.closed,this.__rememberedObjects.length>0&&(e.preset=this.preset,e.remembered||(e.remembered={}),e.remembered[this.preset]=ws(this)),e.folders={},yi.each(this.__folders,function(t,n){e.folders[n]=t.getSaveObject()}),e},save:function(){this.load.remembered||(this.load.remembered={}),this.load.remembered[this.preset]=ws(this),ps(this,!1),this.saveToLocalStorageIfPossible()},saveAs:function(e){this.load.remembered||(this.load.remembered={},this.load.remembered[as]=ws(this,!0)),this.load.remembered[e]=ws(this),this.preset=e,Ss(this,e,!0),this.saveToLocalStorageIfPossible()},revert:function(e){yi.each(this.__controllers,function(t){this.getRoot().load.remembered?_s(e||this.getRoot(),t):t.setValue(t.initialValue),t.__onFinishChange&&t.__onFinishChange.call(t,t.getValue())},this),yi.each(this.__folders,function(e){e.revert(e)}),e||ps(this.getRoot(),!1)},listen:function(e){var t=0===this.__listening.length;this.__listening.push(e),t&&function e(t){0!==t.length&&rs.call(window,function(){e(t)});yi.each(t,function(e){e.updateDisplay()})}(this.__listening)},updateDisplay:function(){yi.each(this.__controllers,function(e){e.updateDisplay()}),yi.each(this.__folders,function(e){e.updateDisplay()})}});var Ts=fs,Es=n(51),As=function(e,t,n,r){return new(n||(n=Promise))(function(o,a){function i(e){try{l(r.next(e))}catch(e){a(e)}}function s(e){try{l(r.throw(e))}catch(e){a(e)}}function l(e){e.done?o(e.value):new n(function(t){t(e.value)}).then(i,s)}l((r=r.apply(e,t||[])).next())})};const Ps=e=>As(void 0,void 0,void 0,function*(){const t=yield(e=>As(void 0,void 0,void 0,function*(){const t=yield fetch(e);if(!t.ok)throw`Could not download tfx file '${e}'`;return yield t.arrayBuffer()}))(e),n=(e=>{const t=new Float32Array(e,0,1)[0],n=new Uint32Array(e,4,7);return{version:t,numHairStrands:n[0],numVerticesPerStrand:n[1],offsetVertexPosition:n[2],offsetStrandUV:n[3],offsetVertexUV:n[4],offsetStrandThickness:n[5],offsetVertexColor:n[6]}})(t);console.log("Loaded Tfx file with header",n);const r=n.numHairStrands*n.numVerticesPerStrand;return{header:n,totalVertices:r,vertexPositionsBuffer:new Float32Array(t,n.offsetVertexPosition,4*r)}}),Ms=(e,t,n,r)=>{const{totalVertices:a}=n,i=((e,t)=>{const n=e.getParameter(e.MAX_TEXTURE_SIZE);return{width:Math.min(n,t),height:Math.ceil(t/n)}})(e,a),s=new w(e,t,_.Texture2d,Object(o.fromValues)(i.width,i.height,0),0,e.RGBA32F,R({filterMin:T.Nearest,filterMag:A.Nearest}));return((e,t,n,r)=>{const a={start:Object(o.fromValues)(0,0,0),dimensions:n.dimensions},i={unsizedPixelFormat:e.RGBA,perChannelType:e.FLOAT,data:r};n.write(e,t,0,a,i)})(e,t,s,r),s},Cs=(e,t,n)=>{const{header:r}=n,a=Ms(e,t,n,n.vertexPositionsBuffer),i=((e,t,n)=>{const{vertexPositionsBuffer:r,header:{numHairStrands:a,numVerticesPerStrand:i}}=n,s=new Float32Array(r.length),l=e=>Object(o.fromValues)(r[4*e],r[4*e+1],r[4*e+2]),c=(e,t)=>{s[4*e+0]=t[0],s[4*e+1]=t[1],s[4*e+2]=t[2]};for(let e=0;e<a;++e){const t=e*i,n=l(t),r=l(t+1);c(t,Po(r,n));for(let e=1;e<i;e++){const n=l(t+e-1),r=l(t+e),o=l(t+e+1),a=Po(r,n),s=Po(o,r);let u=Mo(a,s);e===i-1&&(u=a),c(t+e,u)}}return Ms(e,t,n,s)})(e,t,n),s=((e,t)=>{const n=t.numHairStrands*t.numVerticesPerStrand,r=Array(6*n).fill(0);let o=0,a=0;for(let e=0;e<t.numHairStrands;e++){for(let e=0;e<t.numVerticesPerStrand-1;e++)r[a++]=2*o,r[a++]=2*o+1,r[a++]=2*o+2,r[a++]=2*o+2,r[a++]=2*o+1,r[a++]=2*o+3,o++;o++}const i=Uint32Array.from(r),s=be.fromData(e,me.IndexBuffer,_e.STATIC_DRAW,i);return s.bind(e),{indexBuffer:s,indexGlType:e.UNSIGNED_INT,triangleCnt:Math.floor(a/3)}})(e,n.header);return new Ia(r.numHairStrands,r.numVerticesPerStrand,a,i,s)};class Os extends ya{constructor(e){super(),this.name=e}destroy(e){}}Os.TYPE=Sa.Name;var Rs=function(e,t,n,r){return new(n||(n=Promise))(function(o,a){function i(e){try{l(r.next(e))}catch(e){a(e)}}function s(e){try{l(r.throw(e))}catch(e){a(e)}}function l(e){e.done?o(e.value):new n(function(t){t(e.value)}).then(i,s)}l((r=r.apply(e,t||[])).next())})};const Ls={sintel:n(186),sintel_eyeballs:n(187)},Is={sintel:n(188),sintel_spec:n(189),sintel_hairShadow:n(190),sintel_eyeballs:n(191)},Ns=n(192),Ds="sintel",Fs="sintel_eyes",ks="sintel_tfx",Bs=e=>Rs(void 0,void 0,void 0,function*(){const t=yield fetch(e);if(!t.ok)throw`Could not download mesh file '${e}'`;const n=yield t.text();return new Es.Mesh(n)}),Vs=(e,t)=>{const n=Float32Array.from(t.vertices),r=Float32Array.from(t.vertexNormals),o=Float32Array.from(t.textures),a=new po(e,[{name:"position",stride:0,offset:0,type:uo.FLOAT_VEC3,rawData:n},{name:"normals",stride:0,offset:0,type:uo.FLOAT_VEC3,rawData:r},{name:"uv",stride:0,offset:0,type:uo.FLOAT_VEC2,rawData:o}]),i=Uint16Array.from(t.indices),s=be.fromData(e,me.IndexBuffer,_e.STATIC_DRAW,i);return new Ra(a,{indexBuffer:s,indexGlType:e.UNSIGNED_SHORT,triangleCnt:i.length/3})},js=(e,t,n,r)=>new w(e,t,_.Texture2d,Object(o.fromValues)(n[0],n[1],0),0,r,R({filterMin:T.Nearest,filterMag:A.Nearest})),zs=(e,t,n,r)=>Rs(void 0,void 0,void 0,function*(){const i=yield((e,t,n)=>Rs(void 0,void 0,void 0,function*(){const r=js(t,n,Object(a.fromValues)(2048,1024),t.RGB8UI);yield Oo(t,n,Is.sintel,r);const o=js(t,n,Object(a.fromValues)(2048,1024),t.RGB8UI);yield Oo(t,n,Is.sintel_spec,o);const i=js(t,n,Object(a.fromValues)(512,512),t.RGB8UI);yield Oo(t,n,Is.sintel_hairShadow,i);const s=e.createEnity();return e.addComponent(s,new Oa(r,o,i)),e.addComponent(s,Vs(t,yield Bs(Ls.sintel))),e.addComponent(s,new Os(Ds)),s}))(e,n,r),s=yield((e,t,n)=>Rs(void 0,void 0,void 0,function*(){const r=js(t,n,Object(a.fromValues)(512,512),t.RGB8UI);yield Oo(t,n,Is.sintel_eyeballs,r);const o=e.createEnity(),i=new Oa(r,null);return i.specularMul=3,e.addComponent(o,i),e.addComponent(o,Vs(t,yield Bs(Ls.sintel_eyeballs))),e.addComponent(o,new Os(Fs)),o}))(e,n,r),l=yield((e,t,n)=>Rs(void 0,void 0,void 0,function*(){const r=yield Ps(Ns),o=Cs(t,n,r),a=e.createEnity();return e.addComponent(a,o),e.addComponent(a,new Os(ks)),a}))(e,n,r),c=new Ba,u=t.sintel.modelScale;Object(o.set)(c.scale,u,u,u),c.updateModelMatrix(),e.addComponent(i,c),e.addComponent(s,c),e.addComponent(l,c)}),Gs=R({filterMin:T.Linear,filterMag:A.Linear,wrap:[M.UseEdgePixel,M.UseEdgePixel,M.UseEdgePixel]});class Us{constructor(e){this.cfg=e}initialize(e){this.initializeShaders(e.gl);const t=this.initializeShadowResources(e,this.cfg.shadows.shadowmapSize);this.shadowDepthTex=t.texture,this.shadowDepthFbo=t.fbo;const n=this.initializeShadowResources(e,this.cfg.lightSSS.depthmapSize);this.sssDepthTex=n.texture,this.sssDepthFbo=n.fbo,this.initializeSSAO_RngTexture(e)}onResize(e,t){this.destroyResizableResources(e.gl),this.initializeForwardPassResources(e,t),this.initializeLinearDepthPassResources(e,t),this.initializeTonemappingPassResources(e,t),this.initializeSSAOPassResources(e,t)}initializeShaders(e){this.shadowShader=new co(e,n(193),n(49)),this.shadowTfxShader=new co(e,n(194),n(49)),this.meshShader=new co(e,n(195),n(196)),this.finalShader=new co(e,n(5),n(197)),this.dbgShadowsShader=new co(e,n(5),n(198)),this.dbgSphereShader=new co(e,n(199),n(200)),this.tonemappingShader=new co(e,n(5),n(201)),this.sssBlurShader=new co(e,n(5),n(202)),this.linearDepthShader=new co(e,n(5),n(203)),this.tfxShader=new co(e,n(204),n(205)),this.ssaoShader=new co(e,n(5),n(206)),this.blurShader=new co(e,n(5),n(207))}initializeForwardPassResources(e,t){const{gl:n}=e;t=this.getFullscreenDimensions(t),this.forwardDepthTex=this.createTexture(e,n.DEPTH24_STENCIL8,t,this.createTextureOpts(n,n.DEPTH24_STENCIL8)),this.forwardColorTex=this.createTexture(e,n.RGBA32F,t,this.createTextureOpts(n,n.RGBA32F)),this.forwardNormalsTex=this.createTexture(e,n.RGBA8,t,this.createTextureOpts(n,n.RGBA8)),this.forwardFbo=new no(n,[this.forwardDepthTex,this.forwardColorTex,this.forwardNormalsTex]),this.sssBlurPingPongTex=this.createTexture(e,n.RGBA32F,t,this.createTextureOpts(n,n.RGBA32F)),this.sssBlurPingPongFbo=new no(n,[this.forwardDepthTex,this.sssBlurPingPongTex])}initializeLinearDepthPassResources(e,t){const{gl:n}=e;t=this.getFullscreenDimensions(t),this.linearDepthTex=this.createTexture(e,n.R32F,t,this.createTextureOpts(n,n.R32F)),this.linearDepthFbo=new no(n,[this.linearDepthTex])}initializeTonemappingPassResources(e,t){const{gl:n}=e;t=this.getFullscreenDimensions(t),this.tonemappingResultTex=this.createTexture(e,n.RGBA8,t,this.createTextureOpts(n,n.RGBA8)),this.tonemappingFbo=new no(n,[this.tonemappingResultTex])}initializeSSAO_RngTexture(e){const{gl:t,textureBindingState:n}=e;this.ssaoRngTex=this.createTexture(e,t.RGB16F,{width:4,height:4},Object.assign({},Gs,{filterMin:T.Nearest,filterMag:A.Nearest,wrap:[M.Repeat,M.Repeat,M.Repeat]}));const r=new Float32Array(48);for(let e=0;e<16;e++)r[3*e]=2*Math.random()-1,r[3*e+1]=2*Math.random()-1,r[3*e+2]=0;this.ssaoRngTex.write(t,n,0,{start:Object(o.fromValues)(0,0,0),dimensions:Object(o.fromValues)(4,4,1)},{unsizedPixelFormat:t.RGB,perChannelType:t.FLOAT,data:r})}initializeSSAOPassResources(e,t){const{gl:n}=e,r=this.cfg.ssao.textureSizeMul;t={width:(t=this.getFullscreenDimensions(t)).width*r,height:t.height*r},this.ssaoTex=this.createTexture(e,n.R16F,t,this.createTextureOpts(n,n.R16F)),this.ssaoFbo=new no(n,[this.ssaoTex]),this.ssaoBlurPingPongTex=this.createTexture(e,n.R16F,t,this.createTextureOpts(n,n.R16F)),this.ssaoBlurPingPongFbo=new no(n,[this.ssaoBlurPingPongTex])}initializeShadowResources(e,t){const{gl:n}=e,r=this.createTexture(e,n.DEPTH_COMPONENT16,{width:t,height:t},this.createTextureOpts(n,n.DEPTH_COMPONENT16));return{texture:r,fbo:new no(n,[r])}}getFullscreenDimensions(e){return this.cfg.useMSAA?{width:2*e.width,height:2*e.height}:e}createTexture(e,t,n,r){const{gl:a,textureBindingState:i}=e;return new w(a,i,_.Texture2d,Object(o.fromValues)(n.width,n.height,1),0,t,r)}createTextureOpts(e,t){const n=Object.assign({},Gs);return p(t)&&(n.filterMin=T.Nearest,n.filterMag=A.Nearest),[e.DEPTH_COMPONENT16,e.DEPTH24_STENCIL8].includes(t)&&(n.filterMin=T.Nearest,n.filterMag=A.Nearest,n.wrap[0]=M.UseEdgePixel,n.wrap[1]=M.UseEdgePixel),n}destroyResizableResources(e){this.forwardFbo&&this.forwardFbo.destroy(e),this.forwardDepthTex&&this.forwardDepthTex.destroy(e),this.forwardColorTex&&this.forwardColorTex.destroy(e),this.forwardNormalsTex&&this.forwardNormalsTex.destroy(e),this.linearDepthFbo&&this.linearDepthFbo.destroy(e),this.linearDepthTex&&this.linearDepthTex.destroy(e),this.sssBlurPingPongFbo&&this.sssBlurPingPongFbo.destroy(e),this.sssBlurPingPongTex&&this.sssBlurPingPongTex.destroy(e),this.tonemappingFbo&&this.tonemappingFbo.destroy(e),this.tonemappingResultTex&&this.tonemappingResultTex.destroy(e),this.ssaoFbo&&this.ssaoFbo.destroy(e),this.ssaoTex&&this.ssaoTex.destroy(e)}}class Hs{constructor(){this.getLightShadowMvp=((e,t,n)=>{const r=this.getDepthViewMatrix(e,n),o=this.getDepthProjectionMatrix(e);return d(t,r,o)})}execute(e,t){const{device:n}=e,{gl:r}=n,{fbo:o,renderHair:a}=t;o.bind(r,$r.Draw,!0),r.clear(r.DEPTH_BUFFER_BIT),r.viewport(0,0,o.dimensions[0],o.dimensions[1]);const i=new ai;i.depth.write=!0,i.depth.test=ja.IfLessOrEqual,i.culling=ri.None,i.colorWrite=[!1,!1,!1,!1],n.setState(i),this.renderMeshObjects(e,t),a&&this.renderHairObjects(e,t,o.dimensions)}renderMeshObjects(e,t){const{cfg:n,device:r,ecs:o,frameRes:a}=e,{gl:i}=r,{position:s}=t,l=a.shadowShader;l.use(i),o.forEachEntity((e,t,o,a)=>{const i=o.modelMatrix;So(r,l,{u_MVP:this.getLightShadowMvp(n,i,s)},!0),r.renderMesh(a)},Oa,Ba,Ra)}renderHairObjects(e,t,n){const{cfg:o,device:a,ecs:i,frameRes:s}=e,{gl:l}=a,{position:c}=t,u=s.shadowTfxShader;u.use(l);const d=this.getLightShadowMvp(o,Object(r.create)(),c);i.forEachEntity((e,t,r)=>{a.renderTressFx(t,u,{modelMat:r.modelMatrix,viewProjectionMat:d,cameraPosition:c,viewport:{width:n[0],height:n[1]},cfg:o,radiusMultiplier:o.shadows.hairTfxRadiusMultipler})},Ia,Ba)}getDepthViewMatrix(e,t){const n=e.shadows.directionalLight;return Object(r.lookAt)(Object(r.create)(),t,n.target,xo)}getDepthProjectionMatrix(e){const t=e.shadows.directionalLight.projection;return Object(r.ortho)(Object(r.create)(),t.left,t.right,t.bottom,t.top,t.near,t.far)}}const Ws=1,Ys=2,Xs=4;class qs{execute(e,t){const{cfg:n,device:r,frameRes:o,camera:a,ecs:i}=e,{gl:s}=r,l=o.meshShader;l.use(s);const c=o.forwardFbo;c.bind(s,$r.Draw,!0),s.viewport(0,0,c.dimensions[0],c.dimensions[1]);const u=new ai;r.setState(u),s.clear(s.COLOR_BUFFER_BIT|s.DEPTH_BUFFER_BIT|s.STENCIL_BUFFER_BIT);const d=new ai;d.depth.test=ja.IfLessOrEqual,d.culling=ri.None,d.stencil.referenceValue=n.stencilConsts.skin,d.stencil.writeBytes=n.stencilConsts.skin,d.stencil.front.opPass=Ha.Replace,d.stencil.back.opPass=Ha.Replace,r.setState(d),i.forEachEntity((e,i,s,u)=>{const d=s.modelMatrix;So(r,l,Object.assign({u_M:d,u_MVP:a.getMVP(d),u_cameraPosition:a.position,u_viewport:c.dimensions,u_aoTex:o.ssaoTex,u_aoStrength:n.ssao.aoStrength,u_aoExp:n.ssao.aoExp,u_directionalShadowMatrix_MVP:t.getLightShadowMvp(d),u_directionalShadowDepthTex:o.shadowDepthTex,u_maxShadowContribution:n.shadows.strength,u_directionalShadowSampleRadius:Math.floor(n.shadows.blurRadius),u_directionalShadowCasterPosition:Float32Array.from([t.shadowLightPosition[0],t.shadowLightPosition[1],t.shadowLightPosition[2],n.shadows.bias*(n.shadows.usePCSS?-1:1)]),u_albedoTexture:i.albedoTex,u_specularTexture:i.specularTex?i.specularTex:i.albedoTex,u_hairShadowTexture:i.hairShadowTex?i.hairShadowTex:i.albedoTex,u_specular:i.specular,u_specularMul:i.specularMul,u_materialFlags:this.createMaterialFlags(i),u_sssTransluency:i.sssTransluency,u_sssWidth:i.sssWidth,u_sssBias:i.sssBias,u_sssGain:i.sssGain,u_sssStrength:i.sssStrength,u_sssFarPlane:n.shadows.directionalLight.projection.far,u_sssDepthTex:o.sssDepthTex,u_sssPosition:t.sssPosition,u_sssMatrix_VP:t.getSSS_VP(),u_lightAmbient:Float32Array.from([n.lightAmbient.color[0],n.lightAmbient.color[1],n.lightAmbient.color[2],n.lightAmbient.energy])},qs.lightUniforms("light0",n.light0),qs.lightUniforms("light1",n.light1),qs.lightUniforms("light2",n.light2)),!0),r.renderMesh(u)},Oa,Ba,Ra)}createMaterialFlags(e){let t=0;const n=(e,n)=>{t|=e?n:0};return n(e.isMetallic,Ws),n(Boolean(e.specularTex),Ys),n(Boolean(e.hairShadowTex),Xs),t}static lightUniforms(e,t){const n=yo(t.posPhi,t.posTheta,!0);return Object(o.scale)(n,n,t.posRadius),{[`u_${e}_Position`]:n,[`u_${e}_Color`]:Float32Array.from([t.color[0],t.color[1],t.color[2],t.energy])}}}class Ks{execute(e){const{cfg:t,device:n,frameRes:r,viewport:o,camera:i}=e,{gl:s}=n,l=r.finalShader;l.use(s);const c=new ai;c.depth.test=ja.AlwaysPass,c.depth.write=!1,c.culling=ri.None,n.setState(c),n.setBackbufferAsRenderTarget(),s.viewport(0,0,o.width,o.height),So(n,l,{u_viewport:Object(a.fromValues)(o.width,o.height),u_displayMode:t.displayMode,u_gamma:t.postfx.gamma,u_nearAndFar:Object(a.fromValues)(i.settings.zNear,i.settings.zFar),u_tonemappedTex:r.tonemappingResultTex,u_linearDepthTex:r.linearDepthTex,u_normalsTex:r.forwardNormalsTex,u_ssaoTex:r.ssaoTex,u_subpixel:t.postfx.subpixel,u_edgeThreshold:t.postfx.useFxaa?t.postfx.edgeThreshold:0,u_edgeThresholdMin:t.postfx.edgeThresholdMin},!0),n.renderFullscreenQuad(),t.showDebugPositions&&this.debugPositions(e),t.shadows.showDebugView&&this.debugShadowDepths(e)}debugShadowDepths(e){const{device:t,frameRes:n,viewport:r}=e,{gl:o}=t,a=Math.floor(Math.min(r.width/3,200)),i=n.dbgShadowsShader;i.use(o);const s=new ai;s.depth.test=ja.AlwaysPass,s.depth.write=!1,s.culling=ri.None,t.setState(s),[n.shadowDepthTex,n.sssDepthTex].forEach((e,n)=>{o.viewport(n*a+5*n,0,a,a),So(t,i,{u_depthTex:e},!0),t.renderFullscreenQuad(!0)})}debugPositions(e){const{cfg:t,device:n,frameRes:o,camera:a}=e,{gl:i}=n,s=o.dbgSphereShader;s.use(i);const l=new ai;l.depth.test=ja.AlwaysPass,l.depth.write=!1,l.culling=ri.None,n.setState(l);const c=[{position:t.sphericalToCartesian(t.light0),color:t.light0.color},{position:t.sphericalToCartesian(t.light1),color:t.light1.color},{position:t.sphericalToCartesian(t.light2),color:t.light2.color},{position:t.sphericalToCartesian(t.shadows.directionalLight),color:Ao("#404040")},{position:t.sphericalToCartesian(t.lightSSS),color:Ao("#de875d")}],u=a.getMVP(Object(r.create)());c.forEach(e=>{So(n,s,{u_position:e.position,u_scale:1,u_color:e.color,u_VP:u},!0),n.renderDebugSphere()})}}const $s=Object(a.fromValues)(1,0),Qs=Object(a.fromValues)(0,1);class Zs{execute(e,t){const{cfg:n,device:r,frameRes:o}=e,{gl:a}=r,{fbo:i,isFirstPass:s,sourceTexture:l}=t;i.bind(a,$r.Draw,!0),a.viewport(0,0,i.dimensions[0],i.dimensions[1]),s&&a.clear(a.COLOR_BUFFER_BIT);const c=o.sssBlurShader;c.use(a);const u=new ai;u.depth.write=!1,u.depth.test=ja.AlwaysPass,u.culling=ri.None,u.stencil.referenceValue=n.stencilConsts.skin,u.stencil.compareMask=n.stencilConsts.skin|n.stencilConsts.hair,u.stencil.front.test=Ga.IfRefIsEqualCurrent,u.stencil.back.test=Ga.IfRefIsEqualCurrent,r.setState(u),So(r,c,{u_sourceTex:l,u_linearDepthTex:o.linearDepthTex,u_sssDirection:this.getDirection(s),u_sssFollowSurface:n.lightSSS.blurFollowSurface?1:0,u_sssFovy:this.getFovY(e),u_sssWidth:n.lightSSS.blurWidth,u_sssStrength:n.lightSSS.blurStrength},!0),r.renderFullscreenQuad()}getDirection(e){return e?$s:Qs}getFovY(e){const{viewport:t,camera:n}=e;return n.settings.fovDgr/t.width*t.height}}class Js{execute(e){const{device:t,frameRes:n,camera:r}=e,{gl:o}=t,i=n.linearDepthFbo;i.bind(o,$r.Draw,!0),o.viewport(0,0,i.dimensions[0],i.dimensions[1]);const s=n.linearDepthShader;s.use(o),So(t,s,{u_depthPerspTex:n.forwardDepthTex,u_nearAndFar:Object(a.fromValues)(r.settings.zNear,r.settings.zFar)},!0),t.renderFullscreenQuad(!0)}}class el{execute(e,t){const{cfg:n,device:o,frameRes:a,camera:i,ecs:s}=e,{gl:l}=o,c=a.tfxShader;c.use(l);const u=new ai;u.depth.test=ja.IfLessOrEqual,u.culling=ri.None,u.stencil.referenceValue=n.stencilConsts.hair,u.stencil.writeBytes=n.stencilConsts.hair,u.stencil.front.opPass=Ha.Replace,u.stencil.back.opPass=Ha.Replace,o.setState(u);const d=a.forwardFbo;d.bind(l,$r.Draw,!0),l.viewport(0,0,d.dimensions[0],d.dimensions[1]);const f=t.getLightShadowMvp(Object(r.create)());s.forEachEntity((e,r,s)=>{So(o,c,Object.assign({u_displayMode:r.displayMode,u_albedo:r.material.albedo,u_specularColor1:r.material.specularColor1,u_specularColor2:r.material.specularColor2,u_primaryShift:r.material.primaryShift,u_secondaryShift:r.material.secondaryShift,u_specularPower1:r.material.specularPower1,u_specularPower2:r.material.specularPower2,u_specularStrength1:r.material.specularStrength1,u_specularStrength2:r.material.specularStrength2,u_aoTex:a.ssaoTex,u_aoStrength:r.material.aoStrength,u_aoExp:r.material.aoExp,u_directionalShadowMatrix_VP:f,u_directionalShadowDepthTex:a.shadowDepthTex,u_maxShadowContribution:n.shadows.strength,u_directionalShadowSampleRadius:Math.floor(n.shadows.blurRadiusTfx),u_directionalShadowCasterPosition:Float32Array.from([t.shadowLightPosition[0],t.shadowLightPosition[1],t.shadowLightPosition[2],n.shadows.biasHairTfx*(n.shadows.usePCSS?-1:1)]),u_lightAmbient:Float32Array.from([n.lightAmbient.color[0],n.lightAmbient.color[1],n.lightAmbient.color[2],n.lightAmbient.energy])},qs.lightUniforms("light0",n.light0),qs.lightUniforms("light1",n.light1),qs.lightUniforms("light2",n.light2)),!0),o.renderTressFx(r,c,{modelMat:s.modelMatrix,viewProjectionMat:i.viewProjectionMatrix,cameraPosition:i.position,viewport:{width:d.dimensions[0],height:d.dimensions[1]},cfg:n,radiusMultiplier:1})},Ia,Ba)}}const tl=e=>{const t=new Float32Array(3*e),n=Object(o.create)();for(let r=0;r<e;r++){n[0]=2*Math.random()-1,n[1]=2*Math.random()-1,n[2]=Math.random(),Object(o.normalize)(n,n);let a=r/e;a=To(.1,1,a*a),Object(o.scale)(n,n,a),t[3*r]=n[0],t[3*r+1]=n[1],t[3*r+2]=n[2]}return t};class nl{constructor(){nl.lazyInitKernelValues()}static lazyInitKernelValues(){nl.kernelValues||(nl.kernelValues=tl(nl.MAX_KERNEL_VALUES))}execute(e){const{cfg:t,device:n,frameRes:o,camera:i}=e,{gl:s}=n,l=o.ssaoFbo;l.bind(s,$r.Draw,!0),s.viewport(0,0,l.dimensions[0],l.dimensions[1]);const c=o.ssaoShader;c.use(s);const u=o.forwardDepthTex,d=o.ssaoRngTex;So(n,c,{u_sceneDepthTex:u,u_normalTex:o.forwardNormalsTex,u_noiseTex:o.ssaoRngTex,u_noiseScale:Object(a.fromValues)(l.dimensions[0]/d.dimensions[0],l.dimensions[1]/d.dimensions[1]),u_invProjectionMat:Object(r.invert)(Object(r.create)(),i.projectionMatrix),u_viewMat:i.viewMatrix,u_projection:i.projectionMatrix,u_kernelSize:t.ssao.kernelSize,u_radius:t.ssao.radius,u_bias:t.ssao.bias},!0);const f=c.getUniform("u_kernel[0]");if(!f)throw"SSAO could not find 'u_kernel[0]' uniform";s.uniform3fv(f.location,nl.kernelValues),n.renderFullscreenQuad(!0)}}nl.MAX_KERNEL_VALUES=256;const rl=Object(a.fromValues)(1,0),ol=Object(a.fromValues)(0,1);class al{constructor(e,t,n){this.blurRadius=e,this.gaussSigma=t,this.blurMaxDepthDistance=n}execute(e,t){const{device:n,frameRes:r}=e,{gl:o}=n,{fbo:a,isFirstPass:i}=t,s=r.blurShader;s.use(o);const l=new ai;l.depth.write=!1,l.depth.test=ja.AlwaysPass,l.culling=ri.None,n.setState(l),a.bind(o,$r.Draw,!0),o.viewport(0,0,a.dimensions[0],a.dimensions[1]),i&&o.clear(o.COLOR_BUFFER_BIT),So(n,s,{u_sourceTex:t.sourceTexture,u_linearDepthTex:t.depthTexture,u_direction:this.getDirection(i),u_blurRadius:this.blurRadius,u_gaussSigma:this.gaussSigma,u_depthMaxDist:this.blurMaxDepthDistance},!0),n.renderFullscreenQuad()}getDirection(e){return e?rl:ol}}const il=(e,t,n)=>{const r={values:n.map(e=>e.label)};return Object.defineProperty(r,t,{enumerable:!0,get:()=>{const r=e[t];return(n.find(e=>e.value===r)||n[0]).label},set:r=>{const o=n.find(e=>e.label===r)||n[0];e[t]=o.value}}),r};class sl{constructor(e){this.cfg=e}initialize(e,t){this.gui=new Ts;const n=this.cfg.postfx.colorGrading,r={openGithub:()=>{window.location.href=this.cfg.githubRepoLink}};this.gui.add(r,"openGithub").name("GITHUB");const o=il(this.cfg,"displayMode",[{label:"Final",value:0},{label:"Linear Depth",value:1},{label:"Normals",value:2},{label:"SSAO",value:3}]);this.gui.add(o,"displayMode",o.values).name("Display mode"),this.addColorController(this.gui,this.cfg,"clearColor","Bg color"),this.gui.add(this.cfg,"showDebugPositions").name("Show positions"),this.gui.add(this.cfg,"useMSAA").name("Use MSAA").onFinishChange(t),this.addMaterialFolder(this.gui,e,"Sintel",Ds),this.addMaterialFolder(this.gui,e,"Sintel_eyes",Fs),this.addSSS_General(this.gui),this.addTfxFolder(this.gui,e,"TressFX Hair",ks),this.addAmbientLightFolder(this.gui),this.addLightFolder(this.gui,this.cfg.light0,"Light 0"),this.addLightFolder(this.gui,this.cfg.light1,"Light 1"),this.addLightFolder(this.gui,this.cfg.light2,"Light 2"),this.addShadowsFolder(this.gui),this.addSSAO(this.gui),this.addPostFx(this.gui),this.addColorGrading(this.gui,n.global,"Color grading - general",{tint:!0}),this.addColorGrading(this.gui,n.shadows,"Color grading - shadows",{shadowMax:!0}),this.addColorGrading(this.gui,n.midtones,"Color grading - midtones",{}),this.addColorGrading(this.gui,n.highlights,"Color grading - highlights",{highlightsMin:!0}),this.addFxaa(this.gui)}addMaterialFolder(e,t,n,r){const o=t.getByName(r);if(void 0===o)throw`Did not found entity '${r}'`;const a=t.getComponent(o,Oa),i=e.addFolder(n);a.specularTex||i.add(a,"specular",0,1,.01).name("Specular"),i.add(a,"specularMul",0,6,.1).name("Specular mul"),i.add(a,"sssTransluency",0,1).name("SSS transluency"),i.add(a,"sssWidth",0,100).name("SSS width"),i.add(a,"sssBias",0,.1).name("SSS bias"),i.add(a,"sssGain",0,1).name("SSS gain"),i.add(a,"sssStrength",0,10).name("SSS strength")}addSSS_General(e){const t=e.addFolder("SSS general / blur");t.add(this.cfg.lightSSS,"posPhi",-179,179).step(1).name("Position phi"),t.add(this.cfg.lightSSS,"posTheta",15,165).step(1).name("Position th"),t.add(this.cfg.lightSSS,"blurWidth",1,100).name("Blur width"),t.add(this.cfg.lightSSS,"blurStrength",0,1).name("Blur strength"),t.add(this.cfg.lightSSS,"blurFollowSurface").name("Blur follow surface")}addTfxFolder(e,t,n,r){const o=t.getByName(r);if(void 0===o)throw`Did not found entity '${r}'`;const a=t.getComponent(o,Ia),i=e.addFolder(n),s=il(a,"displayMode",[{label:"Final",value:0},{label:"Flat",value:1},{label:"Follow gr.",value:2},{label:"Root-tip %",value:3},{label:"Shadow",value:4}]);i.add(s,"displayMode",s.values).name("Display mode"),i.add(a,"fiberRadius",.001,.015).name("Radius"),i.add(a,"thinTip",0,1,.01).name("Thin tip"),i.add(a,"followHairs",1,Ia.MAX_FOLLOW_HAIRS_PER_GUIDE,1).name("Follow hairs"),i.add(a,"followHairSpreadRoot",0,.4).name("Spread root"),i.add(a,"followHairSpreadTip",0,.4).name("Spread tip");const l=500,c=-.1,u=.1,d=.001,f=a.material;this.addColorController(i,f,"albedo","Diffuse"),this.addColorController(i,f,"specularColor1","Spec 1"),i.add(f,"specularPower1",0,l).name("Spec exp 1"),i.add(f,"specularStrength1",0,1).name("Spec str 1"),i.add(f,"primaryShift",c,u,d).name("Spec shift 1"),this.addColorController(i,f,"specularColor2","Spec 2"),i.add(f,"specularPower2",0,l).name("Spec exp 2"),i.add(f,"specularStrength2",0,1).name("Spec str 2"),i.add(f,"secondaryShift",c,u,d).name("Spec shift 2"),i.add(f,"aoStrength",0,1,.01).name("AO strength"),i.add(f,"aoExp",0,5,.1).name("AO exp")}addShadowsFolder(e){const t=e.addFolder("Shadows");t.add(this.cfg.shadows,"showDebugView").name("Show dbg");const n=il(this.cfg.shadows,"usePCSS",[{label:"PCF",value:!1},{label:"PCSS",value:!0}]);t.add(n,"usePCSS",n.values).name("Technique"),t.add(this.cfg.shadows,"strength",0,1).name("Strength"),t.add(this.cfg.shadows,"blurRadius",[0,1,2,3,4]).name("Blur radius"),t.add(this.cfg.shadows,"bias",.001,.01).name("Bias"),t.add(this.cfg.shadows,"blurRadiusTfx",[0,1,2,3,4]).name("HAIR Blur radius"),t.add(this.cfg.shadows,"biasHairTfx",.001,.01).name("HAIR Bias"),t.add(this.cfg.shadows,"hairTfxRadiusMultipler",.5,3).name("HAIR Radius mul"),t.add(this.cfg.shadows.directionalLight,"posPhi",-179,179).step(1).name("Position phi"),t.add(this.cfg.shadows.directionalLight,"posTheta",15,165).step(1).name("Position th")}addAmbientLightFolder(e){const t=e.addFolder("Ambient light");this.addColorController(t,this.cfg.lightAmbient,"color","Color"),t.add(this.cfg.lightAmbient,"energy",0,.2,.01).name("Energy")}addLightFolder(e,t,n){const r=e.addFolder(n);r.add(t,"posPhi",-179,179).step(1).name("Position phi"),r.add(t,"posTheta",15,165).step(1).name("Position th"),r.add(t,"posRadius",0,10).name("Position r"),this.addColorController(r,t,"color","Color"),r.add(t,"energy",0,2).name("Energy")}addSSAO(e){const t=e.addFolder("SSAO"),n=this.cfg.ssao;t.add(n,"kernelSize",1,nl.MAX_KERNEL_VALUES,1).name("Kernel size"),t.add(n,"radius",.1,3).name("Radius"),t.add(n,"bias",0,.1).name("Bias"),t.add(n,"blurRadius",0,9,1).name("Blur radius"),t.add(n,"blurGaussSigma",1,6,.1).name("Blur gauss sigma"),t.add(n,"blurMaxDepthDistance",.01,.4).name("Blur depth diff"),t.add(n,"aoStrength",0,1,.01).name("AO strength"),t.add(n,"aoExp",0,5,.1).name("AO exp")}addPostFx(e){const t=e.addFolder("Post FX");t.add(this.cfg.postfx,"gamma",1,3).name("Gamma"),t.add(this.cfg.postfx,"ditherStrength",0,2,.01).name("Dither");const n=il(this.cfg.postfx,"tonemappingOp",Io.map(e=>({label:e,value:Lo[e]})));t.add(n,"tonemappingOp",n.values).name("Tonemap op"),t.add(this.cfg.postfx,"acesC",.5,1.5).name("ACES C"),t.add(this.cfg.postfx,"acesS",0,2).name("ACES S"),t.add(this.cfg.postfx,"exposure",.5,2).name("Exposure"),t.add(this.cfg.postfx,"whitePoint",.5,2).name("White point")}addFxaa(e){const t=e.addFolder("FXAA");t.add(this.cfg.postfx,"useFxaa").name("Use FXAA"),t.add(this.cfg.postfx,"subpixel",0,1).name("Subpixel aa"),t.add(this.cfg.postfx,"edgeThreshold",.063,.333).name("Contrast Treshold"),t.add(this.cfg.postfx,"edgeThresholdMin",0,.0833).name("Edge Treshold")}addColorGrading(e,t,n,r){const o=e.addFolder(n);this.addColorGradingProp(o,t.saturation,"Saturation"),this.addColorGradingProp(o,t.contrast,"Contrast"),this.addColorGradingProp(o,t.gamma,"Gamma"),this.addColorGradingProp(o,t.gain,"Gain"),this.addColorGradingProp(o,t.offset,"Offset",-1,1),r.tint,r.shadowMax&&o.add(t,"shadowsMax",0,1).name("shadowsMax"),r.highlightsMin&&o.add(t,"highlightsMin",0,1).name("highlightsMin")}addColorGradingProp(e,t,n,r=0,o=2){this.addColorController(e,t,"color",`${n} color`),e.add(t,"value",r,o,.01).name(n)}addColorController(e,t,n,r){const o={value:[]};Object.defineProperty(o,"value",{enumerable:!0,get:()=>{const e=t[n];return[255*e[0],255*e[1],255*e[2]]},set:e=>{const r=t[n];r[0]=e[0]/255,r[1]=e[1]/255,r[2]=e[2]/255}}),e.addColor(o,"value").name(r)}}var ll=function(e,t,n,r){return new(n||(n=Promise))(function(o,a){function i(e){try{l(r.next(e))}catch(e){a(e)}}function s(e){try{l(r.throw(e))}catch(e){a(e)}}function l(e){e.done?o(e.value):new n(function(t){t(e.value)}).then(i,s)}l((r=r.apply(e,t||[])).next())})};const cl=e=>{const t=(e=>{const{controller:t,camera:n}=e.camera;return{cfg:e.config,device:e.device,ecs:e.ecs,frameRes:e.frameResources,viewport:e.device.surfaceSize,camera:{getMVP:e=>d(e,t.viewMatrix,n.perspectiveMatrix),viewProjectionMatrix:f(t.viewMatrix,n.perspectiveMatrix),position:t.position,settings:n.settings,projectionMatrix:n.perspectiveMatrix,viewMatrix:t.viewMatrix}}})(e),{gl:n,config:o,frameResources:a}=e,i=o.clearColor;n.clearColor(i[0],i[1],i[2],1);const s=new Hs,l=o.sphericalToCartesian(o.shadows.directionalLight);s.execute(t,{fbo:a.shadowDepthFbo,position:l,renderHair:!0});const c=o.sphericalToCartesian(o.lightSSS);s.execute(t,{fbo:a.sssDepthFbo,position:c,renderHair:!1}),(new qs).execute(t,{getLightShadowMvp:e=>s.getLightShadowMvp(o,e,l),getSSS_VP:()=>s.getLightShadowMvp(o,Object(r.create)(),c),shadowLightPosition:l,sssPosition:c});const u=new Js;u.execute(t);const h=new Zs;h.execute(t,{fbo:a.sssBlurPingPongFbo,sourceTexture:a.forwardColorTex,isFirstPass:!0}),h.execute(t,{fbo:a.forwardFbo,sourceTexture:a.sssBlurPingPongTex,isFirstPass:!1}),(new el).execute(t,{getLightShadowMvp:e=>s.getLightShadowMvp(o,e,l),shadowLightPosition:l}),u.execute(t),(new nl).execute(t);const m=new al(o.ssao.blurRadius,o.ssao.blurGaussSigma,o.ssao.blurMaxDepthDistance);m.execute(t,{depthTexture:a.linearDepthTex,fbo:a.ssaoBlurPingPongFbo,sourceTexture:a.ssaoTex,isFirstPass:!0}),m.execute(t,{depthTexture:a.linearDepthTex,fbo:a.ssaoFbo,sourceTexture:a.ssaoBlurPingPongTex,isFirstPass:!1}),(new No).execute(t),(new Ks).execute(t)},ul=e=>(t=0)=>{e.statsSystem.frameBegin(),e.timingSystem.update(t);const{frameTimings:n}=e.timingSystem;e.inputSystem.update(n.deltaTimeMs),cl(e),requestAnimationFrame(ul(e)),e.statsSystem.frameEnd()};(()=>ll(void 0,void 0,void 0,function*(){const e={};e.config=new ko;const t=e.config;e.canvas=document.getElementById("viewport-canvas"),e.gl=((e,t,n)=>{let r;e.addEventListener&&e.addEventListener("webglcontextcreationerror",t=>s(e,t.statusMessage),!1);try{((e,t)=>{t.forEach(t=>{if(!e.getExtension(t))throw`Your browser does not support '${t}' extension`})})(r=l(e,t),n)}catch(t){throw s(e,t.statusMessage||t),t}return r})(e.canvas,{alpha:!1,antialias:!1,depth:!0,failIfMajorPerformanceCaveat:!0,powerPreference:"high-performance",stencil:!0},["EXT_color_buffer_float","OES_texture_float_linear"]),e.gl.clearDepth(t.clearDepth),e.gl.clearStencil(t.clearStencil),e.device=new ii(e.gl),e.ecs=new wa,e.timingSystem=new _i,e.frameResources=new Us(e.config),e.frameResources.initialize(e.device);const n=t=>{e.camera.camera.updateProjectionMatrix(t.width,t.height),e.frameResources.onResize(e.device,t),e.device.surfaceSize=t};return e.resizeSystem=new fi(e.gl,t.resizeUpdateFreq),e.resizeSystem.addHandler(n),e.camera={controller:new Ca,camera:new Ta(e.config.camera.settings)},Object(o.copy)(e.camera.controller.position,t.camera.position),Object(a.copy)(e.camera.controller.angles,t.camera.rotation),e.inputSystem=new pi(e.canvas,e.camera.controller),yield zs(e.ecs,e.config,e.gl,e.device.textureBindingState),e.statsSystem=new gi,e.uISystem=new sl(t),e.uISystem.initialize(e.ecs,()=>{n(e.device.surfaceSize)}),e.resizeSystem.forceRecalc(),e}))().then(e=>{console.log("--- Init done ---"),ul(e)()})}]);